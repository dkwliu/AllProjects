{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-567cda7f1c02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import calendar as cd\n",
    "import numpy as np\n",
    "import math \n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import os\n",
    "\n",
    "DIRTY_FILE_NAME = 'ES=F.csv'\n",
    "CLEAN_FILE_NAME = '(Clean)dowjones_stocks.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA EXTRACTION AND CLEANING AND FORMATTING\n",
    "### Data Extraction\n",
    "Putting the S&P 500 csv data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date     Open     High      Low   Close  Adj Close    Volume\n",
      "0  2000-09-18  1485.25  1489.75  1462.25  1467.5     1467.5  104794.0\n",
      "1  2000-09-19  1467.00  1482.75  1466.75  1478.5     1478.5  103371.0\n",
      "2  2000-09-20  1478.75  1480.50  1450.25  1469.5     1469.5  109667.0\n",
      "3  2000-09-21  1470.25  1474.00  1455.50  1469.5     1469.5   98528.0\n",
      "4  2000-09-22  1454.75  1471.00  1436.75  1468.5     1468.5   97416.0\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(DIRTY_FILE_NAME):\n",
    "    dowjones_stocks = pd.read_csv(DIRTY_FILE_NAME)\n",
    "    print(dowjones_stocks.head())\n",
    "else:\n",
    "    print(\"Error: Input file not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The S&P 500 stock price dataset contains a number of null records typically during holidays or weekends, which are days when the stock market is closed. To clean this dataset, we will simply remove all null records. Due to the missing dates, it should be noted that the stock price forecasting model will not predict stock prices for each subsequent days. Rather, we should assume that the forecasting model will predict stock prices for the next subsequent day in which the stock price would typically be observed and recorded (i.e. non-weekends and non-holidays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-09-18</td>\n",
       "      <td>1485.25</td>\n",
       "      <td>1489.75</td>\n",
       "      <td>1462.25</td>\n",
       "      <td>1467.50</td>\n",
       "      <td>1467.50</td>\n",
       "      <td>104794.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-09-19</td>\n",
       "      <td>1467.00</td>\n",
       "      <td>1482.75</td>\n",
       "      <td>1466.75</td>\n",
       "      <td>1478.50</td>\n",
       "      <td>1478.50</td>\n",
       "      <td>103371.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-09-20</td>\n",
       "      <td>1478.75</td>\n",
       "      <td>1480.50</td>\n",
       "      <td>1450.25</td>\n",
       "      <td>1469.50</td>\n",
       "      <td>1469.50</td>\n",
       "      <td>109667.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-09-21</td>\n",
       "      <td>1470.25</td>\n",
       "      <td>1474.00</td>\n",
       "      <td>1455.50</td>\n",
       "      <td>1469.50</td>\n",
       "      <td>1469.50</td>\n",
       "      <td>98528.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-09-22</td>\n",
       "      <td>1454.75</td>\n",
       "      <td>1471.00</td>\n",
       "      <td>1436.75</td>\n",
       "      <td>1468.50</td>\n",
       "      <td>1468.50</td>\n",
       "      <td>97416.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6189</th>\n",
       "      <td>2020-11-16</td>\n",
       "      <td>3587.00</td>\n",
       "      <td>3637.00</td>\n",
       "      <td>3586.50</td>\n",
       "      <td>3623.00</td>\n",
       "      <td>3623.00</td>\n",
       "      <td>1303941.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6190</th>\n",
       "      <td>2020-11-17</td>\n",
       "      <td>3625.50</td>\n",
       "      <td>3630.00</td>\n",
       "      <td>3584.25</td>\n",
       "      <td>3606.75</td>\n",
       "      <td>3606.75</td>\n",
       "      <td>1268206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6191</th>\n",
       "      <td>2020-11-18</td>\n",
       "      <td>3604.50</td>\n",
       "      <td>3623.25</td>\n",
       "      <td>3556.50</td>\n",
       "      <td>3565.00</td>\n",
       "      <td>3565.00</td>\n",
       "      <td>1325309.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6192</th>\n",
       "      <td>2020-11-19</td>\n",
       "      <td>3562.00</td>\n",
       "      <td>3582.75</td>\n",
       "      <td>3542.25</td>\n",
       "      <td>3580.00</td>\n",
       "      <td>3580.00</td>\n",
       "      <td>1291117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6193</th>\n",
       "      <td>2020-11-20</td>\n",
       "      <td>3560.00</td>\n",
       "      <td>3582.50</td>\n",
       "      <td>3542.75</td>\n",
       "      <td>3554.25</td>\n",
       "      <td>3554.25</td>\n",
       "      <td>1189621.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5131 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date     Open     High      Low    Close  Adj Close     Volume\n",
       "0     2000-09-18  1485.25  1489.75  1462.25  1467.50    1467.50   104794.0\n",
       "1     2000-09-19  1467.00  1482.75  1466.75  1478.50    1478.50   103371.0\n",
       "2     2000-09-20  1478.75  1480.50  1450.25  1469.50    1469.50   109667.0\n",
       "3     2000-09-21  1470.25  1474.00  1455.50  1469.50    1469.50    98528.0\n",
       "4     2000-09-22  1454.75  1471.00  1436.75  1468.50    1468.50    97416.0\n",
       "...          ...      ...      ...      ...      ...        ...        ...\n",
       "6189  2020-11-16  3587.00  3637.00  3586.50  3623.00    3623.00  1303941.0\n",
       "6190  2020-11-17  3625.50  3630.00  3584.25  3606.75    3606.75  1268206.0\n",
       "6191  2020-11-18  3604.50  3623.25  3556.50  3565.00    3565.00  1325309.0\n",
       "6192  2020-11-19  3562.00  3582.75  3542.25  3580.00    3580.00  1291117.0\n",
       "6193  2020-11-20  3560.00  3582.50  3542.75  3554.25    3554.25  1189621.0\n",
       "\n",
       "[5131 rows x 7 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dowjones_stocks_cleaned = dowjones_stocks.loc[dowjones_stocks[\"Open\"].isnull() == False]\n",
    "dowjones_stocks_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there are any null values left in the dataset. There are none left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date         0\n",
       "Open         0\n",
       "High         0\n",
       "Low          0\n",
       "Close        0\n",
       "Adj Close    0\n",
       "Volume       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dowjones_stocks_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save cleaned data without the index column.\n",
    "dowjones_stocks_cleaned.to_csv(CLEAN_FILE_NAME, index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BREAK POINT 1: Data Cleaned and saved till here. Can begin from here if saved file is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Open     High      Low   Close  Adj Close    Volume\n",
      "Date                                                              \n",
      "2000-09-18  1485.25  1489.75  1462.25  1467.5     1467.5  104794.0\n",
      "2000-09-19  1467.00  1482.75  1466.75  1478.5     1478.5  103371.0\n",
      "2000-09-20  1478.75  1480.50  1450.25  1469.5     1469.5  109667.0\n",
      "2000-09-21  1470.25  1474.00  1455.50  1469.5     1469.5   98528.0\n",
      "2000-09-22  1454.75  1471.00  1436.75  1468.5     1468.5   97416.0\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(CLEAN_FILE_NAME):\n",
    "    dowjones_stocks_cleaned = pd.read_csv(CLEAN_FILE_NAME,index_col=['Date'])\n",
    "    print(dowjones_stocks_cleaned.head())\n",
    "else:\n",
    "    print(\"Error: Clean File not found. Restart from the beginning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Data\n",
    "\n",
    "We have 10 years worth of data. Will use 9 years of data to predict the last year.\n",
    "Will break the data down into weekly data and then use that to predict the daily closing price for each day a for a week. We will also remove the \"Adjusted Close\" column as it is the same as the \"Close\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-09-18</th>\n",
       "      <td>1485.25</td>\n",
       "      <td>1489.75</td>\n",
       "      <td>1462.25</td>\n",
       "      <td>1467.50</td>\n",
       "      <td>104794.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-09-19</th>\n",
       "      <td>1467.00</td>\n",
       "      <td>1482.75</td>\n",
       "      <td>1466.75</td>\n",
       "      <td>1478.50</td>\n",
       "      <td>103371.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-09-20</th>\n",
       "      <td>1478.75</td>\n",
       "      <td>1480.50</td>\n",
       "      <td>1450.25</td>\n",
       "      <td>1469.50</td>\n",
       "      <td>109667.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-09-21</th>\n",
       "      <td>1470.25</td>\n",
       "      <td>1474.00</td>\n",
       "      <td>1455.50</td>\n",
       "      <td>1469.50</td>\n",
       "      <td>98528.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-09-22</th>\n",
       "      <td>1454.75</td>\n",
       "      <td>1471.00</td>\n",
       "      <td>1436.75</td>\n",
       "      <td>1468.50</td>\n",
       "      <td>97416.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-16</th>\n",
       "      <td>3587.00</td>\n",
       "      <td>3637.00</td>\n",
       "      <td>3586.50</td>\n",
       "      <td>3623.00</td>\n",
       "      <td>1303941.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-17</th>\n",
       "      <td>3625.50</td>\n",
       "      <td>3630.00</td>\n",
       "      <td>3584.25</td>\n",
       "      <td>3606.75</td>\n",
       "      <td>1268206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-18</th>\n",
       "      <td>3604.50</td>\n",
       "      <td>3623.25</td>\n",
       "      <td>3556.50</td>\n",
       "      <td>3565.00</td>\n",
       "      <td>1325309.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-19</th>\n",
       "      <td>3562.00</td>\n",
       "      <td>3582.75</td>\n",
       "      <td>3542.25</td>\n",
       "      <td>3580.00</td>\n",
       "      <td>1291117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-20</th>\n",
       "      <td>3560.00</td>\n",
       "      <td>3582.50</td>\n",
       "      <td>3542.75</td>\n",
       "      <td>3554.25</td>\n",
       "      <td>1189621.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5131 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Open     High      Low    Close     Volume\n",
       "Date                                                     \n",
       "2000-09-18  1485.25  1489.75  1462.25  1467.50   104794.0\n",
       "2000-09-19  1467.00  1482.75  1466.75  1478.50   103371.0\n",
       "2000-09-20  1478.75  1480.50  1450.25  1469.50   109667.0\n",
       "2000-09-21  1470.25  1474.00  1455.50  1469.50    98528.0\n",
       "2000-09-22  1454.75  1471.00  1436.75  1468.50    97416.0\n",
       "...             ...      ...      ...      ...        ...\n",
       "2020-11-16  3587.00  3637.00  3586.50  3623.00  1303941.0\n",
       "2020-11-17  3625.50  3630.00  3584.25  3606.75  1268206.0\n",
       "2020-11-18  3604.50  3623.25  3556.50  3565.00  1325309.0\n",
       "2020-11-19  3562.00  3582.75  3542.25  3580.00  1291117.0\n",
       "2020-11-20  3560.00  3582.50  3542.75  3554.25  1189621.0\n",
       "\n",
       "[5131 rows x 5 columns]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dowjones_stocks_cleaned_copy = dowjones_stocks_cleaned.copy()\n",
    "del dowjones_stocks_cleaned_copy[\"Adj Close\"]\n",
    "dowjones_stocks_cleaned_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length= 5131\n",
      "Total Weeks= 1026\n",
      "-----TRAIN DATA-----\n",
      "Length= 4871\n",
      "-----TEST DATA-----\n",
      "Length= 260\n",
      "[  1485.25   1489.75   1462.25   1467.5  104794.  ]\n",
      "[   3237.      3261.75    3234.25    3259.   1416241.  ]\n"
     ]
    }
   ],
   "source": [
    "def split(dataset):\n",
    "    dataset = dataset.values\n",
    "    length = len(dataset)\n",
    "    print(\"Length=\",length)\n",
    "    total_weeks = int(length/5)\n",
    "    print(\"Total Weeks=\",total_weeks)\n",
    "    \n",
    "    #use last 1 year as test data set, everything else as train dataset\n",
    "    WEEKS_IN_ONE_YEAR = 52\n",
    "    ONE_YEAR_WORK_DAYS = 5*52\n",
    "    \n",
    "    train = dataset[0:-ONE_YEAR_WORK_DAYS]\n",
    "    test = dataset[-ONE_YEAR_WORK_DAYS:]\n",
    "    \n",
    "    #convert to array\n",
    "    train = np.array(train)\n",
    "    test = np.array(test)\n",
    "    \n",
    "    print(\"-----TRAIN DATA-----\")\n",
    "    print(\"Length=\",len(train))\n",
    "    print(\"-----TEST DATA-----\")\n",
    "    print(\"Length=\",len(test))\n",
    "    print(train[0])\n",
    "    print(test[0])\n",
    "    return train,test\n",
    "    \n",
    "train_data,test_data = split(dowjones_stocks_cleaned_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What to predict?\n",
    "Use 15 days of the available data with features Open Price, High, Low, Close, and Volume to predict the next 5 days of Close Price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_TO_PREDICT = 3 #Closing cost for the day\n",
    "NUMBER_OF_DAYS_DATA_TO_USE = 15\n",
    "NUMBER_OF_DAYS_DATA_TO_PREDICT = 5\n",
    "NUMBER_OF_COLUMNS = train_data.shape[1]\n",
    "\n",
    "#split the given data into inputs and outputs. We can use last 7 days data to predict the next day \n",
    "# or we can use monthly data to predict. It depends onm how we want to model the data\n",
    "# and will experiment with various models\n",
    "#if column_with_result is None, then trying to make data for validation\n",
    "def convert_data_into_io(input_data, steps, column_with_result, num_of_days_to_predict):\n",
    "    print(column_with_result)\n",
    "    x,y = list(), list()\n",
    "    \n",
    "    for i in range(len(input_data)):\n",
    "        end = i + steps\n",
    "        if end+1 > len(input_data) or end+num_of_days_to_predict > len(input_data):\n",
    "            break\n",
    "        \n",
    "        _x = input_data[i:end,]\n",
    "        \n",
    "        _y = input_data[end:end+num_of_days_to_predict,column_with_result]\n",
    "        \n",
    "        y.append(_y)\n",
    "        x.append(_x)\n",
    "        \n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "------------------------\n",
      "Total Train Data: 4852\n",
      "Sample Train Input Data:\n",
      "[[  1485.25   1489.75   1462.25   1467.5  104794.  ]\n",
      " [  1467.     1482.75   1466.75   1478.5  103371.  ]\n",
      " [  1478.75   1480.5    1450.25   1469.5  109667.  ]\n",
      " [  1470.25   1474.     1455.5    1469.5   98528.  ]\n",
      " [  1454.75   1471.     1436.75   1468.5   97416.  ]\n",
      " [  1469.5    1477.75   1455.5    1461.    85491.  ]\n",
      " [  1461.     1467.     1442.5    1443.    99803.  ]\n",
      " [  1444.     1456.     1438.25   1446.75 101996.  ]\n",
      " [  1447.75   1481.     1445.     1476.    84280.  ]\n",
      " [  1473.     1473.25   1454.     1454.    78277.  ]\n",
      " [  1453.75   1464.25   1447.5    1456.25  84100.  ]\n",
      " [  1457.25   1474.     1438.75   1441.5   89440.  ]\n",
      " [  1442.     1457.25   1432.5    1450.25 101607.  ]\n",
      " [  1449.5    1462.     1447.25   1456.    92232.  ]\n",
      " [  1456.     1460.5    1411.5    1426.25  95257.  ]]\n",
      "Sample Train Output Data:\n",
      "[1416.5  1391.   1378.5  1344.   1386.25]\n",
      "------------------------\n",
      "3\n",
      "------------------------\n",
      "Total Test Data: 241\n",
      "Sample Test Input Data:\n",
      "[[   3237.      3261.75    3234.25    3259.   1416241.  ]\n",
      " [   3261.      3263.5     3206.75    3235.5  1755057.  ]\n",
      " [   3220.25    3223.75    3216.25    3222.   1002909.  ]\n",
      " [   3220.25    3249.5     3208.75    3243.5  1502748.  ]\n",
      " [   3243.5     3254.5     3226.      3235.25 1293494.  ]\n",
      " [   3231.75    3267.75    3181.      3260.25 2279138.  ]\n",
      " [   3261.25    3276.75    3257.75    3276.   1297679.  ]\n",
      " [   3275.5     3287.      3260.75    3264.75 1533121.  ]\n",
      " [   3265.75    3271.5     3265.5     3270.25  304502.  ]\n",
      " [   3265.75    3291.      3265.5     3289.75 1008998.  ]\n",
      " [   3289.25    3296.75    3275.25    3288.   1694799.  ]\n",
      " [   3287.75    3299.      3277.75    3293.75 1468347.  ]\n",
      " [   3294.25    3318.      3294.      3316.5  1335246.  ]\n",
      " [   3316.75    3330.25    3316.      3325.   1312253.  ]\n",
      " [   3325.      3327.75    3323.25    3327.75  340135.  ]]\n",
      "Sample Test Output Data:\n",
      "[3319.5  3319.75 3326.   3293.5  3258.5 ]\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "train_x,train_y = convert_data_into_io(train_data,NUMBER_OF_DAYS_DATA_TO_USE,COLUMN_TO_PREDICT,NUMBER_OF_DAYS_DATA_TO_PREDICT)\n",
    "print(\"------------------------\")\n",
    "print(\"Total Train Data:\", len(train_x))\n",
    "print(\"Sample Train Input Data:\")\n",
    "print(train_x[0])\n",
    "print(\"Sample Train Output Data:\")\n",
    "print(train_y[0])\n",
    "print(\"------------------------\")\n",
    "\n",
    "test_x,test_y = convert_data_into_io(test_data,NUMBER_OF_DAYS_DATA_TO_USE,COLUMN_TO_PREDICT,NUMBER_OF_DAYS_DATA_TO_PREDICT)\n",
    "print(\"------------------------\")\n",
    "print(\"Total Test Data:\", len(test_x))\n",
    "print(\"Sample Test Input Data:\")\n",
    "print(test_x[0])\n",
    "print(\"Sample Test Output Data:\")\n",
    "print(test_y[0])\n",
    "print(\"-------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model (2000 Epochs with ADAM)\n",
    "Creating a 5 day closing stock price forecasting model with LSTM with 2000 epochs using adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of epochs and optimizer\n",
    "epochs = 2000\n",
    "optimizer = \"adam\"\n",
    "\n",
    "# Number of features\n",
    "num_features = train_x.shape[2]\n",
    "\n",
    "# name of model and history \n",
    "model_name_1 = \"stock_model_1.h5\"\n",
    "history_name_1 = \"stock_model_history_1.csv\"\n",
    "\n",
    "# The model\n",
    "def stock_model(num_features, epochs, opt, model_name, history_name):\n",
    "    stock_model = keras.Sequential()\n",
    "    stock_model.add(LSTM(100, activation='relu', return_sequences=False, input_shape=(NUMBER_OF_DAYS_DATA_TO_USE, num_features)))\n",
    "    stock_model.add(Dense(NUMBER_OF_DAYS_DATA_TO_PREDICT))\n",
    "\n",
    "    print(stock_model.summary())\n",
    "    \n",
    "    stock_model.compile(optimizer=opt, loss='mae')\n",
    "    stock_model_history = stock_model.fit(train_x, train_y, epochs=epochs, validation_data=(test_x, test_y))\n",
    "    \n",
    "    stock_model.save(model_name)\n",
    "\n",
    "    pd.DataFrame(stock_model_history.history).to_csv(history_name)\n",
    "    \n",
    "    return stock_model, stock_model_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the forecasting model with 2000 epochs if it exists. If not, run the forecasting model and fit a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model not Found. Fitting model...\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 100)               42400     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 42,905\n",
      "Trainable params: 42,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2000\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 59539.6914 - val_loss: 39544.9805\n",
      "Epoch 2/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22573.1191 - val_loss: 10981.3018\n",
      "Epoch 3/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 10430.2861 - val_loss: 24568.5664\n",
      "Epoch 4/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 12156.4316 - val_loss: 10070.1289\n",
      "Epoch 5/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3666.2095 - val_loss: 5961.0840\n",
      "Epoch 6/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2458.1694 - val_loss: 4584.9609\n",
      "Epoch 7/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1873.7556 - val_loss: 4823.5938\n",
      "Epoch 8/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1615.3993 - val_loss: 4690.8809\n",
      "Epoch 9/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1518.8781 - val_loss: 4880.8071\n",
      "Epoch 10/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1341.3822 - val_loss: 3870.8245\n",
      "Epoch 11/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1108.0758 - val_loss: 3189.6619\n",
      "Epoch 12/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 924.6288 - val_loss: 3153.8665\n",
      "Epoch 13/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 911.7449 - val_loss: 2512.5891\n",
      "Epoch 14/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 715.5096 - val_loss: 2081.2625\n",
      "Epoch 15/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 660.9213 - val_loss: 2120.8857\n",
      "Epoch 16/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 618.4139 - val_loss: 1650.2111\n",
      "Epoch 17/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 943.4944 - val_loss: 1954.3618\n",
      "Epoch 18/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 794.4361 - val_loss: 2106.0969\n",
      "Epoch 19/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 813.3933 - val_loss: 1428.3430\n",
      "Epoch 20/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 677.6494 - val_loss: 1258.3926\n",
      "Epoch 21/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 845.1962 - val_loss: 1400.7504\n",
      "Epoch 22/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 714.2289 - val_loss: 1116.3732\n",
      "Epoch 23/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 842.8857 - val_loss: 961.7222\n",
      "Epoch 24/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 852.3812 - val_loss: 725.9621\n",
      "Epoch 25/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 581.5574 - val_loss: 775.8569\n",
      "Epoch 26/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 669.6031 - val_loss: 947.0629\n",
      "Epoch 27/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 996.5786 - val_loss: 1327.9159\n",
      "Epoch 28/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 694.3689 - val_loss: 727.5264\n",
      "Epoch 29/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 514.8079 - val_loss: 617.0585\n",
      "Epoch 30/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 614.4794 - val_loss: 806.2493\n",
      "Epoch 31/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 656.3387 - val_loss: 1281.2092\n",
      "Epoch 32/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 638.2178 - val_loss: 1047.7632\n",
      "Epoch 33/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 652.6072 - val_loss: 835.4131\n",
      "Epoch 34/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 542.9371 - val_loss: 532.7274\n",
      "Epoch 35/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 618.5723 - val_loss: 1084.4111\n",
      "Epoch 36/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 524.6301 - val_loss: 1304.2203\n",
      "Epoch 37/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 613.6963 - val_loss: 431.3710\n",
      "Epoch 38/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 440.4207 - val_loss: 675.0106\n",
      "Epoch 39/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 526.7654 - val_loss: 555.2200\n",
      "Epoch 40/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 647.3042 - val_loss: 799.8102\n",
      "Epoch 41/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 502.1500 - val_loss: 786.5079\n",
      "Epoch 42/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 537.5522 - val_loss: 788.0021\n",
      "Epoch 43/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 425.6570 - val_loss: 509.6672\n",
      "Epoch 44/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 481.0581 - val_loss: 458.5402\n",
      "Epoch 45/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 418.7807 - val_loss: 451.2055\n",
      "Epoch 46/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 414.2688 - val_loss: 669.3177\n",
      "Epoch 47/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 426.8470 - val_loss: 565.0856\n",
      "Epoch 48/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 440.8969 - val_loss: 400.4922\n",
      "Epoch 49/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 328.6146 - val_loss: 513.8687\n",
      "Epoch 50/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 442.5819 - val_loss: 725.1425\n",
      "Epoch 51/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 368.1107 - val_loss: 687.8107\n",
      "Epoch 52/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 354.3033 - val_loss: 428.5806\n",
      "Epoch 53/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 380.5334 - val_loss: 458.0838\n",
      "Epoch 54/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 312.7574 - val_loss: 429.6651\n",
      "Epoch 55/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 396.6826 - val_loss: 677.8406\n",
      "Epoch 56/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 409.4503 - val_loss: 749.1174\n",
      "Epoch 57/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 413.2430 - val_loss: 759.3310\n",
      "Epoch 58/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 317.1490 - val_loss: 494.9745\n",
      "Epoch 59/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 388.2035 - val_loss: 2241.0051\n",
      "Epoch 60/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 362.4407 - val_loss: 562.4623\n",
      "Epoch 61/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 323.6684 - val_loss: 576.3286\n",
      "Epoch 62/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 454.3030 - val_loss: 828.8539\n",
      "Epoch 63/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 364.7057 - val_loss: 443.0714\n",
      "Epoch 64/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 270.4527 - val_loss: 578.7598\n",
      "Epoch 65/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 404.0623 - val_loss: 485.4444\n",
      "Epoch 66/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 365.7828 - val_loss: 563.8678\n",
      "Epoch 67/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 330.3988 - val_loss: 879.5716\n",
      "Epoch 68/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 314.6084 - val_loss: 593.6698\n",
      "Epoch 69/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 333.5008 - val_loss: 272.7124\n",
      "Epoch 70/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 250.8534 - val_loss: 282.8667\n",
      "Epoch 71/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 273.9374 - val_loss: 316.5369\n",
      "Epoch 72/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 260.7020 - val_loss: 422.8561\n",
      "Epoch 73/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 281.8088 - val_loss: 977.2336\n",
      "Epoch 74/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 327.7099 - val_loss: 302.9370\n",
      "Epoch 75/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 245.2520 - val_loss: 591.9403\n",
      "Epoch 76/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 267.6151 - val_loss: 338.8465\n",
      "Epoch 77/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 221.5157 - val_loss: 629.9173\n",
      "Epoch 78/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 274.3900 - val_loss: 537.1777\n",
      "Epoch 79/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 192.2340 - val_loss: 1333.2941\n",
      "Epoch 80/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 241.3533 - val_loss: 426.4244\n",
      "Epoch 81/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 259.2292 - val_loss: 404.0971\n",
      "Epoch 82/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 205.2689 - val_loss: 273.5253\n",
      "Epoch 83/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 224.2851 - val_loss: 260.2735\n",
      "Epoch 84/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 185.5869 - val_loss: 436.3733\n",
      "Epoch 85/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 240.7636 - val_loss: 277.2404\n",
      "Epoch 86/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 193.8690 - val_loss: 265.8509\n",
      "Epoch 87/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 226.9764 - val_loss: 527.4423\n",
      "Epoch 88/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 173.9063 - val_loss: 261.3972\n",
      "Epoch 89/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 178.4303 - val_loss: 351.6359\n",
      "Epoch 90/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 168.5849 - val_loss: 176.8362\n",
      "Epoch 91/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 159.0338 - val_loss: 270.8988\n",
      "Epoch 92/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 166.7126 - val_loss: 313.6045\n",
      "Epoch 93/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 193.6750 - val_loss: 433.7393\n",
      "Epoch 94/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 199.9137 - val_loss: 365.4822\n",
      "Epoch 95/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 162.4714 - val_loss: 396.9730\n",
      "Epoch 96/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 169.7191 - val_loss: 427.8973\n",
      "Epoch 97/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 186.0616 - val_loss: 172.8863\n",
      "Epoch 98/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 134.0860 - val_loss: 188.6575\n",
      "Epoch 99/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 174.6320 - val_loss: 201.9334\n",
      "Epoch 100/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 157.4148 - val_loss: 161.1011\n",
      "Epoch 101/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 158.0552 - val_loss: 240.8651\n",
      "Epoch 102/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 139.7249 - val_loss: 255.3545\n",
      "Epoch 103/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 158.5736 - val_loss: 283.5583\n",
      "Epoch 104/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 173.2159 - val_loss: 202.2531\n",
      "Epoch 105/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 148.8408 - val_loss: 162.6427\n",
      "Epoch 106/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 175.9169 - val_loss: 252.4040\n",
      "Epoch 107/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 147.0334 - val_loss: 175.0786\n",
      "Epoch 108/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 149.0513 - val_loss: 192.3039\n",
      "Epoch 109/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 151.4803 - val_loss: 209.6666\n",
      "Epoch 110/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 138.3750 - val_loss: 208.1490\n",
      "Epoch 111/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 120.6855 - val_loss: 310.3483\n",
      "Epoch 112/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 122.3228 - val_loss: 320.6809\n",
      "Epoch 113/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 187.7095 - val_loss: 180.4392\n",
      "Epoch 114/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 124.0876 - val_loss: 246.9737\n",
      "Epoch 115/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 135.3654 - val_loss: 208.9245\n",
      "Epoch 116/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 117.3864 - val_loss: 267.3041\n",
      "Epoch 117/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 141.0656 - val_loss: 198.9757\n",
      "Epoch 118/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 118.7445 - val_loss: 185.2921\n",
      "Epoch 119/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 124.8558 - val_loss: 231.2504\n",
      "Epoch 120/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 134.7402 - val_loss: 241.8943\n",
      "Epoch 121/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 127.5778 - val_loss: 163.8107\n",
      "Epoch 122/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 129.0023 - val_loss: 115.0690\n",
      "Epoch 123/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 116.0937 - val_loss: 160.8754\n",
      "Epoch 124/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 134.7131 - val_loss: 203.5766\n",
      "Epoch 125/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 123.0351 - val_loss: 206.3095\n",
      "Epoch 126/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 113.9272 - val_loss: 210.9265\n",
      "Epoch 127/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 132.9110 - val_loss: 144.3009\n",
      "Epoch 128/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 109.4510 - val_loss: 111.2484\n",
      "Epoch 129/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 126.6327 - val_loss: 157.4103\n",
      "Epoch 130/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 134.1863 - val_loss: 199.8647\n",
      "Epoch 131/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 98.0707 - val_loss: 123.8824\n",
      "Epoch 132/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 78.2200 - val_loss: 131.3622\n",
      "Epoch 133/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 100.7953 - val_loss: 161.9635\n",
      "Epoch 134/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 92.5903 - val_loss: 143.5583\n",
      "Epoch 135/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 83.6467 - val_loss: 117.2700\n",
      "Epoch 136/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 77.5891 - val_loss: 204.0694\n",
      "Epoch 137/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 90.6454 - val_loss: 148.5276\n",
      "Epoch 138/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 81.2679 - val_loss: 130.3916\n",
      "Epoch 139/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 98.2744 - val_loss: 122.0489\n",
      "Epoch 140/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 74.8418 - val_loss: 143.3345\n",
      "Epoch 141/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 78.4357 - val_loss: 176.0099\n",
      "Epoch 142/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 71.0648 - val_loss: 99.2602\n",
      "Epoch 143/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 71.1447 - val_loss: 105.3970\n",
      "Epoch 144/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 61.1385 - val_loss: 106.4771\n",
      "Epoch 145/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 81.4450 - val_loss: 124.8703\n",
      "Epoch 146/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 63.7806 - val_loss: 135.0742\n",
      "Epoch 147/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 73.4825 - val_loss: 116.1869\n",
      "Epoch 148/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 79.9666 - val_loss: 92.1272\n",
      "Epoch 149/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 70.6740 - val_loss: 90.3144\n",
      "Epoch 150/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 53.4077 - val_loss: 101.4383\n",
      "Epoch 151/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 61.9404 - val_loss: 84.4589\n",
      "Epoch 152/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 67.3647 - val_loss: 129.7594\n",
      "Epoch 153/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 54.9122 - val_loss: 128.3033\n",
      "Epoch 154/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.0460 - val_loss: 100.9229\n",
      "Epoch 155/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 64.3760 - val_loss: 198.8762\n",
      "Epoch 156/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 63.8012 - val_loss: 138.2949\n",
      "Epoch 157/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 59.4093 - val_loss: 92.7316\n",
      "Epoch 158/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.6939 - val_loss: 104.5834\n",
      "Epoch 159/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 60.1210 - val_loss: 82.9193\n",
      "Epoch 160/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.4339 - val_loss: 93.2162\n",
      "Epoch 161/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 35.9120 - val_loss: 180.6948\n",
      "Epoch 162/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 63.8591 - val_loss: 157.4166\n",
      "Epoch 163/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 45.1621 - val_loss: 102.7345\n",
      "Epoch 164/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.7950 - val_loss: 77.1814\n",
      "Epoch 165/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 42.4293 - val_loss: 96.8459\n",
      "Epoch 166/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 42.3594 - val_loss: 82.9858\n",
      "Epoch 167/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 37.8513 - val_loss: 84.9748\n",
      "Epoch 168/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 39.1436 - val_loss: 80.5947\n",
      "Epoch 169/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 34.5347 - val_loss: 95.9261\n",
      "Epoch 170/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.9343 - val_loss: 97.5021\n",
      "Epoch 171/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 37.6092 - val_loss: 78.2544\n",
      "Epoch 172/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 34.8015 - val_loss: 80.1969\n",
      "Epoch 173/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 38.0573 - val_loss: 95.7758\n",
      "Epoch 174/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 37.5197 - val_loss: 77.1816\n",
      "Epoch 175/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 33.1478 - val_loss: 98.2677\n",
      "Epoch 176/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 38.8448 - val_loss: 79.9057\n",
      "Epoch 177/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 32.8335 - val_loss: 93.4029\n",
      "Epoch 178/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 32.3255 - val_loss: 73.3414\n",
      "Epoch 179/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.5229 - val_loss: 101.4208\n",
      "Epoch 180/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 33.0157 - val_loss: 79.2555\n",
      "Epoch 181/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.6280 - val_loss: 72.0324\n",
      "Epoch 182/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.3943 - val_loss: 90.8253\n",
      "Epoch 183/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.4893 - val_loss: 77.8164\n",
      "Epoch 184/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.6839 - val_loss: 83.0085\n",
      "Epoch 185/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.5332 - val_loss: 74.6177\n",
      "Epoch 186/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5505 - val_loss: 78.6128\n",
      "Epoch 187/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.3191 - val_loss: 75.3236\n",
      "Epoch 188/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.6667 - val_loss: 79.6430\n",
      "Epoch 189/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6239 - val_loss: 77.2282\n",
      "Epoch 190/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.1743 - val_loss: 83.8614\n",
      "Epoch 191/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.7112 - val_loss: 75.0655\n",
      "Epoch 192/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.4315 - val_loss: 72.2130\n",
      "Epoch 193/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.0985 - val_loss: 73.5602\n",
      "Epoch 194/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5359 - val_loss: 91.1107\n",
      "Epoch 195/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.6147 - val_loss: 85.4947\n",
      "Epoch 196/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.6060 - val_loss: 72.4027\n",
      "Epoch 197/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 35.3291 - val_loss: 71.9483\n",
      "Epoch 198/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.5977 - val_loss: 77.8041\n",
      "Epoch 199/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.9386 - val_loss: 73.5838\n",
      "Epoch 200/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.8933 - val_loss: 77.9961\n",
      "Epoch 201/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1769 - val_loss: 72.2677\n",
      "Epoch 202/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.6860 - val_loss: 112.3406\n",
      "Epoch 203/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.3768 - val_loss: 74.2224\n",
      "Epoch 204/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8717 - val_loss: 70.8820\n",
      "Epoch 205/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8807 - val_loss: 70.6747\n",
      "Epoch 206/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6047 - val_loss: 71.5660\n",
      "Epoch 207/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.7224 - val_loss: 71.7233\n",
      "Epoch 208/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8660 - val_loss: 83.5419\n",
      "Epoch 209/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.4419 - val_loss: 77.9804\n",
      "Epoch 210/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1266 - val_loss: 69.8296\n",
      "Epoch 211/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6373 - val_loss: 70.4162\n",
      "Epoch 212/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.5473 - val_loss: 74.1745\n",
      "Epoch 213/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3530 - val_loss: 71.9383\n",
      "Epoch 214/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.8586 - val_loss: 96.4266\n",
      "Epoch 215/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7908 - val_loss: 69.7180\n",
      "Epoch 216/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 970.2640 - val_loss: 898.9465\n",
      "Epoch 217/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 377.0809 - val_loss: 579.2154\n",
      "Epoch 218/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 193.2350 - val_loss: 320.1244\n",
      "Epoch 219/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 145.1771 - val_loss: 270.3277\n",
      "Epoch 220/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 117.4493 - val_loss: 220.7643\n",
      "Epoch 221/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 109.8821 - val_loss: 214.7495\n",
      "Epoch 222/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 92.1250 - val_loss: 197.5272\n",
      "Epoch 223/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 82.2765 - val_loss: 186.0700\n",
      "Epoch 224/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 72.2360 - val_loss: 181.5716\n",
      "Epoch 225/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 68.8891 - val_loss: 180.1494\n",
      "Epoch 226/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 59.6781 - val_loss: 154.3316\n",
      "Epoch 227/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 56.0311 - val_loss: 154.4596\n",
      "Epoch 228/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 60.1278 - val_loss: 158.4207\n",
      "Epoch 229/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.9853 - val_loss: 144.8480\n",
      "Epoch 230/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.6278 - val_loss: 144.4753\n",
      "Epoch 231/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.8540 - val_loss: 147.5218\n",
      "Epoch 232/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.3406 - val_loss: 129.6383\n",
      "Epoch 233/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.2602 - val_loss: 150.8932\n",
      "Epoch 234/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 52.0236 - val_loss: 128.4168\n",
      "Epoch 235/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.1522 - val_loss: 146.4730\n",
      "Epoch 236/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.2268 - val_loss: 130.9104\n",
      "Epoch 237/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 38.5289 - val_loss: 139.2074\n",
      "Epoch 238/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 42.7644 - val_loss: 129.1209\n",
      "Epoch 239/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 42.4822 - val_loss: 155.0568\n",
      "Epoch 240/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.6478 - val_loss: 118.4231\n",
      "Epoch 241/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 52.5957 - val_loss: 162.9177\n",
      "Epoch 242/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 42.3790 - val_loss: 122.8724\n",
      "Epoch 243/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 40.2530 - val_loss: 109.9783\n",
      "Epoch 244/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6995 - val_loss: 163.7435\n",
      "Epoch 245/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 36.8902 - val_loss: 120.5594\n",
      "Epoch 246/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.4767 - val_loss: 126.2890\n",
      "Epoch 247/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 36.7217 - val_loss: 110.3323\n",
      "Epoch 248/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 40.4532 - val_loss: 114.7244\n",
      "Epoch 249/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 40.1537 - val_loss: 109.7278\n",
      "Epoch 250/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 39.3878 - val_loss: 114.5567\n",
      "Epoch 251/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.6437 - val_loss: 113.4988\n",
      "Epoch 252/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 38.6969 - val_loss: 110.1317\n",
      "Epoch 253/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 42.6491 - val_loss: 104.5733\n",
      "Epoch 254/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 34.3663 - val_loss: 106.5386\n",
      "Epoch 255/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 32.3039 - val_loss: 93.8500\n",
      "Epoch 256/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 34.7612 - val_loss: 104.5228\n",
      "Epoch 257/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 36.2554 - val_loss: 103.9197\n",
      "Epoch 258/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 33.8286 - val_loss: 105.7046\n",
      "Epoch 259/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 36.7068 - val_loss: 120.6671\n",
      "Epoch 260/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 35.0115 - val_loss: 102.5957\n",
      "Epoch 261/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 35.5262 - val_loss: 92.0535\n",
      "Epoch 262/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 34.4446 - val_loss: 106.0799\n",
      "Epoch 263/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 35.0228 - val_loss: 105.0811\n",
      "Epoch 264/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.7186 - val_loss: 91.0397\n",
      "Epoch 265/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 32.1487 - val_loss: 93.0300\n",
      "Epoch 266/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 63.6564 - val_loss: 90.1238\n",
      "Epoch 267/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 38.4623 - val_loss: 91.1935\n",
      "Epoch 268/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 33.6444 - val_loss: 81.2321\n",
      "Epoch 269/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 35.7736 - val_loss: 85.8253\n",
      "Epoch 270/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 35.2534 - val_loss: 82.4306\n",
      "Epoch 271/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 37.6930 - val_loss: 99.8810\n",
      "Epoch 272/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.9968 - val_loss: 86.3311\n",
      "Epoch 273/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.3897 - val_loss: 81.2022\n",
      "Epoch 274/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.3902 - val_loss: 78.5334\n",
      "Epoch 275/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.4159 - val_loss: 84.4460\n",
      "Epoch 276/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.4462 - val_loss: 101.0947\n",
      "Epoch 277/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.3295 - val_loss: 81.8713\n",
      "Epoch 278/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.0454 - val_loss: 82.0693\n",
      "Epoch 279/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 39.3093 - val_loss: 112.9404\n",
      "Epoch 280/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.9285 - val_loss: 79.0995\n",
      "Epoch 281/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.6261 - val_loss: 79.3539\n",
      "Epoch 282/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.9146 - val_loss: 80.3826\n",
      "Epoch 283/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.7501 - val_loss: 77.9284\n",
      "Epoch 284/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.7692 - val_loss: 96.2007\n",
      "Epoch 285/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2154 - val_loss: 104.8386\n",
      "Epoch 286/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.9529 - val_loss: 80.7632\n",
      "Epoch 287/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.0557 - val_loss: 80.9997\n",
      "Epoch 288/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5828 - val_loss: 74.8508\n",
      "Epoch 289/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 42.2263 - val_loss: 77.0693\n",
      "Epoch 290/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 26.0865 - val_loss: 75.2023\n",
      "Epoch 291/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 27.7235 - val_loss: 77.2597\n",
      "Epoch 292/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 27.0241 - val_loss: 79.8219\n",
      "Epoch 293/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1496 - val_loss: 75.3737\n",
      "Epoch 294/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.8580 - val_loss: 74.1540\n",
      "Epoch 295/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.2153 - val_loss: 79.2926\n",
      "Epoch 296/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 36.8622 - val_loss: 79.1595\n",
      "Epoch 297/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.3795 - val_loss: 78.4706\n",
      "Epoch 298/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.0919 - val_loss: 74.9726\n",
      "Epoch 299/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8550 - val_loss: 75.3543\n",
      "Epoch 300/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5429 - val_loss: 87.0711\n",
      "Epoch 301/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2101 - val_loss: 84.1768\n",
      "Epoch 302/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.1273 - val_loss: 76.4280\n",
      "Epoch 303/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.9069 - val_loss: 76.8619\n",
      "Epoch 304/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 32.6551 - val_loss: 87.7942\n",
      "Epoch 305/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 33.9899 - val_loss: 86.6134\n",
      "Epoch 306/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.3628 - val_loss: 81.7123\n",
      "Epoch 307/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.1225 - val_loss: 75.4264\n",
      "Epoch 308/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 34.1114 - val_loss: 93.6254\n",
      "Epoch 309/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 34.3072 - val_loss: 80.2638\n",
      "Epoch 310/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.3454 - val_loss: 72.9784\n",
      "Epoch 311/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.3935 - val_loss: 82.4990\n",
      "Epoch 312/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.9915 - val_loss: 73.9887\n",
      "Epoch 313/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.5196 - val_loss: 72.1168\n",
      "Epoch 314/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.6541 - val_loss: 71.7864\n",
      "Epoch 315/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0461 - val_loss: 74.2408\n",
      "Epoch 316/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.7621 - val_loss: 72.4943\n",
      "Epoch 317/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5943 - val_loss: 73.3147\n",
      "Epoch 318/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 32.7594 - val_loss: 83.1172\n",
      "Epoch 319/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.7221 - val_loss: 74.2430\n",
      "Epoch 320/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.5818 - val_loss: 81.2489\n",
      "Epoch 321/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.7416 - val_loss: 76.6113\n",
      "Epoch 322/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.2286 - val_loss: 76.2044\n",
      "Epoch 323/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2836 - val_loss: 94.8706\n",
      "Epoch 324/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 35.3046 - val_loss: 86.1307\n",
      "Epoch 325/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.9389 - val_loss: 109.3674\n",
      "Epoch 326/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.1622 - val_loss: 88.0891\n",
      "Epoch 327/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5764 - val_loss: 72.8399\n",
      "Epoch 328/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.6299 - val_loss: 83.5656\n",
      "Epoch 329/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.8351 - val_loss: 70.9385\n",
      "Epoch 330/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.0549 - val_loss: 71.4752\n",
      "Epoch 331/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.9600 - val_loss: 80.4732\n",
      "Epoch 332/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8564 - val_loss: 99.0121\n",
      "Epoch 333/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.6323 - val_loss: 88.6236\n",
      "Epoch 334/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.4031 - val_loss: 70.5574\n",
      "Epoch 335/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.4061 - val_loss: 72.6060\n",
      "Epoch 336/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.8704 - val_loss: 73.2437\n",
      "Epoch 337/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.8083 - val_loss: 71.0149\n",
      "Epoch 338/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 32.1814 - val_loss: 76.9312\n",
      "Epoch 339/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.0395 - val_loss: 101.2677\n",
      "Epoch 340/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.0398 - val_loss: 73.3232\n",
      "Epoch 341/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.0114 - val_loss: 84.0728\n",
      "Epoch 342/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7392 - val_loss: 69.8225\n",
      "Epoch 343/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 36.6775 - val_loss: 71.6090\n",
      "Epoch 344/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.9563 - val_loss: 77.6020\n",
      "Epoch 345/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.4252 - val_loss: 87.3356\n",
      "Epoch 346/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.5554 - val_loss: 76.3408\n",
      "Epoch 347/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.0981 - val_loss: 89.2907\n",
      "Epoch 348/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.6787 - val_loss: 75.1369\n",
      "Epoch 349/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.4850 - val_loss: 72.2933\n",
      "Epoch 350/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.8953 - val_loss: 113.1581\n",
      "Epoch 351/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.3370 - val_loss: 73.8563\n",
      "Epoch 352/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.4851 - val_loss: 73.5108\n",
      "Epoch 353/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 34.2450 - val_loss: 111.8414\n",
      "Epoch 354/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.0712 - val_loss: 74.2132\n",
      "Epoch 355/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.5270 - val_loss: 76.5515\n",
      "Epoch 356/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.7909 - val_loss: 71.1932\n",
      "Epoch 357/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.9437 - val_loss: 70.4828\n",
      "Epoch 358/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9024 - val_loss: 75.8876\n",
      "Epoch 359/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.7180 - val_loss: 73.0939\n",
      "Epoch 360/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.9592 - val_loss: 70.2613\n",
      "Epoch 361/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.4844 - val_loss: 80.4057\n",
      "Epoch 362/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6895 - val_loss: 69.9560\n",
      "Epoch 363/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.6887 - val_loss: 77.3309\n",
      "Epoch 364/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.3353 - val_loss: 70.5978\n",
      "Epoch 365/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.9444 - val_loss: 69.4200\n",
      "Epoch 366/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.6322 - val_loss: 80.2462\n",
      "Epoch 367/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.7348 - val_loss: 79.2333\n",
      "Epoch 368/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.7738 - val_loss: 72.1329\n",
      "Epoch 369/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.9181 - val_loss: 125.7207\n",
      "Epoch 370/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.0569 - val_loss: 73.7647\n",
      "Epoch 371/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 32.5811 - val_loss: 72.2612\n",
      "Epoch 372/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.7819 - val_loss: 70.1608\n",
      "Epoch 373/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.5314 - val_loss: 82.6005\n",
      "Epoch 374/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.3157 - val_loss: 84.5425\n",
      "Epoch 375/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.6001 - val_loss: 79.1620\n",
      "Epoch 376/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.0831 - val_loss: 71.3474\n",
      "Epoch 377/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.2114 - val_loss: 123.5702\n",
      "Epoch 378/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.9069 - val_loss: 76.3378\n",
      "Epoch 379/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.8211 - val_loss: 89.5529\n",
      "Epoch 380/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.2362 - val_loss: 100.4568\n",
      "Epoch 381/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.7542 - val_loss: 83.1995\n",
      "Epoch 382/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.6568 - val_loss: 79.0959\n",
      "Epoch 383/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8483 - val_loss: 86.3168\n",
      "Epoch 384/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.7588 - val_loss: 82.9436\n",
      "Epoch 385/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.8019 - val_loss: 70.2174\n",
      "Epoch 386/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5421 - val_loss: 72.5908\n",
      "Epoch 387/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9610 - val_loss: 70.3915\n",
      "Epoch 388/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7935 - val_loss: 79.9883\n",
      "Epoch 389/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 34.6128 - val_loss: 156.0880\n",
      "Epoch 390/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.7309 - val_loss: 97.3995\n",
      "Epoch 391/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.9560 - val_loss: 79.9111\n",
      "Epoch 392/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.2403 - val_loss: 74.7633\n",
      "Epoch 393/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2024 - val_loss: 76.1088\n",
      "Epoch 394/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2935 - val_loss: 72.8419\n",
      "Epoch 395/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.5341 - val_loss: 72.5781\n",
      "Epoch 396/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.2740 - val_loss: 90.8417\n",
      "Epoch 397/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.1668 - val_loss: 70.3092\n",
      "Epoch 398/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.7191 - val_loss: 70.9539\n",
      "Epoch 399/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2004 - val_loss: 69.2819\n",
      "Epoch 400/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 35.5691 - val_loss: 90.5389\n",
      "Epoch 401/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.9436 - val_loss: 68.8585\n",
      "Epoch 402/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1961 - val_loss: 76.1764\n",
      "Epoch 403/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.3026 - val_loss: 77.7021\n",
      "Epoch 404/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.3548 - val_loss: 70.6436\n",
      "Epoch 405/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.4559 - val_loss: 73.8025\n",
      "Epoch 406/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8549 - val_loss: 72.2286\n",
      "Epoch 407/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 34.3245 - val_loss: 71.2860\n",
      "Epoch 408/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.1268 - val_loss: 73.2968\n",
      "Epoch 409/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.0227 - val_loss: 71.5847\n",
      "Epoch 410/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6780 - val_loss: 72.2410\n",
      "Epoch 411/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.7877 - val_loss: 84.2978\n",
      "Epoch 412/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.6983 - val_loss: 79.0228\n",
      "Epoch 413/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8599 - val_loss: 69.6776\n",
      "Epoch 414/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.4350 - val_loss: 68.5042\n",
      "Epoch 415/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 32.0244 - val_loss: 69.5777\n",
      "Epoch 416/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.8715 - val_loss: 84.6459\n",
      "Epoch 417/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 32.3936 - val_loss: 69.9806\n",
      "Epoch 418/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1197 - val_loss: 83.5349\n",
      "Epoch 419/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8423 - val_loss: 82.4303\n",
      "Epoch 420/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 34.5649 - val_loss: 69.6265\n",
      "Epoch 421/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0899 - val_loss: 86.1724\n",
      "Epoch 422/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.2578 - val_loss: 72.9313\n",
      "Epoch 423/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9499 - val_loss: 71.1740\n",
      "Epoch 424/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.1304 - val_loss: 77.6198\n",
      "Epoch 425/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.9093 - val_loss: 74.6208\n",
      "Epoch 426/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.2014 - val_loss: 85.3981\n",
      "Epoch 427/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.4616 - val_loss: 68.8989\n",
      "Epoch 428/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.9608 - val_loss: 72.9707\n",
      "Epoch 429/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.1501 - val_loss: 85.7536\n",
      "Epoch 430/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.5656 - val_loss: 69.9003\n",
      "Epoch 431/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9983 - val_loss: 69.8875\n",
      "Epoch 432/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.8233 - val_loss: 67.8928\n",
      "Epoch 433/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.2085 - val_loss: 86.6777\n",
      "Epoch 434/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.3893 - val_loss: 80.6943\n",
      "Epoch 435/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.6435 - val_loss: 69.0719\n",
      "Epoch 436/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.7826 - val_loss: 69.5441\n",
      "Epoch 437/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4213 - val_loss: 71.8030\n",
      "Epoch 438/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.8355 - val_loss: 67.8426\n",
      "Epoch 439/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 32.3708 - val_loss: 74.4940\n",
      "Epoch 440/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.2883 - val_loss: 67.9339\n",
      "Epoch 441/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6406 - val_loss: 68.7081\n",
      "Epoch 442/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4702 - val_loss: 82.6240\n",
      "Epoch 443/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6607 - val_loss: 72.8606\n",
      "Epoch 444/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8841 - val_loss: 70.1003\n",
      "Epoch 445/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 35.2582 - val_loss: 71.9552\n",
      "Epoch 446/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.4235 - val_loss: 75.6447\n",
      "Epoch 447/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.2119 - val_loss: 74.7140\n",
      "Epoch 448/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.8750 - val_loss: 67.7882\n",
      "Epoch 449/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.9282 - val_loss: 69.9513\n",
      "Epoch 450/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1574 - val_loss: 71.1092\n",
      "Epoch 451/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.3617 - val_loss: 71.5749\n",
      "Epoch 452/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.4748 - val_loss: 90.8337\n",
      "Epoch 453/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.9718 - val_loss: 69.6228\n",
      "Epoch 454/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.0770 - val_loss: 70.1675\n",
      "Epoch 455/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 24.0451 - val_loss: 70.0302\n",
      "Epoch 456/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3480 - val_loss: 68.8889\n",
      "Epoch 457/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.8644 - val_loss: 77.2475\n",
      "Epoch 458/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 40.0357 - val_loss: 69.9264\n",
      "Epoch 459/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 34.1688 - val_loss: 72.6148\n",
      "Epoch 460/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.1653 - val_loss: 69.8210\n",
      "Epoch 461/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9531 - val_loss: 69.7966\n",
      "Epoch 462/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.3652 - val_loss: 82.7781\n",
      "Epoch 463/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.6278 - val_loss: 73.9957\n",
      "Epoch 464/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.7617 - val_loss: 68.5351\n",
      "Epoch 465/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3975 - val_loss: 68.1619\n",
      "Epoch 466/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.7058 - val_loss: 77.3118\n",
      "Epoch 467/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.1029 - val_loss: 68.4657\n",
      "Epoch 468/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.0533 - val_loss: 96.7036\n",
      "Epoch 469/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4633 - val_loss: 71.7459\n",
      "Epoch 470/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.7119 - val_loss: 69.1379\n",
      "Epoch 471/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9264 - val_loss: 69.0123\n",
      "Epoch 472/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.4674 - val_loss: 70.3890\n",
      "Epoch 473/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 29.6687 - val_loss: 99.1012\n",
      "Epoch 474/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.6400 - val_loss: 69.2889\n",
      "Epoch 475/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.3192 - val_loss: 72.0237\n",
      "Epoch 476/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.0448 - val_loss: 69.2020\n",
      "Epoch 477/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.0988 - val_loss: 73.6097\n",
      "Epoch 478/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.0161 - val_loss: 87.0132\n",
      "Epoch 479/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.2498 - val_loss: 72.9281\n",
      "Epoch 480/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.6660 - val_loss: 68.2284\n",
      "Epoch 481/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 34.2010 - val_loss: 74.1417\n",
      "Epoch 482/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.6284 - val_loss: 68.2684\n",
      "Epoch 483/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9100 - val_loss: 83.4573\n",
      "Epoch 484/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3932 - val_loss: 68.3112\n",
      "Epoch 485/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.3136 - val_loss: 88.9790\n",
      "Epoch 486/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7715 - val_loss: 72.5395\n",
      "Epoch 487/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.0223 - val_loss: 69.2425\n",
      "Epoch 488/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 34.9212 - val_loss: 94.3245\n",
      "Epoch 489/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.9504 - val_loss: 68.7969\n",
      "Epoch 490/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.4227 - val_loss: 77.2686\n",
      "Epoch 491/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3789 - val_loss: 68.8366\n",
      "Epoch 492/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.7339 - val_loss: 79.1300\n",
      "Epoch 493/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7692 - val_loss: 75.4621\n",
      "Epoch 494/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.3621 - val_loss: 67.8226\n",
      "Epoch 495/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.5312 - val_loss: 68.2426\n",
      "Epoch 496/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.5905 - val_loss: 75.7278\n",
      "Epoch 497/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5741 - val_loss: 70.6615\n",
      "Epoch 498/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.9406 - val_loss: 73.4441\n",
      "Epoch 499/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.9000 - val_loss: 96.8966\n",
      "Epoch 500/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0820 - val_loss: 72.7990\n",
      "Epoch 501/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.7532 - val_loss: 68.3254\n",
      "Epoch 502/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.0863 - val_loss: 95.1581\n",
      "Epoch 503/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.6883 - val_loss: 73.4054\n",
      "Epoch 504/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.1055 - val_loss: 78.4552\n",
      "Epoch 505/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 38.3238 - val_loss: 128.1379\n",
      "Epoch 506/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.9137 - val_loss: 68.7882\n",
      "Epoch 507/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.5229 - val_loss: 68.7398\n",
      "Epoch 508/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5002 - val_loss: 69.2403\n",
      "Epoch 509/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2789 - val_loss: 72.9036\n",
      "Epoch 510/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6800 - val_loss: 70.5953\n",
      "Epoch 511/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.7273 - val_loss: 85.8076\n",
      "Epoch 512/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7875 - val_loss: 71.4210\n",
      "Epoch 513/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5271 - val_loss: 70.7901\n",
      "Epoch 514/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.2700 - val_loss: 90.8566\n",
      "Epoch 515/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.6603 - val_loss: 70.1002\n",
      "Epoch 516/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.6929 - val_loss: 71.1338\n",
      "Epoch 517/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.6215 - val_loss: 70.7502\n",
      "Epoch 518/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2218 - val_loss: 68.3746\n",
      "Epoch 519/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.8938 - val_loss: 72.2897\n",
      "Epoch 520/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.5535 - val_loss: 74.8096\n",
      "Epoch 521/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2437 - val_loss: 72.2723\n",
      "Epoch 522/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.4048 - val_loss: 68.6912\n",
      "Epoch 523/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.3801 - val_loss: 72.4444\n",
      "Epoch 524/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.5127 - val_loss: 68.8243\n",
      "Epoch 525/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.2619 - val_loss: 78.5513\n",
      "Epoch 526/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7630 - val_loss: 69.6956\n",
      "Epoch 527/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.0845 - val_loss: 95.2389\n",
      "Epoch 528/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.9758 - val_loss: 78.9098\n",
      "Epoch 529/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.4049 - val_loss: 69.3908\n",
      "Epoch 530/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0611 - val_loss: 69.4321\n",
      "Epoch 531/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.1139 - val_loss: 85.8201\n",
      "Epoch 532/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.5808 - val_loss: 69.2790\n",
      "Epoch 533/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.3565 - val_loss: 71.4858\n",
      "Epoch 534/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1287 - val_loss: 76.6026\n",
      "Epoch 535/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7906 - val_loss: 70.5938\n",
      "Epoch 536/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.8555 - val_loss: 70.3227\n",
      "Epoch 537/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.4725 - val_loss: 72.8950\n",
      "Epoch 538/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.8223 - val_loss: 83.0357\n",
      "Epoch 539/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3096 - val_loss: 72.2908\n",
      "Epoch 540/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3549 - val_loss: 71.3354\n",
      "Epoch 541/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.8955 - val_loss: 76.5515\n",
      "Epoch 542/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.9080 - val_loss: 69.5896\n",
      "Epoch 543/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.9134 - val_loss: 71.3250\n",
      "Epoch 544/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 32.6194 - val_loss: 88.4528\n",
      "Epoch 545/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.9205 - val_loss: 69.9367\n",
      "Epoch 546/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.9056 - val_loss: 70.1093\n",
      "Epoch 547/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4397 - val_loss: 74.4125\n",
      "Epoch 548/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.0100 - val_loss: 68.7854\n",
      "Epoch 549/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.1573 - val_loss: 70.6453\n",
      "Epoch 550/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7131 - val_loss: 71.2249\n",
      "Epoch 551/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7798 - val_loss: 67.7103\n",
      "Epoch 552/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.4914 - val_loss: 90.5674\n",
      "Epoch 553/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.2312 - val_loss: 70.0956\n",
      "Epoch 554/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.5623 - val_loss: 82.3399\n",
      "Epoch 555/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5132 - val_loss: 75.2777\n",
      "Epoch 556/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.7030 - val_loss: 69.5619\n",
      "Epoch 557/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.1429 - val_loss: 68.8241\n",
      "Epoch 558/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9643 - val_loss: 74.7583\n",
      "Epoch 559/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.4721 - val_loss: 70.7744\n",
      "Epoch 560/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.5930 - val_loss: 83.2582\n",
      "Epoch 561/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0503 - val_loss: 78.9127\n",
      "Epoch 562/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.0658 - val_loss: 69.8144\n",
      "Epoch 563/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0238 - val_loss: 102.4681\n",
      "Epoch 564/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.0742 - val_loss: 83.7066\n",
      "Epoch 565/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.6293 - val_loss: 69.7685\n",
      "Epoch 566/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9861 - val_loss: 71.5224\n",
      "Epoch 567/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6550 - val_loss: 78.2736\n",
      "Epoch 568/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.8207 - val_loss: 72.7969\n",
      "Epoch 569/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2600 - val_loss: 69.1938\n",
      "Epoch 570/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.6648 - val_loss: 69.9581\n",
      "Epoch 571/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.7021 - val_loss: 69.3757\n",
      "Epoch 572/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.3218 - val_loss: 69.0413\n",
      "Epoch 573/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.5520 - val_loss: 69.5947\n",
      "Epoch 574/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.7635 - val_loss: 72.3751\n",
      "Epoch 575/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.1323 - val_loss: 67.8715\n",
      "Epoch 576/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.4905 - val_loss: 79.5347\n",
      "Epoch 577/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.0465 - val_loss: 69.5772\n",
      "Epoch 578/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.5820 - val_loss: 75.5229\n",
      "Epoch 579/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6657 - val_loss: 69.3230\n",
      "Epoch 580/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.1419 - val_loss: 67.8618\n",
      "Epoch 581/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5473 - val_loss: 71.5299\n",
      "Epoch 582/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.4655 - val_loss: 74.4945\n",
      "Epoch 583/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.2995 - val_loss: 68.7692\n",
      "Epoch 584/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7017 - val_loss: 76.0156\n",
      "Epoch 585/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.5707 - val_loss: 69.0834\n",
      "Epoch 586/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.9760 - val_loss: 69.8733\n",
      "Epoch 587/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.5646 - val_loss: 77.9579\n",
      "Epoch 588/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1578 - val_loss: 76.9755\n",
      "Epoch 589/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.5760 - val_loss: 69.9554\n",
      "Epoch 590/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8907 - val_loss: 71.2601\n",
      "Epoch 591/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.2150 - val_loss: 89.7990\n",
      "Epoch 592/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1870 - val_loss: 70.2744\n",
      "Epoch 593/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8669 - val_loss: 69.8121\n",
      "Epoch 594/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1328 - val_loss: 68.1939\n",
      "Epoch 595/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.4220 - val_loss: 68.3020\n",
      "Epoch 596/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1812 - val_loss: 70.6354\n",
      "Epoch 597/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9321 - val_loss: 72.4091\n",
      "Epoch 598/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.9839 - val_loss: 69.3712\n",
      "Epoch 599/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8655 - val_loss: 71.4939\n",
      "Epoch 600/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1197 - val_loss: 68.7487\n",
      "Epoch 601/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1297 - val_loss: 71.0286\n",
      "Epoch 602/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6073 - val_loss: 78.7378\n",
      "Epoch 603/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.0860 - val_loss: 72.4907\n",
      "Epoch 604/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.2473 - val_loss: 79.7760\n",
      "Epoch 605/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2905 - val_loss: 73.6662\n",
      "Epoch 606/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.5116 - val_loss: 80.7645\n",
      "Epoch 607/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.8092 - val_loss: 68.6503\n",
      "Epoch 608/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7029 - val_loss: 68.3565\n",
      "Epoch 609/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 24.2774 - val_loss: 67.5246\n",
      "Epoch 610/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7812 - val_loss: 74.6693\n",
      "Epoch 611/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.9748 - val_loss: 83.7412\n",
      "Epoch 612/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2074 - val_loss: 74.0599\n",
      "Epoch 613/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1586 - val_loss: 74.6097\n",
      "Epoch 614/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.5056 - val_loss: 68.6733\n",
      "Epoch 615/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.5741 - val_loss: 71.4414\n",
      "Epoch 616/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.1895 - val_loss: 89.8456\n",
      "Epoch 617/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 36.4011 - val_loss: 69.5856\n",
      "Epoch 618/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.4780 - val_loss: 76.7981\n",
      "Epoch 619/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.0616 - val_loss: 76.2850\n",
      "Epoch 620/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9233 - val_loss: 69.3321\n",
      "Epoch 621/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9224 - val_loss: 71.7304\n",
      "Epoch 622/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9297 - val_loss: 70.3132\n",
      "Epoch 623/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.1619 - val_loss: 68.8752\n",
      "Epoch 624/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.9380 - val_loss: 70.1950\n",
      "Epoch 625/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1586 - val_loss: 71.5513\n",
      "Epoch 626/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4625 - val_loss: 71.2047\n",
      "Epoch 627/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.0872 - val_loss: 70.9033\n",
      "Epoch 628/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.9740 - val_loss: 68.1403\n",
      "Epoch 629/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2576 - val_loss: 73.3430\n",
      "Epoch 630/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.4829 - val_loss: 77.1748\n",
      "Epoch 631/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.2996 - val_loss: 77.5544\n",
      "Epoch 632/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3410 - val_loss: 73.6046\n",
      "Epoch 633/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.9223 - val_loss: 69.1902\n",
      "Epoch 634/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2815 - val_loss: 78.9815\n",
      "Epoch 635/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8760 - val_loss: 73.6957\n",
      "Epoch 636/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6758 - val_loss: 68.2218\n",
      "Epoch 637/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9546 - val_loss: 74.1159\n",
      "Epoch 638/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5712 - val_loss: 67.9292\n",
      "Epoch 639/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8768 - val_loss: 73.8822\n",
      "Epoch 640/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.9086 - val_loss: 69.9526\n",
      "Epoch 641/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6362 - val_loss: 97.9771\n",
      "Epoch 642/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.8988 - val_loss: 86.7716\n",
      "Epoch 643/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4376 - val_loss: 68.9992\n",
      "Epoch 644/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2974 - val_loss: 73.2613\n",
      "Epoch 645/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.7844 - val_loss: 71.3090\n",
      "Epoch 646/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.2231 - val_loss: 71.7059\n",
      "Epoch 647/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.8999 - val_loss: 72.3879\n",
      "Epoch 648/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.1207 - val_loss: 69.3382\n",
      "Epoch 649/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.8343 - val_loss: 87.2870\n",
      "Epoch 650/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.0591 - val_loss: 69.5003\n",
      "Epoch 651/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.9067 - val_loss: 74.1643\n",
      "Epoch 652/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7032 - val_loss: 74.5220\n",
      "Epoch 653/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3049 - val_loss: 81.8554\n",
      "Epoch 654/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8345 - val_loss: 69.0918\n",
      "Epoch 655/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.5272 - val_loss: 71.7280\n",
      "Epoch 656/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6640 - val_loss: 70.3317\n",
      "Epoch 657/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9598 - val_loss: 68.2198\n",
      "Epoch 658/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.6770 - val_loss: 69.1686\n",
      "Epoch 659/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0730 - val_loss: 71.6330\n",
      "Epoch 660/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8048 - val_loss: 83.2382\n",
      "Epoch 661/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.1988 - val_loss: 67.9032\n",
      "Epoch 662/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2361 - val_loss: 69.6549\n",
      "Epoch 663/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1150 - val_loss: 84.7393\n",
      "Epoch 664/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4697 - val_loss: 75.8385\n",
      "Epoch 665/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.5332 - val_loss: 74.7658\n",
      "Epoch 666/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.9150 - val_loss: 67.5831\n",
      "Epoch 667/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.0980 - val_loss: 69.2410\n",
      "Epoch 668/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.8375 - val_loss: 75.9872\n",
      "Epoch 669/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4744 - val_loss: 69.9537\n",
      "Epoch 670/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.3064 - val_loss: 74.8939\n",
      "Epoch 671/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.3959 - val_loss: 71.9671\n",
      "Epoch 672/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.9675 - val_loss: 72.5392\n",
      "Epoch 673/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7312 - val_loss: 73.1259\n",
      "Epoch 674/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1957 - val_loss: 78.1463\n",
      "Epoch 675/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.1565 - val_loss: 67.6774\n",
      "Epoch 676/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.7417 - val_loss: 67.4527\n",
      "Epoch 677/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.0139 - val_loss: 68.8937\n",
      "Epoch 678/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 35.9620 - val_loss: 70.2434\n",
      "Epoch 679/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8869 - val_loss: 73.2930\n",
      "Epoch 680/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6530 - val_loss: 71.1374\n",
      "Epoch 681/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7627 - val_loss: 73.8455\n",
      "Epoch 682/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4064 - val_loss: 70.6241\n",
      "Epoch 683/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.8677 - val_loss: 78.2572\n",
      "Epoch 684/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0149 - val_loss: 68.2808\n",
      "Epoch 685/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.4696 - val_loss: 70.6956\n",
      "Epoch 686/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0168 - val_loss: 69.8429\n",
      "Epoch 687/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.9132 - val_loss: 69.3375\n",
      "Epoch 688/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2667 - val_loss: 71.0474\n",
      "Epoch 689/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.4588 - val_loss: 69.6871\n",
      "Epoch 690/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4461 - val_loss: 74.6709\n",
      "Epoch 691/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.6537 - val_loss: 76.5115\n",
      "Epoch 692/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7032 - val_loss: 70.3316\n",
      "Epoch 693/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4297 - val_loss: 76.0830\n",
      "Epoch 694/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.7233 - val_loss: 75.1378\n",
      "Epoch 695/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7929 - val_loss: 72.1646\n",
      "Epoch 696/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4445 - val_loss: 74.9453\n",
      "Epoch 697/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.0397 - val_loss: 68.8070\n",
      "Epoch 698/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4581 - val_loss: 67.7208\n",
      "Epoch 699/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6840 - val_loss: 72.8082\n",
      "Epoch 700/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0358 - val_loss: 76.4892\n",
      "Epoch 701/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.0263 - val_loss: 74.7067\n",
      "Epoch 702/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6119 - val_loss: 75.7097\n",
      "Epoch 703/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9215 - val_loss: 84.4996\n",
      "Epoch 704/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.1442 - val_loss: 70.8713\n",
      "Epoch 705/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.5071 - val_loss: 68.4428\n",
      "Epoch 706/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7861 - val_loss: 74.4646\n",
      "Epoch 707/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3139 - val_loss: 69.4720\n",
      "Epoch 708/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5430 - val_loss: 69.2502\n",
      "Epoch 709/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.9002 - val_loss: 80.1156\n",
      "Epoch 710/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.1543 - val_loss: 71.2111\n",
      "Epoch 711/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9003 - val_loss: 83.9235\n",
      "Epoch 712/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3017 - val_loss: 69.1939\n",
      "Epoch 713/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.1557 - val_loss: 69.0199\n",
      "Epoch 714/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.2733 - val_loss: 78.5584\n",
      "Epoch 715/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3510 - val_loss: 69.5838\n",
      "Epoch 716/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.9315 - val_loss: 75.6290\n",
      "Epoch 717/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.1614 - val_loss: 68.7643\n",
      "Epoch 718/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9316 - val_loss: 70.6411\n",
      "Epoch 719/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.4309 - val_loss: 71.7342\n",
      "Epoch 720/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9505 - val_loss: 78.1367\n",
      "Epoch 721/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8947 - val_loss: 70.3556\n",
      "Epoch 722/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.6334 - val_loss: 74.7812\n",
      "Epoch 723/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3599 - val_loss: 68.6381\n",
      "Epoch 724/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9485 - val_loss: 90.5376\n",
      "Epoch 725/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.6829 - val_loss: 74.4296\n",
      "Epoch 726/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7897 - val_loss: 68.7697\n",
      "Epoch 727/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3626 - val_loss: 74.4846\n",
      "Epoch 728/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2253 - val_loss: 72.8910\n",
      "Epoch 729/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.9169 - val_loss: 90.2472\n",
      "Epoch 730/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.2117 - val_loss: 76.1799\n",
      "Epoch 731/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7012 - val_loss: 70.6346\n",
      "Epoch 732/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9704 - val_loss: 70.9509\n",
      "Epoch 733/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3986 - val_loss: 69.1653\n",
      "Epoch 734/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5251 - val_loss: 69.2694\n",
      "Epoch 735/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6170 - val_loss: 67.6940\n",
      "Epoch 736/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7983 - val_loss: 83.1978\n",
      "Epoch 737/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2646 - val_loss: 82.8864\n",
      "Epoch 738/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8790 - val_loss: 71.4112\n",
      "Epoch 739/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.7346 - val_loss: 74.3439\n",
      "Epoch 740/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8215 - val_loss: 71.5872\n",
      "Epoch 741/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.6777 - val_loss: 72.1577\n",
      "Epoch 742/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6646 - val_loss: 68.9140\n",
      "Epoch 743/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9021 - val_loss: 69.1458\n",
      "Epoch 744/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7761 - val_loss: 67.7881\n",
      "Epoch 745/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3479 - val_loss: 77.4251\n",
      "Epoch 746/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7001 - val_loss: 71.4334\n",
      "Epoch 747/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.5242 - val_loss: 71.7296\n",
      "Epoch 748/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.3664 - val_loss: 72.1815\n",
      "Epoch 749/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6384 - val_loss: 67.7422\n",
      "Epoch 750/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.8853 - val_loss: 92.3604\n",
      "Epoch 751/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.7382 - val_loss: 67.9451\n",
      "Epoch 752/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.5300 - val_loss: 70.7092\n",
      "Epoch 753/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.8108 - val_loss: 101.4789\n",
      "Epoch 754/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.8461 - val_loss: 68.6771\n",
      "Epoch 755/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5232 - val_loss: 73.1105\n",
      "Epoch 756/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8219 - val_loss: 71.8654\n",
      "Epoch 757/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.9316 - val_loss: 67.8063\n",
      "Epoch 758/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9690 - val_loss: 68.6688\n",
      "Epoch 759/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4419 - val_loss: 77.0019\n",
      "Epoch 760/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.8443 - val_loss: 84.4144\n",
      "Epoch 761/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4588 - val_loss: 79.7893\n",
      "Epoch 762/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.3957 - val_loss: 68.3578\n",
      "Epoch 763/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6992 - val_loss: 71.0512\n",
      "Epoch 764/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.1094 - val_loss: 81.6293\n",
      "Epoch 765/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.6821 - val_loss: 68.9963\n",
      "Epoch 766/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7340 - val_loss: 80.6602\n",
      "Epoch 767/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6653 - val_loss: 69.7641\n",
      "Epoch 768/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.1112 - val_loss: 71.2561\n",
      "Epoch 769/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3759 - val_loss: 90.3408\n",
      "Epoch 770/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2901 - val_loss: 74.7437\n",
      "Epoch 771/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.1114 - val_loss: 80.4431\n",
      "Epoch 772/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9618 - val_loss: 67.6089\n",
      "Epoch 773/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6678 - val_loss: 68.0881\n",
      "Epoch 774/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.1196 - val_loss: 72.7747\n",
      "Epoch 775/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0923 - val_loss: 68.8086\n",
      "Epoch 776/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.1189 - val_loss: 72.2418\n",
      "Epoch 777/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4048 - val_loss: 68.5186\n",
      "Epoch 778/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9897 - val_loss: 84.5634\n",
      "Epoch 779/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.3036 - val_loss: 67.5421\n",
      "Epoch 780/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5852 - val_loss: 84.7743\n",
      "Epoch 781/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 32.2330 - val_loss: 85.0009\n",
      "Epoch 782/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8856 - val_loss: 68.6068\n",
      "Epoch 783/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6583 - val_loss: 74.0554\n",
      "Epoch 784/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.7295 - val_loss: 73.4796\n",
      "Epoch 785/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.3557 - val_loss: 90.2535\n",
      "Epoch 786/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.1356 - val_loss: 70.0516\n",
      "Epoch 787/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5640 - val_loss: 68.8614\n",
      "Epoch 788/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8621 - val_loss: 77.6413\n",
      "Epoch 789/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.4278 - val_loss: 76.5820\n",
      "Epoch 790/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.1111 - val_loss: 69.5128\n",
      "Epoch 791/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9340 - val_loss: 71.2790\n",
      "Epoch 792/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1516 - val_loss: 68.4283\n",
      "Epoch 793/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.0734 - val_loss: 68.2094\n",
      "Epoch 794/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.2750 - val_loss: 68.9677\n",
      "Epoch 795/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6294 - val_loss: 74.4822\n",
      "Epoch 796/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.6453 - val_loss: 86.2738\n",
      "Epoch 797/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8658 - val_loss: 67.8778\n",
      "Epoch 798/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2305 - val_loss: 72.8688\n",
      "Epoch 799/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8193 - val_loss: 69.5856\n",
      "Epoch 800/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 25.7152 - val_loss: 76.7115\n",
      "Epoch 801/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 27.0755 - val_loss: 68.8262\n",
      "Epoch 802/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.9379 - val_loss: 69.8130\n",
      "Epoch 803/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6156 - val_loss: 93.1766\n",
      "Epoch 804/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.1156 - val_loss: 72.2225\n",
      "Epoch 805/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6432 - val_loss: 76.2722\n",
      "Epoch 806/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0237 - val_loss: 67.9577\n",
      "Epoch 807/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.1763 - val_loss: 74.1773\n",
      "Epoch 808/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3924 - val_loss: 67.5380\n",
      "Epoch 809/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5802 - val_loss: 70.4752\n",
      "Epoch 810/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.3554 - val_loss: 79.8612\n",
      "Epoch 811/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7404 - val_loss: 79.7393\n",
      "Epoch 812/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.9289 - val_loss: 89.7466\n",
      "Epoch 813/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.7113 - val_loss: 70.7578\n",
      "Epoch 814/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.9962 - val_loss: 73.2250\n",
      "Epoch 815/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.4383 - val_loss: 76.2537\n",
      "Epoch 816/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3264 - val_loss: 71.6505\n",
      "Epoch 817/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.1998 - val_loss: 103.8007\n",
      "Epoch 818/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.3788 - val_loss: 72.5710\n",
      "Epoch 819/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.3749 - val_loss: 93.1433\n",
      "Epoch 820/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 113.9889 - val_loss: 87.8158\n",
      "Epoch 821/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.5296 - val_loss: 81.8382\n",
      "Epoch 822/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.8016 - val_loss: 74.3420\n",
      "Epoch 823/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.4982 - val_loss: 77.6932\n",
      "Epoch 824/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.3013 - val_loss: 80.1039\n",
      "Epoch 825/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.7204 - val_loss: 76.3533\n",
      "Epoch 826/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.5290 - val_loss: 78.5495\n",
      "Epoch 827/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8026 - val_loss: 74.8455\n",
      "Epoch 828/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7556 - val_loss: 73.3800\n",
      "Epoch 829/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5881 - val_loss: 77.4744\n",
      "Epoch 830/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.3728 - val_loss: 69.1469\n",
      "Epoch 831/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.1569 - val_loss: 68.3098\n",
      "Epoch 832/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6781 - val_loss: 74.3862\n",
      "Epoch 833/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.3975 - val_loss: 70.5080\n",
      "Epoch 834/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.0755 - val_loss: 91.9291\n",
      "Epoch 835/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9872 - val_loss: 89.8092\n",
      "Epoch 836/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.0294 - val_loss: 71.6350\n",
      "Epoch 837/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.0002 - val_loss: 68.1166\n",
      "Epoch 838/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.3152 - val_loss: 68.4853\n",
      "Epoch 839/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.3947 - val_loss: 69.8152\n",
      "Epoch 840/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4417 - val_loss: 74.8590\n",
      "Epoch 841/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.1392 - val_loss: 71.1999\n",
      "Epoch 842/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6187 - val_loss: 84.0383\n",
      "Epoch 843/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5143 - val_loss: 69.6831\n",
      "Epoch 844/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2112 - val_loss: 84.0632\n",
      "Epoch 845/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8342 - val_loss: 70.8527\n",
      "Epoch 846/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8739 - val_loss: 71.5404\n",
      "Epoch 847/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.1719 - val_loss: 80.7502\n",
      "Epoch 848/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6323 - val_loss: 74.0146\n",
      "Epoch 849/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.1829 - val_loss: 68.5538\n",
      "Epoch 850/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4686 - val_loss: 71.6565\n",
      "Epoch 851/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8615 - val_loss: 71.0738\n",
      "Epoch 852/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.3185 - val_loss: 74.5241\n",
      "Epoch 853/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9154 - val_loss: 70.4453\n",
      "Epoch 854/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.9576 - val_loss: 72.0202\n",
      "Epoch 855/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8752 - val_loss: 70.6120\n",
      "Epoch 856/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1117 - val_loss: 68.5954\n",
      "Epoch 857/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.7151 - val_loss: 67.4059\n",
      "Epoch 858/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5728 - val_loss: 72.1201\n",
      "Epoch 859/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9261 - val_loss: 69.1047\n",
      "Epoch 860/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2124 - val_loss: 69.1315\n",
      "Epoch 861/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.6796 - val_loss: 68.9488\n",
      "Epoch 862/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7471 - val_loss: 74.0136\n",
      "Epoch 863/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1724 - val_loss: 69.5676\n",
      "Epoch 864/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.6911 - val_loss: 75.7947\n",
      "Epoch 865/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7883 - val_loss: 68.2168\n",
      "Epoch 866/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5132 - val_loss: 69.2988\n",
      "Epoch 867/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7044 - val_loss: 67.4067\n",
      "Epoch 868/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.9572 - val_loss: 82.4502\n",
      "Epoch 869/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.0062 - val_loss: 76.2373\n",
      "Epoch 870/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.3430 - val_loss: 73.8915\n",
      "Epoch 871/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8209 - val_loss: 69.8180\n",
      "Epoch 872/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.5367 - val_loss: 69.0698\n",
      "Epoch 873/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.6887 - val_loss: 68.7888\n",
      "Epoch 874/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8028 - val_loss: 71.8977\n",
      "Epoch 875/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7753 - val_loss: 68.8708\n",
      "Epoch 876/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7964 - val_loss: 68.1530\n",
      "Epoch 877/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7619 - val_loss: 67.8958\n",
      "Epoch 878/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.4812 - val_loss: 74.0065\n",
      "Epoch 879/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2118 - val_loss: 69.4368\n",
      "Epoch 880/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.2538 - val_loss: 74.4323\n",
      "Epoch 881/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.0032 - val_loss: 68.5611\n",
      "Epoch 882/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9260 - val_loss: 70.2628\n",
      "Epoch 883/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.1403 - val_loss: 68.0096\n",
      "Epoch 884/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9917 - val_loss: 79.6304\n",
      "Epoch 885/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4300 - val_loss: 69.3838\n",
      "Epoch 886/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0573 - val_loss: 73.2365\n",
      "Epoch 887/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6985 - val_loss: 70.0000\n",
      "Epoch 888/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7575 - val_loss: 75.8596\n",
      "Epoch 889/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3618 - val_loss: 69.1939\n",
      "Epoch 890/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9319 - val_loss: 68.9292\n",
      "Epoch 891/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3437 - val_loss: 69.6148\n",
      "Epoch 892/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.3156 - val_loss: 69.4554\n",
      "Epoch 893/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.8558 - val_loss: 71.2479\n",
      "Epoch 894/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7544 - val_loss: 72.3340\n",
      "Epoch 895/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.1361 - val_loss: 94.7144\n",
      "Epoch 896/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9928 - val_loss: 72.2019\n",
      "Epoch 897/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0082 - val_loss: 69.2651\n",
      "Epoch 898/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1864 - val_loss: 70.7534\n",
      "Epoch 899/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.4309 - val_loss: 73.3585\n",
      "Epoch 900/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4180 - val_loss: 68.5363\n",
      "Epoch 901/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 22.5285 - val_loss: 70.4794\n",
      "Epoch 902/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8086 - val_loss: 80.5561\n",
      "Epoch 903/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4106 - val_loss: 68.8336\n",
      "Epoch 904/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6037 - val_loss: 75.3102\n",
      "Epoch 905/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5664 - val_loss: 68.9725\n",
      "Epoch 906/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5668 - val_loss: 68.1061\n",
      "Epoch 907/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0631 - val_loss: 70.4481\n",
      "Epoch 908/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.8266 - val_loss: 73.4153\n",
      "Epoch 909/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.5838 - val_loss: 71.1039\n",
      "Epoch 910/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4013 - val_loss: 88.4641\n",
      "Epoch 911/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3056 - val_loss: 69.2341\n",
      "Epoch 912/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2654 - val_loss: 71.6155\n",
      "Epoch 913/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7502 - val_loss: 70.3899\n",
      "Epoch 914/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5098 - val_loss: 68.6082\n",
      "Epoch 915/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.8591 - val_loss: 70.8295\n",
      "Epoch 916/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5197 - val_loss: 70.7666\n",
      "Epoch 917/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 24.6878 - val_loss: 70.2347\n",
      "Epoch 918/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6845 - val_loss: 68.9036\n",
      "Epoch 919/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8698 - val_loss: 93.0624\n",
      "Epoch 920/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4385 - val_loss: 69.8996\n",
      "Epoch 921/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5135 - val_loss: 75.2443\n",
      "Epoch 922/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.3519 - val_loss: 68.9919\n",
      "Epoch 923/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8987 - val_loss: 68.2642\n",
      "Epoch 924/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1726 - val_loss: 67.8298\n",
      "Epoch 925/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6499 - val_loss: 78.8689\n",
      "Epoch 926/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7965 - val_loss: 70.0573\n",
      "Epoch 927/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2812 - val_loss: 69.6330\n",
      "Epoch 928/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7271 - val_loss: 68.1946\n",
      "Epoch 929/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9385 - val_loss: 70.3007\n",
      "Epoch 930/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.4944 - val_loss: 73.2338\n",
      "Epoch 931/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9513 - val_loss: 69.0044\n",
      "Epoch 932/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2404 - val_loss: 76.1221\n",
      "Epoch 933/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3870 - val_loss: 72.4232\n",
      "Epoch 934/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8577 - val_loss: 69.0794\n",
      "Epoch 935/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9194 - val_loss: 81.0510\n",
      "Epoch 936/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9492 - val_loss: 70.6012\n",
      "Epoch 937/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7567 - val_loss: 69.1162\n",
      "Epoch 938/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0240 - val_loss: 69.0477\n",
      "Epoch 939/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5543 - val_loss: 70.1475\n",
      "Epoch 940/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.3514 - val_loss: 88.4866\n",
      "Epoch 941/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7231 - val_loss: 69.9090\n",
      "Epoch 942/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3058 - val_loss: 69.8931\n",
      "Epoch 943/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1870 - val_loss: 69.4475\n",
      "Epoch 944/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3139 - val_loss: 70.4328\n",
      "Epoch 945/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1591 - val_loss: 72.2521\n",
      "Epoch 946/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0421 - val_loss: 71.5097\n",
      "Epoch 947/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8010 - val_loss: 71.6678\n",
      "Epoch 948/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.8970 - val_loss: 74.1519\n",
      "Epoch 949/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7076 - val_loss: 69.4962\n",
      "Epoch 950/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.9800 - val_loss: 70.6290\n",
      "Epoch 951/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9926 - val_loss: 68.3867\n",
      "Epoch 952/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7591 - val_loss: 76.1231\n",
      "Epoch 953/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8500 - val_loss: 68.4367\n",
      "Epoch 954/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.2343 - val_loss: 69.1184\n",
      "Epoch 955/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7533 - val_loss: 85.0678\n",
      "Epoch 956/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3051 - val_loss: 74.6994\n",
      "Epoch 957/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3708 - val_loss: 69.3676\n",
      "Epoch 958/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7529 - val_loss: 70.3370\n",
      "Epoch 959/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8114 - val_loss: 69.3636\n",
      "Epoch 960/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.0322 - val_loss: 69.4765\n",
      "Epoch 961/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8395 - val_loss: 71.6998\n",
      "Epoch 962/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.5793 - val_loss: 69.0928\n",
      "Epoch 963/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2859 - val_loss: 78.8593\n",
      "Epoch 964/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0133 - val_loss: 77.7964\n",
      "Epoch 965/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1322 - val_loss: 75.5273\n",
      "Epoch 966/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.4192 - val_loss: 68.6893\n",
      "Epoch 967/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4670 - val_loss: 74.6728\n",
      "Epoch 968/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0116 - val_loss: 77.5980\n",
      "Epoch 969/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4229 - val_loss: 69.7012\n",
      "Epoch 970/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1675 - val_loss: 69.0405\n",
      "Epoch 971/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9603 - val_loss: 68.4550\n",
      "Epoch 972/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.6500 - val_loss: 73.7528\n",
      "Epoch 973/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4939 - val_loss: 70.0655\n",
      "Epoch 974/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0115 - val_loss: 69.1135\n",
      "Epoch 975/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4924 - val_loss: 83.7451\n",
      "Epoch 976/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3044 - val_loss: 78.4762\n",
      "Epoch 977/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.3669 - val_loss: 71.1449\n",
      "Epoch 978/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4592 - val_loss: 68.3810\n",
      "Epoch 979/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1059 - val_loss: 71.9724\n",
      "Epoch 980/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.2334 - val_loss: 69.8187\n",
      "Epoch 981/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9024 - val_loss: 69.4231\n",
      "Epoch 982/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6004 - val_loss: 70.3440\n",
      "Epoch 983/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.9969 - val_loss: 82.2924\n",
      "Epoch 984/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1633 - val_loss: 71.8711\n",
      "Epoch 985/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0983 - val_loss: 69.2898\n",
      "Epoch 986/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5201 - val_loss: 69.2026\n",
      "Epoch 987/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5822 - val_loss: 74.9965\n",
      "Epoch 988/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2432 - val_loss: 68.2248\n",
      "Epoch 989/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4271 - val_loss: 71.4203\n",
      "Epoch 990/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8087 - val_loss: 72.0840\n",
      "Epoch 991/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3480 - val_loss: 68.8625\n",
      "Epoch 992/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0092 - val_loss: 70.9962\n",
      "Epoch 993/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9366 - val_loss: 74.9611\n",
      "Epoch 994/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0944 - val_loss: 79.9747\n",
      "Epoch 995/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6517 - val_loss: 74.1833\n",
      "Epoch 996/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3172 - val_loss: 69.3324\n",
      "Epoch 997/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6682 - val_loss: 69.6788\n",
      "Epoch 998/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0692 - val_loss: 77.2905\n",
      "Epoch 999/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5827 - val_loss: 69.0054\n",
      "Epoch 1000/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.7102 - val_loss: 70.2778\n",
      "Epoch 1001/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7182 - val_loss: 71.1869\n",
      "Epoch 1002/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5838 - val_loss: 74.0776\n",
      "Epoch 1003/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5218 - val_loss: 68.4791\n",
      "Epoch 1004/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6062 - val_loss: 68.4284\n",
      "Epoch 1005/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4379 - val_loss: 73.1748\n",
      "Epoch 1006/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1202 - val_loss: 69.8719\n",
      "Epoch 1007/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6267 - val_loss: 70.1654\n",
      "Epoch 1008/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3486 - val_loss: 71.4537\n",
      "Epoch 1009/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.0929 - val_loss: 70.0169\n",
      "Epoch 1010/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5189 - val_loss: 69.5538\n",
      "Epoch 1011/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0843 - val_loss: 72.0686\n",
      "Epoch 1012/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8771 - val_loss: 81.8072\n",
      "Epoch 1013/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4201 - val_loss: 75.0528\n",
      "Epoch 1014/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8600 - val_loss: 69.4295\n",
      "Epoch 1015/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1172 - val_loss: 68.7499\n",
      "Epoch 1016/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1370 - val_loss: 85.1440\n",
      "Epoch 1017/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.8840 - val_loss: 82.2389\n",
      "Epoch 1018/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3259 - val_loss: 78.3828\n",
      "Epoch 1019/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8594 - val_loss: 69.5289\n",
      "Epoch 1020/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.3097 - val_loss: 74.3591\n",
      "Epoch 1021/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2192 - val_loss: 76.3974\n",
      "Epoch 1022/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5287 - val_loss: 86.5550\n",
      "Epoch 1023/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0782 - val_loss: 76.2416\n",
      "Epoch 1024/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1002 - val_loss: 77.2444\n",
      "Epoch 1025/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.2417 - val_loss: 68.8361\n",
      "Epoch 1026/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.8263 - val_loss: 73.2991\n",
      "Epoch 1027/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.0802 - val_loss: 71.1613\n",
      "Epoch 1028/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9364 - val_loss: 70.9813\n",
      "Epoch 1029/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8272 - val_loss: 76.0665\n",
      "Epoch 1030/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7391 - val_loss: 68.3572\n",
      "Epoch 1031/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5132 - val_loss: 70.2743\n",
      "Epoch 1032/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4861 - val_loss: 69.5835\n",
      "Epoch 1033/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6896 - val_loss: 68.8716\n",
      "Epoch 1034/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3988 - val_loss: 68.7178\n",
      "Epoch 1035/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5144 - val_loss: 68.2951\n",
      "Epoch 1036/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6648 - val_loss: 70.1269\n",
      "Epoch 1037/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0743 - val_loss: 77.1641\n",
      "Epoch 1038/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4861 - val_loss: 87.4183\n",
      "Epoch 1039/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8545 - val_loss: 69.5358\n",
      "Epoch 1040/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5568 - val_loss: 76.2333\n",
      "Epoch 1041/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8010 - val_loss: 69.5621\n",
      "Epoch 1042/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3992 - val_loss: 74.4864\n",
      "Epoch 1043/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5334 - val_loss: 68.8435\n",
      "Epoch 1044/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8624 - val_loss: 76.7042\n",
      "Epoch 1045/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.0056 - val_loss: 72.1250\n",
      "Epoch 1046/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8016 - val_loss: 71.8221\n",
      "Epoch 1047/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.5703 - val_loss: 89.6830\n",
      "Epoch 1048/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7889 - val_loss: 69.3337\n",
      "Epoch 1049/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4139 - val_loss: 85.4666\n",
      "Epoch 1050/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4879 - val_loss: 73.0128\n",
      "Epoch 1051/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4611 - val_loss: 69.2307\n",
      "Epoch 1052/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7080 - val_loss: 82.4316\n",
      "Epoch 1053/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5776 - val_loss: 71.2675\n",
      "Epoch 1054/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5663 - val_loss: 68.9535\n",
      "Epoch 1055/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1723 - val_loss: 70.0236\n",
      "Epoch 1056/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5992 - val_loss: 69.5322\n",
      "Epoch 1057/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8686 - val_loss: 70.7700\n",
      "Epoch 1058/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3241 - val_loss: 72.7799\n",
      "Epoch 1059/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8253 - val_loss: 75.8920\n",
      "Epoch 1060/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7144 - val_loss: 76.5121\n",
      "Epoch 1061/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4771 - val_loss: 68.5025\n",
      "Epoch 1062/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2951 - val_loss: 74.6107\n",
      "Epoch 1063/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7710 - val_loss: 72.0190\n",
      "Epoch 1064/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0987 - val_loss: 71.0054\n",
      "Epoch 1065/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0337 - val_loss: 69.4478\n",
      "Epoch 1066/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4612 - val_loss: 69.0237\n",
      "Epoch 1067/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8747 - val_loss: 81.9891\n",
      "Epoch 1068/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8299 - val_loss: 76.7702\n",
      "Epoch 1069/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0600 - val_loss: 73.8121\n",
      "Epoch 1070/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8347 - val_loss: 84.4854\n",
      "Epoch 1071/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4439 - val_loss: 72.4071\n",
      "Epoch 1072/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9954 - val_loss: 68.7711\n",
      "Epoch 1073/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8584 - val_loss: 69.6981\n",
      "Epoch 1074/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9653 - val_loss: 68.6632\n",
      "Epoch 1075/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8130 - val_loss: 77.4304\n",
      "Epoch 1076/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3654 - val_loss: 70.4887\n",
      "Epoch 1077/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5229 - val_loss: 68.4339\n",
      "Epoch 1078/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5722 - val_loss: 70.4763\n",
      "Epoch 1079/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7432 - val_loss: 69.0056\n",
      "Epoch 1080/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7492 - val_loss: 70.1718\n",
      "Epoch 1081/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9176 - val_loss: 69.6049\n",
      "Epoch 1082/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4277 - val_loss: 86.4846\n",
      "Epoch 1083/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1468 - val_loss: 69.6737\n",
      "Epoch 1084/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0621 - val_loss: 69.1013\n",
      "Epoch 1085/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3221 - val_loss: 70.1658\n",
      "Epoch 1086/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5841 - val_loss: 69.0301\n",
      "Epoch 1087/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5570 - val_loss: 69.2238\n",
      "Epoch 1088/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8847 - val_loss: 72.2928\n",
      "Epoch 1089/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5424 - val_loss: 72.2664\n",
      "Epoch 1090/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4989 - val_loss: 68.7270\n",
      "Epoch 1091/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8559 - val_loss: 69.0644\n",
      "Epoch 1092/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5005 - val_loss: 68.5427\n",
      "Epoch 1093/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3966 - val_loss: 73.4234\n",
      "Epoch 1094/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6652 - val_loss: 74.0170\n",
      "Epoch 1095/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6349 - val_loss: 72.3240\n",
      "Epoch 1096/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0046 - val_loss: 70.5829\n",
      "Epoch 1097/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0348 - val_loss: 68.3799\n",
      "Epoch 1098/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1229 - val_loss: 73.6126\n",
      "Epoch 1099/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3824 - val_loss: 68.9625\n",
      "Epoch 1100/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.5180 - val_loss: 68.8190\n",
      "Epoch 1101/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7641 - val_loss: 73.4054\n",
      "Epoch 1102/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0362 - val_loss: 70.7547\n",
      "Epoch 1103/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3676 - val_loss: 69.5397\n",
      "Epoch 1104/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4798 - val_loss: 70.7091\n",
      "Epoch 1105/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5240 - val_loss: 84.7281\n",
      "Epoch 1106/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.0165 - val_loss: 68.4957\n",
      "Epoch 1107/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1416 - val_loss: 70.9433\n",
      "Epoch 1108/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9229 - val_loss: 69.5823\n",
      "Epoch 1109/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1989 - val_loss: 70.6884\n",
      "Epoch 1110/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2747 - val_loss: 73.9427\n",
      "Epoch 1111/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9576 - val_loss: 76.3519\n",
      "Epoch 1112/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1104 - val_loss: 68.4527\n",
      "Epoch 1113/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3087 - val_loss: 68.6609\n",
      "Epoch 1114/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4436 - val_loss: 69.1130\n",
      "Epoch 1115/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0609 - val_loss: 70.9725\n",
      "Epoch 1116/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0863 - val_loss: 82.1427\n",
      "Epoch 1117/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0146 - val_loss: 69.2407\n",
      "Epoch 1118/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2481 - val_loss: 70.9112\n",
      "Epoch 1119/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4834 - val_loss: 76.9525\n",
      "Epoch 1120/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6219 - val_loss: 70.6389\n",
      "Epoch 1121/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.4824 - val_loss: 77.1565\n",
      "Epoch 1122/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0073 - val_loss: 69.2258\n",
      "Epoch 1123/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.2798 - val_loss: 69.9877\n",
      "Epoch 1124/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8144 - val_loss: 68.6789\n",
      "Epoch 1125/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7922 - val_loss: 76.2787\n",
      "Epoch 1126/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3849 - val_loss: 71.3768\n",
      "Epoch 1127/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5537 - val_loss: 68.3526\n",
      "Epoch 1128/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0158 - val_loss: 77.6797\n",
      "Epoch 1129/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.3182 - val_loss: 69.6897\n",
      "Epoch 1130/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0622 - val_loss: 68.6972\n",
      "Epoch 1131/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1583 - val_loss: 81.8576\n",
      "Epoch 1132/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6923 - val_loss: 77.9189\n",
      "Epoch 1133/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5308 - val_loss: 68.4584\n",
      "Epoch 1134/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8002 - val_loss: 68.5776\n",
      "Epoch 1135/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4565 - val_loss: 68.7848\n",
      "Epoch 1136/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1582 - val_loss: 68.2870\n",
      "Epoch 1137/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.6664 - val_loss: 80.5819\n",
      "Epoch 1138/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6967 - val_loss: 68.9574\n",
      "Epoch 1139/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4635 - val_loss: 68.4917\n",
      "Epoch 1140/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1425 - val_loss: 69.5462\n",
      "Epoch 1141/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0989 - val_loss: 69.5851\n",
      "Epoch 1142/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4675 - val_loss: 71.5129\n",
      "Epoch 1143/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3270 - val_loss: 79.2848\n",
      "Epoch 1144/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0168 - val_loss: 69.1358\n",
      "Epoch 1145/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0313 - val_loss: 70.6896\n",
      "Epoch 1146/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1627 - val_loss: 69.9247\n",
      "Epoch 1147/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7016 - val_loss: 71.0082\n",
      "Epoch 1148/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4542 - val_loss: 76.2036\n",
      "Epoch 1149/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.8674 - val_loss: 69.0233\n",
      "Epoch 1150/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5680 - val_loss: 69.9573\n",
      "Epoch 1151/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2986 - val_loss: 68.9607\n",
      "Epoch 1152/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.4647 - val_loss: 69.2363\n",
      "Epoch 1153/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8009 - val_loss: 81.1759\n",
      "Epoch 1154/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.5323 - val_loss: 70.7703\n",
      "Epoch 1155/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.6052 - val_loss: 69.0630\n",
      "Epoch 1156/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2363 - val_loss: 68.5078\n",
      "Epoch 1157/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7336 - val_loss: 78.1748\n",
      "Epoch 1158/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7327 - val_loss: 72.6010\n",
      "Epoch 1159/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4815 - val_loss: 68.5863\n",
      "Epoch 1160/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5724 - val_loss: 70.5570\n",
      "Epoch 1161/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8058 - val_loss: 81.3018\n",
      "Epoch 1162/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.4461 - val_loss: 71.4668\n",
      "Epoch 1163/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3608 - val_loss: 72.2173\n",
      "Epoch 1164/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.0685 - val_loss: 68.8838\n",
      "Epoch 1165/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4751 - val_loss: 68.2031\n",
      "Epoch 1166/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.7338 - val_loss: 72.5397\n",
      "Epoch 1167/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1998 - val_loss: 70.5051\n",
      "Epoch 1168/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5089 - val_loss: 75.6783\n",
      "Epoch 1169/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0222 - val_loss: 68.5124\n",
      "Epoch 1170/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5325 - val_loss: 75.3244\n",
      "Epoch 1171/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2426 - val_loss: 68.2898\n",
      "Epoch 1172/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6825 - val_loss: 72.1440\n",
      "Epoch 1173/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1871 - val_loss: 73.2046\n",
      "Epoch 1174/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3395 - val_loss: 75.3081\n",
      "Epoch 1175/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1569 - val_loss: 69.7489\n",
      "Epoch 1176/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8730 - val_loss: 75.3036\n",
      "Epoch 1177/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0058 - val_loss: 71.9983\n",
      "Epoch 1178/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0711 - val_loss: 70.0237\n",
      "Epoch 1179/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1921 - val_loss: 73.2798\n",
      "Epoch 1180/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2239 - val_loss: 68.3882\n",
      "Epoch 1181/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3801 - val_loss: 70.3193\n",
      "Epoch 1182/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2387 - val_loss: 74.3025\n",
      "Epoch 1183/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0111 - val_loss: 70.7846\n",
      "Epoch 1184/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0144 - val_loss: 74.9519\n",
      "Epoch 1185/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8063 - val_loss: 90.7114\n",
      "Epoch 1186/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8052 - val_loss: 68.3668\n",
      "Epoch 1187/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1353 - val_loss: 71.4309\n",
      "Epoch 1188/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7351 - val_loss: 69.0063\n",
      "Epoch 1189/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2699 - val_loss: 70.9911\n",
      "Epoch 1190/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5813 - val_loss: 71.1716\n",
      "Epoch 1191/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9899 - val_loss: 85.4546\n",
      "Epoch 1192/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.4697 - val_loss: 82.6576\n",
      "Epoch 1193/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5501 - val_loss: 70.4832\n",
      "Epoch 1194/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8938 - val_loss: 69.7615\n",
      "Epoch 1195/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5002 - val_loss: 91.6010\n",
      "Epoch 1196/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9038 - val_loss: 74.5888\n",
      "Epoch 1197/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1338 - val_loss: 68.6072\n",
      "Epoch 1198/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2783 - val_loss: 68.6003\n",
      "Epoch 1199/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3778 - val_loss: 70.3850\n",
      "Epoch 1200/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.1878 - val_loss: 68.7698\n",
      "Epoch 1201/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7687 - val_loss: 69.0573\n",
      "Epoch 1202/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5376 - val_loss: 70.5705\n",
      "Epoch 1203/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1899 - val_loss: 68.8239\n",
      "Epoch 1204/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2804 - val_loss: 74.4678\n",
      "Epoch 1205/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8646 - val_loss: 69.9110\n",
      "Epoch 1206/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1572 - val_loss: 70.6568\n",
      "Epoch 1207/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0981 - val_loss: 68.7087\n",
      "Epoch 1208/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.9442 - val_loss: 69.8190\n",
      "Epoch 1209/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9524 - val_loss: 72.9156\n",
      "Epoch 1210/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.7825 - val_loss: 68.8530\n",
      "Epoch 1211/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3215 - val_loss: 68.7682\n",
      "Epoch 1212/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0303 - val_loss: 71.6759\n",
      "Epoch 1213/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2095 - val_loss: 68.7315\n",
      "Epoch 1214/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5030 - val_loss: 74.1583\n",
      "Epoch 1215/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8391 - val_loss: 71.0445\n",
      "Epoch 1216/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9481 - val_loss: 68.8731\n",
      "Epoch 1217/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0470 - val_loss: 69.9198\n",
      "Epoch 1218/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8452 - val_loss: 69.1430\n",
      "Epoch 1219/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5610 - val_loss: 74.8357\n",
      "Epoch 1220/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5278 - val_loss: 70.1741\n",
      "Epoch 1221/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3467 - val_loss: 68.6347\n",
      "Epoch 1222/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 20.3972 - val_loss: 68.2832\n",
      "Epoch 1223/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9532 - val_loss: 68.2551\n",
      "Epoch 1224/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0764 - val_loss: 68.3027\n",
      "Epoch 1225/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4180 - val_loss: 83.0188\n",
      "Epoch 1226/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7412 - val_loss: 68.9788\n",
      "Epoch 1227/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4586 - val_loss: 68.0656\n",
      "Epoch 1228/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7118 - val_loss: 68.6746\n",
      "Epoch 1229/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.9938 - val_loss: 68.2680\n",
      "Epoch 1230/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2200 - val_loss: 93.6696\n",
      "Epoch 1231/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7827 - val_loss: 69.2321\n",
      "Epoch 1232/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0987 - val_loss: 68.3576\n",
      "Epoch 1233/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1594 - val_loss: 76.5707\n",
      "Epoch 1234/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8821 - val_loss: 69.4942\n",
      "Epoch 1235/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5972 - val_loss: 70.6731\n",
      "Epoch 1236/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7905 - val_loss: 71.2290\n",
      "Epoch 1237/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9290 - val_loss: 72.1622\n",
      "Epoch 1238/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6696 - val_loss: 69.2245\n",
      "Epoch 1239/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5518 - val_loss: 82.8018\n",
      "Epoch 1240/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3626 - val_loss: 68.4657\n",
      "Epoch 1241/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2778 - val_loss: 68.4387\n",
      "Epoch 1242/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9231 - val_loss: 68.6323\n",
      "Epoch 1243/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9341 - val_loss: 71.9121\n",
      "Epoch 1244/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4925 - val_loss: 71.0184\n",
      "Epoch 1245/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9481 - val_loss: 68.8325\n",
      "Epoch 1246/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3284 - val_loss: 68.3438\n",
      "Epoch 1247/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1511 - val_loss: 68.6771\n",
      "Epoch 1248/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6765 - val_loss: 69.6358\n",
      "Epoch 1249/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8961 - val_loss: 69.9507\n",
      "Epoch 1250/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8467 - val_loss: 73.0632\n",
      "Epoch 1251/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8024 - val_loss: 69.3788\n",
      "Epoch 1252/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5595 - val_loss: 68.9122\n",
      "Epoch 1253/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4822 - val_loss: 68.2625\n",
      "Epoch 1254/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6748 - val_loss: 80.7339\n",
      "Epoch 1255/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9816 - val_loss: 77.1975\n",
      "Epoch 1256/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4097 - val_loss: 68.1956\n",
      "Epoch 1257/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2235 - val_loss: 69.1203\n",
      "Epoch 1258/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8192 - val_loss: 71.8249\n",
      "Epoch 1259/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5643 - val_loss: 68.8084\n",
      "Epoch 1260/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2954 - val_loss: 74.2772\n",
      "Epoch 1261/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1658 - val_loss: 69.1741\n",
      "Epoch 1262/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5876 - val_loss: 70.2930\n",
      "Epoch 1263/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.5839 - val_loss: 68.7067\n",
      "Epoch 1264/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0240 - val_loss: 76.4465\n",
      "Epoch 1265/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6948 - val_loss: 68.4060\n",
      "Epoch 1266/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1197 - val_loss: 69.8092\n",
      "Epoch 1267/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7118 - val_loss: 68.6503\n",
      "Epoch 1268/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5984 - val_loss: 69.0906\n",
      "Epoch 1269/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7892 - val_loss: 69.7263\n",
      "Epoch 1270/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5884 - val_loss: 98.7249\n",
      "Epoch 1271/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7562 - val_loss: 77.1267\n",
      "Epoch 1272/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0027 - val_loss: 68.3663\n",
      "Epoch 1273/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5409 - val_loss: 69.4798\n",
      "Epoch 1274/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4476 - val_loss: 68.3133\n",
      "Epoch 1275/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8122 - val_loss: 71.2404\n",
      "Epoch 1276/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4654 - val_loss: 68.2474\n",
      "Epoch 1277/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.2294 - val_loss: 72.1761\n",
      "Epoch 1278/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7712 - val_loss: 71.2856\n",
      "Epoch 1279/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1407 - val_loss: 68.1922\n",
      "Epoch 1280/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.1185 - val_loss: 71.2979\n",
      "Epoch 1281/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7377 - val_loss: 69.8467\n",
      "Epoch 1282/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3666 - val_loss: 68.9003\n",
      "Epoch 1283/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9586 - val_loss: 68.4907\n",
      "Epoch 1284/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5260 - val_loss: 68.6304\n",
      "Epoch 1285/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5894 - val_loss: 69.8321\n",
      "Epoch 1286/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6261 - val_loss: 69.3401\n",
      "Epoch 1287/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8720 - val_loss: 72.5604\n",
      "Epoch 1288/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0549 - val_loss: 74.0896\n",
      "Epoch 1289/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2942 - val_loss: 97.3446\n",
      "Epoch 1290/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8736 - val_loss: 68.4929\n",
      "Epoch 1291/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9805 - val_loss: 71.3613\n",
      "Epoch 1292/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2475 - val_loss: 68.5658\n",
      "Epoch 1293/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0366 - val_loss: 69.4729\n",
      "Epoch 1294/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3773 - val_loss: 71.1930\n",
      "Epoch 1295/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.8878 - val_loss: 69.3176\n",
      "Epoch 1296/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5758 - val_loss: 68.0502\n",
      "Epoch 1297/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5161 - val_loss: 68.7462\n",
      "Epoch 1298/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2778 - val_loss: 77.2626\n",
      "Epoch 1299/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0877 - val_loss: 77.7025\n",
      "Epoch 1300/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4910 - val_loss: 70.3535\n",
      "Epoch 1301/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5714 - val_loss: 68.3000\n",
      "Epoch 1302/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0261 - val_loss: 72.0080\n",
      "Epoch 1303/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0894 - val_loss: 70.6517\n",
      "Epoch 1304/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2924 - val_loss: 68.4494\n",
      "Epoch 1305/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9238 - val_loss: 70.3185\n",
      "Epoch 1306/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8521 - val_loss: 72.9933\n",
      "Epoch 1307/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5776 - val_loss: 75.4651\n",
      "Epoch 1308/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8090 - val_loss: 69.9250\n",
      "Epoch 1309/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0734 - val_loss: 68.0806\n",
      "Epoch 1310/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5817 - val_loss: 69.4168\n",
      "Epoch 1311/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.6003 - val_loss: 82.8878\n",
      "Epoch 1312/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6857 - val_loss: 68.9927\n",
      "Epoch 1313/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3272 - val_loss: 68.4397\n",
      "Epoch 1314/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4686 - val_loss: 68.3090\n",
      "Epoch 1315/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5706 - val_loss: 70.5066\n",
      "Epoch 1316/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2731 - val_loss: 68.3708\n",
      "Epoch 1317/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4318 - val_loss: 68.5256\n",
      "Epoch 1318/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2690 - val_loss: 82.8862\n",
      "Epoch 1319/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2830 - val_loss: 69.6265\n",
      "Epoch 1320/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7829 - val_loss: 81.8989\n",
      "Epoch 1321/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4090 - val_loss: 70.1674\n",
      "Epoch 1322/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4368 - val_loss: 68.3775\n",
      "Epoch 1323/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1814 - val_loss: 72.6503\n",
      "Epoch 1324/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3011 - val_loss: 71.7387\n",
      "Epoch 1325/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.7751 - val_loss: 68.8071\n",
      "Epoch 1326/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8108 - val_loss: 78.7938\n",
      "Epoch 1327/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2194 - val_loss: 68.8274\n",
      "Epoch 1328/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0338 - val_loss: 68.8344\n",
      "Epoch 1329/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6030 - val_loss: 72.7516\n",
      "Epoch 1330/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4888 - val_loss: 68.9781\n",
      "Epoch 1331/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9918 - val_loss: 72.9606\n",
      "Epoch 1332/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4291 - val_loss: 83.8428\n",
      "Epoch 1333/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3689 - val_loss: 67.8299\n",
      "Epoch 1334/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.4056 - val_loss: 70.6144\n",
      "Epoch 1335/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1223 - val_loss: 70.3352\n",
      "Epoch 1336/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0348 - val_loss: 70.5539\n",
      "Epoch 1337/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.6096 - val_loss: 73.3769\n",
      "Epoch 1338/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7720 - val_loss: 69.8525\n",
      "Epoch 1339/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1956 - val_loss: 71.0763\n",
      "Epoch 1340/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3875 - val_loss: 68.3910\n",
      "Epoch 1341/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1008 - val_loss: 69.4355\n",
      "Epoch 1342/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2476 - val_loss: 68.1529\n",
      "Epoch 1343/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8063 - val_loss: 68.9776\n",
      "Epoch 1344/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.7840 - val_loss: 67.9573\n",
      "Epoch 1345/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9814 - val_loss: 77.9483\n",
      "Epoch 1346/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 20.6875 - val_loss: 71.7097\n",
      "Epoch 1347/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5588 - val_loss: 69.0532\n",
      "Epoch 1348/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4323 - val_loss: 72.6095\n",
      "Epoch 1349/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0431 - val_loss: 70.9556\n",
      "Epoch 1350/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7627 - val_loss: 70.6955\n",
      "Epoch 1351/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0747 - val_loss: 70.1229\n",
      "Epoch 1352/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8000 - val_loss: 73.9781\n",
      "Epoch 1353/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5661 - val_loss: 69.0668\n",
      "Epoch 1354/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1330 - val_loss: 70.0957\n",
      "Epoch 1355/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9211 - val_loss: 69.2717\n",
      "Epoch 1356/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0801 - val_loss: 70.1389\n",
      "Epoch 1357/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3169 - val_loss: 85.5895\n",
      "Epoch 1358/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9624 - val_loss: 75.0469\n",
      "Epoch 1359/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.4922 - val_loss: 68.9811\n",
      "Epoch 1360/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4144 - val_loss: 68.5031\n",
      "Epoch 1361/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5025 - val_loss: 68.1366\n",
      "Epoch 1362/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.3533 - val_loss: 71.1383\n",
      "Epoch 1363/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0030 - val_loss: 68.2495\n",
      "Epoch 1364/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2043 - val_loss: 81.5014\n",
      "Epoch 1365/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5211 - val_loss: 75.7801\n",
      "Epoch 1366/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2939 - val_loss: 71.2304\n",
      "Epoch 1367/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8681 - val_loss: 69.1643\n",
      "Epoch 1368/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3859 - val_loss: 68.6773\n",
      "Epoch 1369/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7301 - val_loss: 68.9762\n",
      "Epoch 1370/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4701 - val_loss: 70.6852\n",
      "Epoch 1371/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0631 - val_loss: 90.9706\n",
      "Epoch 1372/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3674 - val_loss: 73.5901\n",
      "Epoch 1373/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9179 - val_loss: 72.9734\n",
      "Epoch 1374/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2595 - val_loss: 68.0090\n",
      "Epoch 1375/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0382 - val_loss: 71.5826\n",
      "Epoch 1376/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5458 - val_loss: 68.0622\n",
      "Epoch 1377/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0889 - val_loss: 86.5463\n",
      "Epoch 1378/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9101 - val_loss: 71.4379\n",
      "Epoch 1379/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0999 - val_loss: 70.8040\n",
      "Epoch 1380/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1383 - val_loss: 67.8910\n",
      "Epoch 1381/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.4802 - val_loss: 69.4835\n",
      "Epoch 1382/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8994 - val_loss: 69.6354\n",
      "Epoch 1383/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8861 - val_loss: 78.7412\n",
      "Epoch 1384/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7897 - val_loss: 68.6991\n",
      "Epoch 1385/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.3412 - val_loss: 78.4320\n",
      "Epoch 1386/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4881 - val_loss: 69.9565\n",
      "Epoch 1387/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4441 - val_loss: 68.9335\n",
      "Epoch 1388/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7800 - val_loss: 68.4005\n",
      "Epoch 1389/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3952 - val_loss: 68.3189\n",
      "Epoch 1390/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9998 - val_loss: 73.8550\n",
      "Epoch 1391/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5726 - val_loss: 67.9639\n",
      "Epoch 1392/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9775 - val_loss: 72.3021\n",
      "Epoch 1393/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5818 - val_loss: 71.8959\n",
      "Epoch 1394/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2709 - val_loss: 72.9261\n",
      "Epoch 1395/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8688 - val_loss: 71.9671\n",
      "Epoch 1396/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.4725 - val_loss: 68.0181\n",
      "Epoch 1397/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0597 - val_loss: 71.3536\n",
      "Epoch 1398/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2373 - val_loss: 69.6146\n",
      "Epoch 1399/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3852 - val_loss: 69.8958\n",
      "Epoch 1400/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0032 - val_loss: 67.9677\n",
      "Epoch 1401/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1416 - val_loss: 69.0395\n",
      "Epoch 1402/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9694 - val_loss: 70.9103\n",
      "Epoch 1403/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1813 - val_loss: 68.9688\n",
      "Epoch 1404/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.6361 - val_loss: 72.2643\n",
      "Epoch 1405/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 22.9552 - val_loss: 68.9645\n",
      "Epoch 1406/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9633 - val_loss: 67.8144\n",
      "Epoch 1407/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.7313 - val_loss: 77.7884\n",
      "Epoch 1408/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9353 - val_loss: 68.1073\n",
      "Epoch 1409/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5239 - val_loss: 68.2322\n",
      "Epoch 1410/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2956 - val_loss: 67.9151\n",
      "Epoch 1411/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1199 - val_loss: 70.4005\n",
      "Epoch 1412/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.2503 - val_loss: 69.1876\n",
      "Epoch 1413/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5703 - val_loss: 68.5360\n",
      "Epoch 1414/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3952 - val_loss: 68.1119\n",
      "Epoch 1415/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2385 - val_loss: 71.5877\n",
      "Epoch 1416/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2173 - val_loss: 67.8294\n",
      "Epoch 1417/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7699 - val_loss: 73.4730\n",
      "Epoch 1418/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6962 - val_loss: 68.5107\n",
      "Epoch 1419/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6873 - val_loss: 68.7184\n",
      "Epoch 1420/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8286 - val_loss: 68.1708\n",
      "Epoch 1421/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7725 - val_loss: 69.4294\n",
      "Epoch 1422/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3461 - val_loss: 68.7470\n",
      "Epoch 1423/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.4185 - val_loss: 70.3686\n",
      "Epoch 1424/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9058 - val_loss: 68.2884\n",
      "Epoch 1425/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0995 - val_loss: 71.8192\n",
      "Epoch 1426/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2660 - val_loss: 83.1067\n",
      "Epoch 1427/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5850 - val_loss: 68.0500\n",
      "Epoch 1428/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2882 - val_loss: 70.2326\n",
      "Epoch 1429/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6119 - val_loss: 69.0374\n",
      "Epoch 1430/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9018 - val_loss: 70.1590\n",
      "Epoch 1431/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.2653 - val_loss: 73.9133\n",
      "Epoch 1432/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9921 - val_loss: 68.6787\n",
      "Epoch 1433/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.3501 - val_loss: 69.2930\n",
      "Epoch 1434/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0711 - val_loss: 70.8017\n",
      "Epoch 1435/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.3324 - val_loss: 69.1950\n",
      "Epoch 1436/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3544 - val_loss: 70.7580\n",
      "Epoch 1437/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0446 - val_loss: 68.1522\n",
      "Epoch 1438/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1511 - val_loss: 67.9374\n",
      "Epoch 1439/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1806 - val_loss: 68.2900\n",
      "Epoch 1440/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3628 - val_loss: 68.6723\n",
      "Epoch 1441/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6068 - val_loss: 70.0573\n",
      "Epoch 1442/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8086 - val_loss: 70.3280\n",
      "Epoch 1443/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2001 - val_loss: 76.4463\n",
      "Epoch 1444/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3626 - val_loss: 67.9216\n",
      "Epoch 1445/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5835 - val_loss: 71.3400\n",
      "Epoch 1446/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8645 - val_loss: 68.1388\n",
      "Epoch 1447/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2539 - val_loss: 68.5009\n",
      "Epoch 1448/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.6090 - val_loss: 68.8443\n",
      "Epoch 1449/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1547 - val_loss: 70.7972\n",
      "Epoch 1450/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9635 - val_loss: 69.7906\n",
      "Epoch 1451/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4784 - val_loss: 68.8945\n",
      "Epoch 1452/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7038 - val_loss: 69.1480\n",
      "Epoch 1453/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7368 - val_loss: 69.4995\n",
      "Epoch 1454/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2982 - val_loss: 73.8685\n",
      "Epoch 1455/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.5945 - val_loss: 71.1038\n",
      "Epoch 1456/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5256 - val_loss: 80.4634\n",
      "Epoch 1457/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5417 - val_loss: 67.8830\n",
      "Epoch 1458/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.2176 - val_loss: 68.0779\n",
      "Epoch 1459/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4901 - val_loss: 68.7087\n",
      "Epoch 1460/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6953 - val_loss: 67.9412\n",
      "Epoch 1461/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4554 - val_loss: 67.9785\n",
      "Epoch 1462/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6739 - val_loss: 85.0890\n",
      "Epoch 1463/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1732 - val_loss: 68.3532\n",
      "Epoch 1464/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9325 - val_loss: 75.8376\n",
      "Epoch 1465/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6869 - val_loss: 68.3137\n",
      "Epoch 1466/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1988 - val_loss: 68.3463\n",
      "Epoch 1467/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0920 - val_loss: 68.5031\n",
      "Epoch 1468/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8287 - val_loss: 67.8501\n",
      "Epoch 1469/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.5898 - val_loss: 68.8145\n",
      "Epoch 1470/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0264 - val_loss: 67.9168\n",
      "Epoch 1471/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0536 - val_loss: 67.9248\n",
      "Epoch 1472/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3379 - val_loss: 73.5754\n",
      "Epoch 1473/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2772 - val_loss: 71.8394\n",
      "Epoch 1474/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1327 - val_loss: 70.0542\n",
      "Epoch 1475/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.0109 - val_loss: 72.0165\n",
      "Epoch 1476/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2351 - val_loss: 69.5464\n",
      "Epoch 1477/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3526 - val_loss: 68.3983\n",
      "Epoch 1478/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.7524 - val_loss: 70.7224\n",
      "Epoch 1479/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3574 - val_loss: 68.0792\n",
      "Epoch 1480/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0970 - val_loss: 68.5205\n",
      "Epoch 1481/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5668 - val_loss: 69.5672\n",
      "Epoch 1482/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0015 - val_loss: 68.4612\n",
      "Epoch 1483/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5648 - val_loss: 75.1214\n",
      "Epoch 1484/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0456 - val_loss: 67.9447\n",
      "Epoch 1485/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2687 - val_loss: 70.1551\n",
      "Epoch 1486/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8561 - val_loss: 68.6179\n",
      "Epoch 1487/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.6492 - val_loss: 68.7284\n",
      "Epoch 1488/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0595 - val_loss: 78.6335\n",
      "Epoch 1489/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8081 - val_loss: 70.4434\n",
      "Epoch 1490/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5183 - val_loss: 69.9248\n",
      "Epoch 1491/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3845 - val_loss: 70.3243\n",
      "Epoch 1492/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8343 - val_loss: 71.9148\n",
      "Epoch 1493/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5727 - val_loss: 71.5248\n",
      "Epoch 1494/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4205 - val_loss: 69.6769\n",
      "Epoch 1495/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2088 - val_loss: 69.1967\n",
      "Epoch 1496/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8248 - val_loss: 70.2268\n",
      "Epoch 1497/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4267 - val_loss: 70.6740\n",
      "Epoch 1498/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1381 - val_loss: 69.0658\n",
      "Epoch 1499/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5114 - val_loss: 68.5985\n",
      "Epoch 1500/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.4845 - val_loss: 67.9785\n",
      "Epoch 1501/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2963 - val_loss: 78.3435\n",
      "Epoch 1502/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4830 - val_loss: 72.5672\n",
      "Epoch 1503/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6209 - val_loss: 67.9243\n",
      "Epoch 1504/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2187 - val_loss: 69.0336\n",
      "Epoch 1505/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2402 - val_loss: 67.7151\n",
      "Epoch 1506/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.7725 - val_loss: 68.4780\n",
      "Epoch 1507/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5414 - val_loss: 68.8737\n",
      "Epoch 1508/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2359 - val_loss: 70.2163\n",
      "Epoch 1509/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4535 - val_loss: 68.5037\n",
      "Epoch 1510/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0317 - val_loss: 68.8053\n",
      "Epoch 1511/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7488 - val_loss: 69.7423\n",
      "Epoch 1512/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4044 - val_loss: 69.6800\n",
      "Epoch 1513/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5102 - val_loss: 69.4371\n",
      "Epoch 1514/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9682 - val_loss: 79.0397\n",
      "Epoch 1515/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5858 - val_loss: 70.4517\n",
      "Epoch 1516/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1796 - val_loss: 75.9997\n",
      "Epoch 1517/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6187 - val_loss: 68.5408\n",
      "Epoch 1518/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.7129 - val_loss: 69.6349\n",
      "Epoch 1519/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6195 - val_loss: 74.7859\n",
      "Epoch 1520/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2840 - val_loss: 77.4457\n",
      "Epoch 1521/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7403 - val_loss: 67.7438\n",
      "Epoch 1522/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8337 - val_loss: 71.1677\n",
      "Epoch 1523/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5065 - val_loss: 76.9644\n",
      "Epoch 1524/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4833 - val_loss: 70.2238\n",
      "Epoch 1525/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4088 - val_loss: 73.2651\n",
      "Epoch 1526/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 20.3548 - val_loss: 76.1993\n",
      "Epoch 1527/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7265 - val_loss: 67.9135\n",
      "Epoch 1528/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0139 - val_loss: 71.3724\n",
      "Epoch 1529/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1256 - val_loss: 68.4000\n",
      "Epoch 1530/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8885 - val_loss: 67.5923\n",
      "Epoch 1531/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.7738 - val_loss: 71.6780\n",
      "Epoch 1532/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2671 - val_loss: 68.8645\n",
      "Epoch 1533/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8933 - val_loss: 75.5950\n",
      "Epoch 1534/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9106 - val_loss: 70.0794\n",
      "Epoch 1535/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5438 - val_loss: 69.1773\n",
      "Epoch 1536/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9322 - val_loss: 68.1443\n",
      "Epoch 1537/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1794 - val_loss: 68.3468\n",
      "Epoch 1538/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0522 - val_loss: 69.4015\n",
      "Epoch 1539/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9653 - val_loss: 71.0339\n",
      "Epoch 1540/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5264 - val_loss: 76.0804\n",
      "Epoch 1541/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5054 - val_loss: 68.3886\n",
      "Epoch 1542/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3581 - val_loss: 69.3384\n",
      "Epoch 1543/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1642 - val_loss: 67.7019\n",
      "Epoch 1544/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1310 - val_loss: 68.9953\n",
      "Epoch 1545/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9192 - val_loss: 75.1724\n",
      "Epoch 1546/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0887 - val_loss: 68.1735\n",
      "Epoch 1547/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0329 - val_loss: 68.4773\n",
      "Epoch 1548/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8269 - val_loss: 67.9789\n",
      "Epoch 1549/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7967 - val_loss: 76.3068\n",
      "Epoch 1550/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1811 - val_loss: 69.1799\n",
      "Epoch 1551/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.6978 - val_loss: 68.9814\n",
      "Epoch 1552/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1768 - val_loss: 69.2309\n",
      "Epoch 1553/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4504 - val_loss: 73.8212\n",
      "Epoch 1554/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7645 - val_loss: 69.9868\n",
      "Epoch 1555/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5411 - val_loss: 67.9086\n",
      "Epoch 1556/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8187 - val_loss: 70.7799\n",
      "Epoch 1557/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5168 - val_loss: 68.1952\n",
      "Epoch 1558/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1944 - val_loss: 68.2162\n",
      "Epoch 1559/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3877 - val_loss: 72.1746\n",
      "Epoch 1560/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.6074 - val_loss: 68.6136\n",
      "Epoch 1561/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.3984 - val_loss: 68.8723\n",
      "Epoch 1562/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2580 - val_loss: 68.0448\n",
      "Epoch 1563/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1178 - val_loss: 76.8342\n",
      "Epoch 1564/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6073 - val_loss: 70.9541\n",
      "Epoch 1565/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1400 - val_loss: 67.7561\n",
      "Epoch 1566/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.4217 - val_loss: 68.2992\n",
      "Epoch 1567/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.4898 - val_loss: 68.6091\n",
      "Epoch 1568/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1278 - val_loss: 68.0371\n",
      "Epoch 1569/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2768 - val_loss: 68.5991\n",
      "Epoch 1570/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.1592 - val_loss: 69.7648\n",
      "Epoch 1571/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6337 - val_loss: 68.6394\n",
      "Epoch 1572/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2746 - val_loss: 72.7939\n",
      "Epoch 1573/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4317 - val_loss: 68.4511\n",
      "Epoch 1574/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5143 - val_loss: 73.7913\n",
      "Epoch 1575/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1155 - val_loss: 71.5323\n",
      "Epoch 1576/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1608 - val_loss: 68.0605\n",
      "Epoch 1577/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2822 - val_loss: 73.0791\n",
      "Epoch 1578/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8074 - val_loss: 68.3045\n",
      "Epoch 1579/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4861 - val_loss: 68.1784\n",
      "Epoch 1580/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.4195 - val_loss: 68.8627\n",
      "Epoch 1581/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1062 - val_loss: 69.0264\n",
      "Epoch 1582/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.7270 - val_loss: 69.6526\n",
      "Epoch 1583/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.5472 - val_loss: 71.5828\n",
      "Epoch 1584/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4236 - val_loss: 68.7358\n",
      "Epoch 1585/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1599 - val_loss: 68.5923\n",
      "Epoch 1586/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3116 - val_loss: 76.0058\n",
      "Epoch 1587/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8183 - val_loss: 67.9513\n",
      "Epoch 1588/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9976 - val_loss: 68.2130\n",
      "Epoch 1589/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4237 - val_loss: 68.7493\n",
      "Epoch 1590/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4280 - val_loss: 69.4535\n",
      "Epoch 1591/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1102 - val_loss: 76.0514\n",
      "Epoch 1592/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4774 - val_loss: 69.7948\n",
      "Epoch 1593/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9784 - val_loss: 68.5578\n",
      "Epoch 1594/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4262 - val_loss: 68.6203\n",
      "Epoch 1595/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 21.8575 - val_loss: 67.6753\n",
      "Epoch 1596/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8092 - val_loss: 70.4118\n",
      "Epoch 1597/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 21.3072 - val_loss: 73.7052\n",
      "Epoch 1598/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 20.9008 - val_loss: 68.1162\n",
      "Epoch 1599/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.6793 - val_loss: 68.4677\n",
      "Epoch 1600/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.3766 - val_loss: 68.8790\n",
      "Epoch 1601/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0523 - val_loss: 68.4928\n",
      "Epoch 1602/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8442 - val_loss: 67.9026\n",
      "Epoch 1603/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.5741 - val_loss: 67.9885\n",
      "Epoch 1604/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6262 - val_loss: 68.2298\n",
      "Epoch 1605/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3128 - val_loss: 72.0099\n",
      "Epoch 1606/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0589 - val_loss: 67.6278\n",
      "Epoch 1607/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3895 - val_loss: 67.9000\n",
      "Epoch 1608/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3150 - val_loss: 68.4484\n",
      "Epoch 1609/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8032 - val_loss: 75.8147\n",
      "Epoch 1610/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8892 - val_loss: 68.0456\n",
      "Epoch 1611/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9975 - val_loss: 71.0207\n",
      "Epoch 1612/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6404 - val_loss: 73.5934\n",
      "Epoch 1613/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1669 - val_loss: 75.1487\n",
      "Epoch 1614/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4722 - val_loss: 69.3206\n",
      "Epoch 1615/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8587 - val_loss: 73.3340\n",
      "Epoch 1616/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3472 - val_loss: 73.4548\n",
      "Epoch 1617/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8619 - val_loss: 68.6070\n",
      "Epoch 1618/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0297 - val_loss: 70.0062\n",
      "Epoch 1619/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.6589 - val_loss: 67.6320\n",
      "Epoch 1620/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8275 - val_loss: 70.5181\n",
      "Epoch 1621/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1140 - val_loss: 72.5068\n",
      "Epoch 1622/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.7707 - val_loss: 75.2163\n",
      "Epoch 1623/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2968 - val_loss: 70.2099\n",
      "Epoch 1624/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4694 - val_loss: 69.6790\n",
      "Epoch 1625/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9965 - val_loss: 68.1827\n",
      "Epoch 1626/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4659 - val_loss: 70.7363\n",
      "Epoch 1627/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3986 - val_loss: 69.5413\n",
      "Epoch 1628/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0316 - val_loss: 77.2186\n",
      "Epoch 1629/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.7420 - val_loss: 67.5912\n",
      "Epoch 1630/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3640 - val_loss: 67.6144\n",
      "Epoch 1631/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2563 - val_loss: 67.8791\n",
      "Epoch 1632/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9032 - val_loss: 69.5855\n",
      "Epoch 1633/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2247 - val_loss: 75.6398\n",
      "Epoch 1634/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7564 - val_loss: 73.4081\n",
      "Epoch 1635/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7490 - val_loss: 67.8721\n",
      "Epoch 1636/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7466 - val_loss: 69.1950\n",
      "Epoch 1637/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4024 - val_loss: 67.9670\n",
      "Epoch 1638/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9089 - val_loss: 67.6496\n",
      "Epoch 1639/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8942 - val_loss: 71.5832\n",
      "Epoch 1640/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1373 - val_loss: 69.5508\n",
      "Epoch 1641/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8504 - val_loss: 68.2191\n",
      "Epoch 1642/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1890 - val_loss: 69.4423\n",
      "Epoch 1643/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.7532 - val_loss: 70.8781\n",
      "Epoch 1644/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3264 - val_loss: 69.0962\n",
      "Epoch 1645/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3406 - val_loss: 72.6043\n",
      "Epoch 1646/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1682 - val_loss: 75.6178\n",
      "Epoch 1647/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1018 - val_loss: 70.0272\n",
      "Epoch 1648/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1525 - val_loss: 71.3134\n",
      "Epoch 1649/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.6596 - val_loss: 73.7982\n",
      "Epoch 1650/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4790 - val_loss: 69.5449\n",
      "Epoch 1651/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6851 - val_loss: 67.6986\n",
      "Epoch 1652/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3581 - val_loss: 75.5655\n",
      "Epoch 1653/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.8115 - val_loss: 70.2491\n",
      "Epoch 1654/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5993 - val_loss: 72.2760\n",
      "Epoch 1655/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5504 - val_loss: 71.0366\n",
      "Epoch 1656/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3256 - val_loss: 68.1982\n",
      "Epoch 1657/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2417 - val_loss: 70.1618\n",
      "Epoch 1658/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7350 - val_loss: 73.9300\n",
      "Epoch 1659/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7280 - val_loss: 70.6467\n",
      "Epoch 1660/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.7299 - val_loss: 70.0715\n",
      "Epoch 1661/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.5510 - val_loss: 67.9466\n",
      "Epoch 1662/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.7350 - val_loss: 72.2254\n",
      "Epoch 1663/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2136 - val_loss: 68.5829\n",
      "Epoch 1664/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6596 - val_loss: 68.2198\n",
      "Epoch 1665/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.5003 - val_loss: 68.3987\n",
      "Epoch 1666/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5033 - val_loss: 67.5757\n",
      "Epoch 1667/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.6465 - val_loss: 68.3574\n",
      "Epoch 1668/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5142 - val_loss: 67.5047\n",
      "Epoch 1669/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0576 - val_loss: 68.3542\n",
      "Epoch 1670/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8304 - val_loss: 78.2921\n",
      "Epoch 1671/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1865 - val_loss: 67.4153\n",
      "Epoch 1672/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8803 - val_loss: 70.7166\n",
      "Epoch 1673/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9976 - val_loss: 68.2281\n",
      "Epoch 1674/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0823 - val_loss: 68.2517\n",
      "Epoch 1675/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1596 - val_loss: 71.0560\n",
      "Epoch 1676/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0959 - val_loss: 73.7077\n",
      "Epoch 1677/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6469 - val_loss: 68.1025\n",
      "Epoch 1678/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 20.5813 - val_loss: 70.5740\n",
      "Epoch 1679/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0256 - val_loss: 71.1564\n",
      "Epoch 1680/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.6573 - val_loss: 69.0526\n",
      "Epoch 1681/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 21.4890 - val_loss: 82.5111\n",
      "Epoch 1682/2000\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 21.8056 - val_loss: 67.6511\n",
      "Epoch 1683/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 21.4625 - val_loss: 69.6253\n",
      "Epoch 1684/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3588 - val_loss: 69.9495\n",
      "Epoch 1685/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0797 - val_loss: 77.1682\n",
      "Epoch 1686/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4499 - val_loss: 70.7066\n",
      "Epoch 1687/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8073 - val_loss: 67.7521\n",
      "Epoch 1688/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0627 - val_loss: 70.4396\n",
      "Epoch 1689/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8009 - val_loss: 67.9636\n",
      "Epoch 1690/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8629 - val_loss: 68.3152\n",
      "Epoch 1691/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1657 - val_loss: 67.6210\n",
      "Epoch 1692/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8700 - val_loss: 75.6952\n",
      "Epoch 1693/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3963 - val_loss: 67.5855\n",
      "Epoch 1694/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5387 - val_loss: 71.7801\n",
      "Epoch 1695/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5954 - val_loss: 74.9933\n",
      "Epoch 1696/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2246 - val_loss: 74.6299\n",
      "Epoch 1697/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3928 - val_loss: 74.6458\n",
      "Epoch 1698/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4740 - val_loss: 68.7299\n",
      "Epoch 1699/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9001 - val_loss: 68.1484\n",
      "Epoch 1700/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7900 - val_loss: 67.6596\n",
      "Epoch 1701/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1194 - val_loss: 68.2461\n",
      "Epoch 1702/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8335 - val_loss: 67.6162\n",
      "Epoch 1703/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.7672 - val_loss: 68.7437\n",
      "Epoch 1704/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7082 - val_loss: 68.2885\n",
      "Epoch 1705/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2690 - val_loss: 70.3237\n",
      "Epoch 1706/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.4020 - val_loss: 67.6491\n",
      "Epoch 1707/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.3525 - val_loss: 68.6272\n",
      "Epoch 1708/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6206 - val_loss: 68.6584\n",
      "Epoch 1709/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2820 - val_loss: 71.5596\n",
      "Epoch 1710/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1297 - val_loss: 68.1274\n",
      "Epoch 1711/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.2290 - val_loss: 67.4464\n",
      "Epoch 1712/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6076 - val_loss: 67.8556\n",
      "Epoch 1713/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7517 - val_loss: 69.5198\n",
      "Epoch 1714/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0036 - val_loss: 67.6954\n",
      "Epoch 1715/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4939 - val_loss: 80.2306\n",
      "Epoch 1716/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0501 - val_loss: 68.5076\n",
      "Epoch 1717/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3979 - val_loss: 67.7174\n",
      "Epoch 1718/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3626 - val_loss: 68.3741\n",
      "Epoch 1719/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5526 - val_loss: 71.7216\n",
      "Epoch 1720/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7601 - val_loss: 67.4930\n",
      "Epoch 1721/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.7571 - val_loss: 67.7416\n",
      "Epoch 1722/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6854 - val_loss: 67.8997\n",
      "Epoch 1723/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8252 - val_loss: 71.3911\n",
      "Epoch 1724/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9114 - val_loss: 67.6834\n",
      "Epoch 1725/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8680 - val_loss: 69.7448\n",
      "Epoch 1726/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2510 - val_loss: 71.0473\n",
      "Epoch 1727/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.9988 - val_loss: 69.5086\n",
      "Epoch 1728/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8800 - val_loss: 72.2694\n",
      "Epoch 1729/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.5786 - val_loss: 68.8904\n",
      "Epoch 1730/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1788 - val_loss: 74.2430\n",
      "Epoch 1731/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2804 - val_loss: 73.2454\n",
      "Epoch 1732/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4341 - val_loss: 69.1180\n",
      "Epoch 1733/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6216 - val_loss: 70.0550\n",
      "Epoch 1734/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8972 - val_loss: 67.3383\n",
      "Epoch 1735/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0983 - val_loss: 69.8515\n",
      "Epoch 1736/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1061 - val_loss: 67.9523\n",
      "Epoch 1737/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0233 - val_loss: 68.2494\n",
      "Epoch 1738/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3451 - val_loss: 68.1871\n",
      "Epoch 1739/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6928 - val_loss: 67.7716\n",
      "Epoch 1740/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5325 - val_loss: 72.1336\n",
      "Epoch 1741/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9665 - val_loss: 68.3758\n",
      "Epoch 1742/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8155 - val_loss: 73.3011\n",
      "Epoch 1743/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 20.5295 - val_loss: 69.4563\n",
      "Epoch 1744/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2290 - val_loss: 78.1282\n",
      "Epoch 1745/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1275 - val_loss: 69.7117\n",
      "Epoch 1746/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8812 - val_loss: 67.8375\n",
      "Epoch 1747/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9978 - val_loss: 77.4180\n",
      "Epoch 1748/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0310 - val_loss: 69.4120\n",
      "Epoch 1749/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8929 - val_loss: 68.7169\n",
      "Epoch 1750/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1590 - val_loss: 69.5199\n",
      "Epoch 1751/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9576 - val_loss: 67.5470\n",
      "Epoch 1752/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.4301 - val_loss: 67.8337\n",
      "Epoch 1753/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7596 - val_loss: 69.1999\n",
      "Epoch 1754/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0416 - val_loss: 67.7350\n",
      "Epoch 1755/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1368 - val_loss: 79.0243\n",
      "Epoch 1756/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4006 - val_loss: 76.1142\n",
      "Epoch 1757/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6476 - val_loss: 72.8900\n",
      "Epoch 1758/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6401 - val_loss: 73.6982\n",
      "Epoch 1759/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4006 - val_loss: 68.7256\n",
      "Epoch 1760/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.4105 - val_loss: 69.9571\n",
      "Epoch 1761/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9065 - val_loss: 76.1469\n",
      "Epoch 1762/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2167 - val_loss: 69.8421\n",
      "Epoch 1763/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3776 - val_loss: 68.9624\n",
      "Epoch 1764/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7970 - val_loss: 67.5929\n",
      "Epoch 1765/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8332 - val_loss: 72.0242\n",
      "Epoch 1766/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3579 - val_loss: 67.7430\n",
      "Epoch 1767/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3882 - val_loss: 67.6660\n",
      "Epoch 1768/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1653 - val_loss: 68.2060\n",
      "Epoch 1769/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1937 - val_loss: 67.2895\n",
      "Epoch 1770/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6744 - val_loss: 70.0974\n",
      "Epoch 1771/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.6135 - val_loss: 72.4219\n",
      "Epoch 1772/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9140 - val_loss: 71.4473\n",
      "Epoch 1773/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 19.9101 - val_loss: 74.0237\n",
      "Epoch 1774/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1160 - val_loss: 72.4968\n",
      "Epoch 1775/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7139 - val_loss: 67.2792\n",
      "Epoch 1776/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1695 - val_loss: 67.9274\n",
      "Epoch 1777/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0200 - val_loss: 70.5840\n",
      "Epoch 1778/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8635 - val_loss: 67.6911\n",
      "Epoch 1779/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4717 - val_loss: 67.8938\n",
      "Epoch 1780/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5451 - val_loss: 76.0666\n",
      "Epoch 1781/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5583 - val_loss: 68.2607\n",
      "Epoch 1782/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.6729 - val_loss: 71.3011\n",
      "Epoch 1783/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4533 - val_loss: 68.9320\n",
      "Epoch 1784/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8989 - val_loss: 72.4798\n",
      "Epoch 1785/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9464 - val_loss: 68.7579\n",
      "Epoch 1786/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4638 - val_loss: 69.9968\n",
      "Epoch 1787/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4176 - val_loss: 68.2251\n",
      "Epoch 1788/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9770 - val_loss: 68.7104\n",
      "Epoch 1789/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 19.7848 - val_loss: 67.9806\n",
      "Epoch 1790/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6916 - val_loss: 67.9357\n",
      "Epoch 1791/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4568 - val_loss: 69.2142\n",
      "Epoch 1792/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6141 - val_loss: 75.9560\n",
      "Epoch 1793/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1917 - val_loss: 68.9806\n",
      "Epoch 1794/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5141 - val_loss: 68.2925\n",
      "Epoch 1795/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1378 - val_loss: 68.7152\n",
      "Epoch 1796/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6012 - val_loss: 67.5454\n",
      "Epoch 1797/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2412 - val_loss: 67.6341\n",
      "Epoch 1798/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3671 - val_loss: 68.1903\n",
      "Epoch 1799/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5503 - val_loss: 67.8926\n",
      "Epoch 1800/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.5055 - val_loss: 67.6285\n",
      "Epoch 1801/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8739 - val_loss: 67.9929\n",
      "Epoch 1802/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.6189 - val_loss: 68.7016\n",
      "Epoch 1803/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4281 - val_loss: 67.8295\n",
      "Epoch 1804/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0340 - val_loss: 71.4081\n",
      "Epoch 1805/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3566 - val_loss: 73.3627\n",
      "Epoch 1806/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8271 - val_loss: 68.6622\n",
      "Epoch 1807/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9086 - val_loss: 71.9512\n",
      "Epoch 1808/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.5727 - val_loss: 70.5333\n",
      "Epoch 1809/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.4347 - val_loss: 69.6064\n",
      "Epoch 1810/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6929 - val_loss: 72.2720\n",
      "Epoch 1811/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.0036 - val_loss: 67.3787\n",
      "Epoch 1812/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.1570 - val_loss: 69.2684\n",
      "Epoch 1813/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5676 - val_loss: 73.6653\n",
      "Epoch 1814/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6389 - val_loss: 67.6106\n",
      "Epoch 1815/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.5901 - val_loss: 67.5111\n",
      "Epoch 1816/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0138 - val_loss: 67.8786\n",
      "Epoch 1817/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4438 - val_loss: 67.3393\n",
      "Epoch 1818/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5574 - val_loss: 67.4738\n",
      "Epoch 1819/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9535 - val_loss: 68.8984\n",
      "Epoch 1820/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8095 - val_loss: 67.3907\n",
      "Epoch 1821/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4692 - val_loss: 71.9008\n",
      "Epoch 1822/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1749 - val_loss: 73.3969\n",
      "Epoch 1823/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2489 - val_loss: 67.9151\n",
      "Epoch 1824/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5909 - val_loss: 73.8401\n",
      "Epoch 1825/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.5366 - val_loss: 70.1846\n",
      "Epoch 1826/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2402 - val_loss: 75.3451\n",
      "Epoch 1827/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3097 - val_loss: 68.4758\n",
      "Epoch 1828/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9029 - val_loss: 67.6840\n",
      "Epoch 1829/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.1859 - val_loss: 67.7397\n",
      "Epoch 1830/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9562 - val_loss: 68.4800\n",
      "Epoch 1831/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 19.9154 - val_loss: 68.3916\n",
      "Epoch 1832/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5904 - val_loss: 69.0558\n",
      "Epoch 1833/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8641 - val_loss: 73.3221\n",
      "Epoch 1834/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8741 - val_loss: 68.2792\n",
      "Epoch 1835/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3608 - val_loss: 69.2940\n",
      "Epoch 1836/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1444 - val_loss: 68.4071\n",
      "Epoch 1837/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9853 - val_loss: 68.9311\n",
      "Epoch 1838/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.3070 - val_loss: 68.9849\n",
      "Epoch 1839/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7803 - val_loss: 68.1227\n",
      "Epoch 1840/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.6123 - val_loss: 67.5136\n",
      "Epoch 1841/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5041 - val_loss: 72.0449\n",
      "Epoch 1842/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.2978 - val_loss: 69.8222\n",
      "Epoch 1843/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.5803 - val_loss: 68.9933\n",
      "Epoch 1844/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.0219 - val_loss: 67.9860\n",
      "Epoch 1845/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9496 - val_loss: 72.7201\n",
      "Epoch 1846/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3394 - val_loss: 67.5391\n",
      "Epoch 1847/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4672 - val_loss: 68.2780\n",
      "Epoch 1848/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2164 - val_loss: 68.2017\n",
      "Epoch 1849/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4291 - val_loss: 78.8140\n",
      "Epoch 1850/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.7344 - val_loss: 67.5248\n",
      "Epoch 1851/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.6024 - val_loss: 68.0157\n",
      "Epoch 1852/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0957 - val_loss: 69.8828\n",
      "Epoch 1853/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2594 - val_loss: 67.4244\n",
      "Epoch 1854/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8059 - val_loss: 70.2146\n",
      "Epoch 1855/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6088 - val_loss: 67.5081\n",
      "Epoch 1856/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7336 - val_loss: 68.6303\n",
      "Epoch 1857/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1148 - val_loss: 72.0229\n",
      "Epoch 1858/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3935 - val_loss: 67.5952\n",
      "Epoch 1859/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3574 - val_loss: 67.2360\n",
      "Epoch 1860/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.1927 - val_loss: 67.8937\n",
      "Epoch 1861/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 19.9869 - val_loss: 69.5883\n",
      "Epoch 1862/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4486 - val_loss: 78.0257\n",
      "Epoch 1863/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8820 - val_loss: 73.6024\n",
      "Epoch 1864/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1059 - val_loss: 69.7997\n",
      "Epoch 1865/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.6695 - val_loss: 70.4396\n",
      "Epoch 1866/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6969 - val_loss: 67.8302\n",
      "Epoch 1867/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8554 - val_loss: 69.0596\n",
      "Epoch 1868/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6269 - val_loss: 71.5894\n",
      "Epoch 1869/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 19.6656 - val_loss: 68.0323\n",
      "Epoch 1870/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.4768 - val_loss: 67.4642\n",
      "Epoch 1871/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8685 - val_loss: 68.6538\n",
      "Epoch 1872/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4020 - val_loss: 68.1915\n",
      "Epoch 1873/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2800 - val_loss: 67.7877\n",
      "Epoch 1874/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2643 - val_loss: 93.5803\n",
      "Epoch 1875/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7065 - val_loss: 67.5918\n",
      "Epoch 1876/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3898 - val_loss: 67.9371\n",
      "Epoch 1877/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5809 - val_loss: 70.9829\n",
      "Epoch 1878/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3778 - val_loss: 67.9488\n",
      "Epoch 1879/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0304 - val_loss: 69.9346\n",
      "Epoch 1880/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6906 - val_loss: 68.5217\n",
      "Epoch 1881/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0920 - val_loss: 68.2850\n",
      "Epoch 1882/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.3499 - val_loss: 68.8464\n",
      "Epoch 1883/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.6753 - val_loss: 69.1018\n",
      "Epoch 1884/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7726 - val_loss: 75.3056\n",
      "Epoch 1885/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6787 - val_loss: 68.6430\n",
      "Epoch 1886/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9333 - val_loss: 75.6697\n",
      "Epoch 1887/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2311 - val_loss: 77.0243\n",
      "Epoch 1888/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9398 - val_loss: 74.0562\n",
      "Epoch 1889/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1512 - val_loss: 73.7788\n",
      "Epoch 1890/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0373 - val_loss: 70.9419\n",
      "Epoch 1891/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9400 - val_loss: 68.1949\n",
      "Epoch 1892/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.4532 - val_loss: 71.7785\n",
      "Epoch 1893/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3325 - val_loss: 75.2560\n",
      "Epoch 1894/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7025 - val_loss: 72.3494\n",
      "Epoch 1895/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.7812 - val_loss: 74.9270\n",
      "Epoch 1896/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.7020 - val_loss: 71.9795\n",
      "Epoch 1897/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5712 - val_loss: 70.6105\n",
      "Epoch 1898/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3977 - val_loss: 73.4845\n",
      "Epoch 1899/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.5489 - val_loss: 74.7450\n",
      "Epoch 1900/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6101 - val_loss: 68.8586\n",
      "Epoch 1901/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.6624 - val_loss: 67.6548\n",
      "Epoch 1902/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7750 - val_loss: 69.0997\n",
      "Epoch 1903/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5952 - val_loss: 77.6516\n",
      "Epoch 1904/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.7299 - val_loss: 68.2462\n",
      "Epoch 1905/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6129 - val_loss: 70.0399\n",
      "Epoch 1906/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0873 - val_loss: 70.4977\n",
      "Epoch 1907/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3461 - val_loss: 67.6452\n",
      "Epoch 1908/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1584 - val_loss: 72.1998\n",
      "Epoch 1909/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.6685 - val_loss: 67.2532\n",
      "Epoch 1910/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8267 - val_loss: 67.2316\n",
      "Epoch 1911/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.3226 - val_loss: 75.8007\n",
      "Epoch 1912/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.4664 - val_loss: 71.1262\n",
      "Epoch 1913/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3479 - val_loss: 70.5776\n",
      "Epoch 1914/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1997 - val_loss: 71.9184\n",
      "Epoch 1915/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.7843 - val_loss: 67.4211\n",
      "Epoch 1916/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5496 - val_loss: 74.0203\n",
      "Epoch 1917/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8059 - val_loss: 74.6030\n",
      "Epoch 1918/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 19.9762 - val_loss: 67.5950\n",
      "Epoch 1919/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8284 - val_loss: 68.5735\n",
      "Epoch 1920/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8325 - val_loss: 67.9451\n",
      "Epoch 1921/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1337 - val_loss: 67.6015\n",
      "Epoch 1922/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.4837 - val_loss: 69.5096\n",
      "Epoch 1923/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.5156 - val_loss: 68.2782\n",
      "Epoch 1924/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6176 - val_loss: 67.3652\n",
      "Epoch 1925/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5527 - val_loss: 67.7818\n",
      "Epoch 1926/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2325 - val_loss: 72.1079\n",
      "Epoch 1927/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2204 - val_loss: 71.3841\n",
      "Epoch 1928/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4345 - val_loss: 68.5698\n",
      "Epoch 1929/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4961 - val_loss: 68.3276\n",
      "Epoch 1930/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3681 - val_loss: 69.0799\n",
      "Epoch 1931/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9471 - val_loss: 74.2766\n",
      "Epoch 1932/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4393 - val_loss: 70.4905\n",
      "Epoch 1933/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1664 - val_loss: 70.9068\n",
      "Epoch 1934/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5348 - val_loss: 71.6452\n",
      "Epoch 1935/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8980 - val_loss: 70.3496\n",
      "Epoch 1936/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8921 - val_loss: 72.5709\n",
      "Epoch 1937/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9679 - val_loss: 70.8858\n",
      "Epoch 1938/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7478 - val_loss: 74.0572\n",
      "Epoch 1939/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2238 - val_loss: 76.2807\n",
      "Epoch 1940/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.7279 - val_loss: 75.8181\n",
      "Epoch 1941/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8248 - val_loss: 68.1501\n",
      "Epoch 1942/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0335 - val_loss: 67.8122\n",
      "Epoch 1943/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.3447 - val_loss: 68.2646\n",
      "Epoch 1944/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.4854 - val_loss: 69.9361\n",
      "Epoch 1945/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0032 - val_loss: 67.2644\n",
      "Epoch 1946/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0183 - val_loss: 67.8078\n",
      "Epoch 1947/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.4605 - val_loss: 67.8561\n",
      "Epoch 1948/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0419 - val_loss: 69.1252\n",
      "Epoch 1949/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2572 - val_loss: 67.6222\n",
      "Epoch 1950/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.4904 - val_loss: 67.7702\n",
      "Epoch 1951/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4754 - val_loss: 72.3378\n",
      "Epoch 1952/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0323 - val_loss: 68.8889\n",
      "Epoch 1953/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9702 - val_loss: 70.1783\n",
      "Epoch 1954/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2617 - val_loss: 67.8393\n",
      "Epoch 1955/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1938 - val_loss: 67.4538\n",
      "Epoch 1956/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2965 - val_loss: 67.6441\n",
      "Epoch 1957/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.2758 - val_loss: 74.3301\n",
      "Epoch 1958/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.1724 - val_loss: 69.7340\n",
      "Epoch 1959/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8235 - val_loss: 70.2717\n",
      "Epoch 1960/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5259 - val_loss: 71.5938\n",
      "Epoch 1961/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2653 - val_loss: 67.2595\n",
      "Epoch 1962/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.5245 - val_loss: 68.7364\n",
      "Epoch 1963/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9746 - val_loss: 67.1811\n",
      "Epoch 1964/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7711 - val_loss: 70.3550\n",
      "Epoch 1965/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.6028 - val_loss: 67.6027\n",
      "Epoch 1966/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6820 - val_loss: 67.9610\n",
      "Epoch 1967/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1833 - val_loss: 69.2769\n",
      "Epoch 1968/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.6684 - val_loss: 71.2845\n",
      "Epoch 1969/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0066 - val_loss: 71.0369\n",
      "Epoch 1970/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9065 - val_loss: 67.4399\n",
      "Epoch 1971/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6765 - val_loss: 67.5934\n",
      "Epoch 1972/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7075 - val_loss: 69.2273\n",
      "Epoch 1973/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.7411 - val_loss: 67.7259\n",
      "Epoch 1974/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8089 - val_loss: 71.3958\n",
      "Epoch 1975/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6832 - val_loss: 67.2647\n",
      "Epoch 1976/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7965 - val_loss: 67.6690\n",
      "Epoch 1977/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7569 - val_loss: 67.9372\n",
      "Epoch 1978/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7750 - val_loss: 68.1561\n",
      "Epoch 1979/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9402 - val_loss: 67.6794\n",
      "Epoch 1980/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4328 - val_loss: 69.2207\n",
      "Epoch 1981/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7328 - val_loss: 70.2350\n",
      "Epoch 1982/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1477 - val_loss: 73.0734\n",
      "Epoch 1983/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9958 - val_loss: 68.6409\n",
      "Epoch 1984/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5339 - val_loss: 73.8306\n",
      "Epoch 1985/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2250 - val_loss: 67.3770\n",
      "Epoch 1986/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5919 - val_loss: 73.8813\n",
      "Epoch 1987/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0602 - val_loss: 68.3942\n",
      "Epoch 1988/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2498 - val_loss: 69.8657\n",
      "Epoch 1989/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.2986 - val_loss: 67.5270\n",
      "Epoch 1990/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.2798 - val_loss: 72.2137\n",
      "Epoch 1991/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7428 - val_loss: 67.2906\n",
      "Epoch 1992/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2256 - val_loss: 69.0582\n",
      "Epoch 1993/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3228 - val_loss: 67.7940\n",
      "Epoch 1994/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8045 - val_loss: 73.4441\n",
      "Epoch 1995/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9310 - val_loss: 70.7845\n",
      "Epoch 1996/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.8385 - val_loss: 67.9140\n",
      "Epoch 1997/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7673 - val_loss: 68.0528\n",
      "Epoch 1998/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9347 - val_loss: 67.6338\n",
      "Epoch 1999/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2225 - val_loss: 84.6628\n",
      "Epoch 2000/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2456 - val_loss: 68.2949\n"
     ]
    }
   ],
   "source": [
    "#SAVE MODEL AFTER FITTING. If saved model is available, then reload that\n",
    "model = None\n",
    "model_history = pd.DataFrame()\n",
    "\n",
    "if os.path.exists(model_name_1):\n",
    "    print(\"Model Found: Loading...\")\n",
    "    model = load_model(model_name_1)\n",
    "    model_history = pd.read_csv(history_name_1)\n",
    "    print(model.summary())\n",
    "    print(\"Model Loaded!\")\n",
    "else:\n",
    "    print(\"Model not Found. Fitting model...\")\n",
    "    model, model_history = stock_model(num_features, epochs, optimizer, model_name_1, history_name_1)\n",
    "    model_history = model_history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "plt.plot(np.arange(0,epochs,1), model_history['val_loss'],'--', label='Baseline Val')\n",
    "plt.plot(np.arange(0,epochs,1), model_history['loss'], color='blue', label='Baseline Train')\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.xlim([0,max(np.arange(0,epochs,1))])\n",
    "plt.ylim([0,max(max(model_history['val_loss']),max(model_history['loss']))])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for preditions and error calculating\n",
    "def predict(model, input_data):\n",
    "    input_data = input_data.reshape(1,NUMBER_OF_DAYS_DATA_TO_USE,NUMBER_OF_COLUMNS)\n",
    "    value = model.predict(input_data, verbose=0)\n",
    "    return value[0][0]\n",
    "\n",
    "def check_all_test_data(data, model):\n",
    "    predicted_data = []\n",
    "    i = 1\n",
    "    for d in data:\n",
    "        print('.',end='')\n",
    "        if i%20 == 0: print('-',i)\n",
    "        d = d.reshape((1, NUMBER_OF_DAYS_DATA_TO_USE, NUMBER_OF_COLUMNS))\n",
    "        # below predicts the first value of the 5 predicted values\n",
    "        data = model.predict(d)\n",
    "        predicted_data.append(list(data[0]))\n",
    "        i = i+1\n",
    "    print('-',i)\n",
    "    return np.array(predicted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict values for the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Start predicting data...\n",
      "....................- 20\n",
      "....................- 40\n",
      "....................- 60\n",
      "....................- 80\n",
      "....................- 100\n",
      "....................- 120\n",
      "....................- 140\n",
      "....................- 160\n",
      "....................- 180\n",
      "....................- 200\n",
      "....................- 220\n",
      "....................- 240\n",
      ".- 242\n",
      "End of data prediction!\n"
     ]
    }
   ],
   "source": [
    "test_x,actual_y = convert_data_into_io(test_data,NUMBER_OF_DAYS_DATA_TO_USE,COLUMN_TO_PREDICT,NUMBER_OF_DAYS_DATA_TO_PREDICT)\n",
    "print(\"Start predicting data...\")\n",
    "predicted_y = check_all_test_data(test_x, model)\n",
    "print(\"End of data prediction!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### from matplotlib import pyplot as plt\n",
    "Below data shows the first predicted day of each set of 5 days that were predicted from each set of 15 prior days\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math \n",
    "\n",
    "#plot actual and predicted\n",
    "x_axis = np.arange(1,len(actual_y)+1)\n",
    "plt.plot(x_axis, predicted_y, label='predicted data')\n",
    "plt.plot(x_axis, actual_y[:,0], label='actual data')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f251ebab70>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.arange(1,len(actual_y)+1)\n",
    "plt.plot(x_axis, predicted_y[:,0], label='predicted data')\n",
    "plt.plot(x_axis, actual_y[:,0], label='actual data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates the MSE, RMSE, and visualizes the percentage differences for each set of predicted values when compared to the real closing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE =  97.99438128763225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f24a439240>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print RMSE\n",
    "mse = mean_squared_error(actual_y, predicted_y)\n",
    "rmse = math.sqrt(mse)\n",
    "print(\"RMSE = \",rmse)\n",
    "\n",
    "def percent_diff(actual, predicted):\n",
    "    return ((actual-predicted)/actual) * 100\n",
    "\n",
    "#get percent difference between actual and predicted\n",
    "difference = []\n",
    "for i in range(0,len(actual_y)):\n",
    "    difference.append(percent_diff(actual_y[i],predicted_y[i]))\n",
    "\n",
    "x_axis = np.arange(1,len(actual_y)+1)\n",
    "plt.plot(x_axis, difference, label='percent difference')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM MODEL (2000 Epochs with RMSPROP)\n",
    "Creating a 5 day closing stock price forecasting model with LSTM with 2000 epochs using rmsprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_2 = \"rmsprop\"\n",
    "model_name_2 = \"stock_model_2.h5\"\n",
    "history_name_2 = \"stock_model_history_2.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the model that uses RMSprop if it exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model not Found. Fitting model...\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_10 (LSTM)               (None, 100)               42400     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 42,905\n",
      "Trainable params: 42,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2000\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 79869.7578 - val_loss: 46965.1875\n",
      "Epoch 2/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23627.5859 - val_loss: 33412.2188\n",
      "Epoch 3/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 13731.8760 - val_loss: 15907.3672\n",
      "Epoch 4/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 6960.6802 - val_loss: 7928.9585\n",
      "Epoch 5/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4821.1880 - val_loss: 5434.1655\n",
      "Epoch 6/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2404.0942 - val_loss: 2802.0662\n",
      "Epoch 7/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1667.6909 - val_loss: 2067.8315\n",
      "Epoch 8/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1030.8136 - val_loss: 1563.6584\n",
      "Epoch 9/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 948.8388 - val_loss: 1395.5093\n",
      "Epoch 10/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 752.4704 - val_loss: 995.1111\n",
      "Epoch 11/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 693.2158 - val_loss: 1063.6395\n",
      "Epoch 12/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 660.4354 - val_loss: 1106.3320\n",
      "Epoch 13/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 611.2254 - val_loss: 697.8740\n",
      "Epoch 14/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 591.1266 - val_loss: 1193.5996\n",
      "Epoch 15/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 573.5587 - val_loss: 754.9094\n",
      "Epoch 16/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 545.2761 - val_loss: 1497.5127\n",
      "Epoch 17/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 539.7131 - val_loss: 699.4830\n",
      "Epoch 18/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 509.8028 - val_loss: 1014.3563\n",
      "Epoch 19/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 500.1937 - val_loss: 849.2263\n",
      "Epoch 20/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 485.3760 - val_loss: 521.5912\n",
      "Epoch 21/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 464.7489 - val_loss: 871.6023\n",
      "Epoch 22/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 443.6575 - val_loss: 605.6182\n",
      "Epoch 23/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 441.1073 - val_loss: 411.7913\n",
      "Epoch 24/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 436.7463 - val_loss: 497.0389\n",
      "Epoch 25/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 410.4379 - val_loss: 387.8457\n",
      "Epoch 26/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 409.8144 - val_loss: 1213.1620\n",
      "Epoch 27/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 399.2718 - val_loss: 608.8893\n",
      "Epoch 28/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 393.9048 - val_loss: 1239.7590\n",
      "Epoch 29/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 371.9625 - val_loss: 633.3030\n",
      "Epoch 30/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 368.7133 - val_loss: 608.3366\n",
      "Epoch 31/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 354.4370 - val_loss: 557.1146\n",
      "Epoch 32/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 358.5087 - val_loss: 376.0031\n",
      "Epoch 33/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 345.7645 - val_loss: 855.0223\n",
      "Epoch 34/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 340.2878 - val_loss: 659.2988\n",
      "Epoch 35/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 338.4153 - val_loss: 367.2334\n",
      "Epoch 36/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 321.4370 - val_loss: 543.2012\n",
      "Epoch 37/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 318.7155 - val_loss: 283.5177\n",
      "Epoch 38/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 317.3798 - val_loss: 242.0380\n",
      "Epoch 39/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 312.4721 - val_loss: 264.2881\n",
      "Epoch 40/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 312.1009 - val_loss: 549.1530\n",
      "Epoch 41/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 304.2576 - val_loss: 272.6309\n",
      "Epoch 42/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 302.6764 - val_loss: 462.9599\n",
      "Epoch 43/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 291.5169 - val_loss: 365.3877\n",
      "Epoch 44/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 295.0809 - val_loss: 368.3626\n",
      "Epoch 45/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 284.0747 - val_loss: 428.5359\n",
      "Epoch 46/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 283.0056 - val_loss: 530.5110\n",
      "Epoch 47/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 279.9085 - val_loss: 446.9634\n",
      "Epoch 48/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 278.6783 - val_loss: 442.1306\n",
      "Epoch 49/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 274.6882 - val_loss: 399.0483\n",
      "Epoch 50/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 262.9050 - val_loss: 250.6337\n",
      "Epoch 51/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 265.0160 - val_loss: 328.0209\n",
      "Epoch 52/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 259.3871 - val_loss: 207.8740\n",
      "Epoch 53/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 251.8515 - val_loss: 239.4805\n",
      "Epoch 54/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 249.2523 - val_loss: 354.1161\n",
      "Epoch 55/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 249.3824 - val_loss: 376.8988\n",
      "Epoch 56/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 249.7015 - val_loss: 479.6063\n",
      "Epoch 57/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 246.7260 - val_loss: 322.9887\n",
      "Epoch 58/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 237.9384 - val_loss: 521.6153\n",
      "Epoch 59/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 240.7406 - val_loss: 426.3151\n",
      "Epoch 60/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 233.0653 - val_loss: 598.5013\n",
      "Epoch 61/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 228.7364 - val_loss: 606.1764\n",
      "Epoch 62/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 221.3817 - val_loss: 284.9209\n",
      "Epoch 63/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 224.8015 - val_loss: 357.4285\n",
      "Epoch 64/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 223.6340 - val_loss: 353.7207\n",
      "Epoch 65/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 219.9299 - val_loss: 244.7980\n",
      "Epoch 66/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 218.4020 - val_loss: 215.9469\n",
      "Epoch 67/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 212.4440 - val_loss: 409.4761\n",
      "Epoch 68/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 209.4857 - val_loss: 553.1525\n",
      "Epoch 69/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 202.6131 - val_loss: 352.4806\n",
      "Epoch 70/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 200.5054 - val_loss: 346.2710\n",
      "Epoch 71/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 197.4107 - val_loss: 515.3751\n",
      "Epoch 72/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 193.7011 - val_loss: 498.5446\n",
      "Epoch 73/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 191.4780 - val_loss: 257.1463\n",
      "Epoch 74/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 191.8037 - val_loss: 199.5316\n",
      "Epoch 75/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 189.8105 - val_loss: 313.8122\n",
      "Epoch 76/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 183.9706 - val_loss: 528.5880\n",
      "Epoch 77/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 184.7020 - val_loss: 334.0442\n",
      "Epoch 78/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 183.5093 - val_loss: 381.4345\n",
      "Epoch 79/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 275.4794 - val_loss: 275.0817\n",
      "Epoch 80/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 201.1046 - val_loss: 199.5822\n",
      "Epoch 81/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 167.8263 - val_loss: 327.4691\n",
      "Epoch 82/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 158.6893 - val_loss: 272.1911\n",
      "Epoch 83/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 150.4217 - val_loss: 143.1416\n",
      "Epoch 84/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 145.1770 - val_loss: 169.8002\n",
      "Epoch 85/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 144.9113 - val_loss: 295.4681\n",
      "Epoch 86/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 142.2835 - val_loss: 145.8793\n",
      "Epoch 87/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 137.4078 - val_loss: 391.9207\n",
      "Epoch 88/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 138.7666 - val_loss: 238.1747\n",
      "Epoch 89/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 135.2737 - val_loss: 159.8535\n",
      "Epoch 90/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 132.4834 - val_loss: 380.6397\n",
      "Epoch 91/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 130.7740 - val_loss: 295.8899\n",
      "Epoch 92/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 138.2345 - val_loss: 358.1835\n",
      "Epoch 93/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 127.5668 - val_loss: 247.0222\n",
      "Epoch 94/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 125.3726 - val_loss: 222.0716\n",
      "Epoch 95/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 123.2014 - val_loss: 287.9558\n",
      "Epoch 96/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 120.9426 - val_loss: 220.3467\n",
      "Epoch 97/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 121.1727 - val_loss: 313.0746\n",
      "Epoch 98/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 121.8168 - val_loss: 208.0487\n",
      "Epoch 99/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 122.6166 - val_loss: 99.1868\n",
      "Epoch 100/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 124.5508 - val_loss: 507.4523\n",
      "Epoch 101/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 127.5635 - val_loss: 134.1581\n",
      "Epoch 102/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 117.7473 - val_loss: 123.5868\n",
      "Epoch 103/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 124.5040 - val_loss: 112.6802\n",
      "Epoch 104/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 118.8001 - val_loss: 279.2119\n",
      "Epoch 105/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 116.5645 - val_loss: 177.2144\n",
      "Epoch 106/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 116.2885 - val_loss: 178.5262\n",
      "Epoch 107/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 117.3241 - val_loss: 104.0516\n",
      "Epoch 108/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 115.8538 - val_loss: 237.8127\n",
      "Epoch 109/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 119.6551 - val_loss: 334.6986\n",
      "Epoch 110/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 113.9103 - val_loss: 255.1751\n",
      "Epoch 111/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 113.1744 - val_loss: 144.0024\n",
      "Epoch 112/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 115.7406 - val_loss: 244.6218\n",
      "Epoch 113/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 113.5886 - val_loss: 211.6004\n",
      "Epoch 114/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 109.0965 - val_loss: 216.0703\n",
      "Epoch 115/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 109.6299 - val_loss: 101.1547\n",
      "Epoch 116/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 108.1333 - val_loss: 253.2768\n",
      "Epoch 117/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 108.1179 - val_loss: 115.5601\n",
      "Epoch 118/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 107.8915 - val_loss: 226.5847\n",
      "Epoch 119/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 106.9704 - val_loss: 205.0665\n",
      "Epoch 120/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 111.7387 - val_loss: 166.5614\n",
      "Epoch 121/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 104.0310 - val_loss: 274.1787\n",
      "Epoch 122/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 104.8640 - val_loss: 204.7461\n",
      "Epoch 123/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 113.8999 - val_loss: 150.3032\n",
      "Epoch 124/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 102.3535 - val_loss: 203.9945\n",
      "Epoch 125/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 102.7857 - val_loss: 263.7962\n",
      "Epoch 126/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 99.4519 - val_loss: 115.7494\n",
      "Epoch 127/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 99.0757 - val_loss: 127.0865\n",
      "Epoch 128/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 99.4618 - val_loss: 147.8588\n",
      "Epoch 129/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 100.6120 - val_loss: 111.9784\n",
      "Epoch 130/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 98.6627 - val_loss: 222.6495\n",
      "Epoch 131/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 99.9113 - val_loss: 300.7722\n",
      "Epoch 132/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 98.1673 - val_loss: 118.5569\n",
      "Epoch 133/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 96.5031 - val_loss: 132.7962\n",
      "Epoch 134/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 98.7230 - val_loss: 156.1173\n",
      "Epoch 135/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 96.0583 - val_loss: 184.1705\n",
      "Epoch 136/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 102.6579 - val_loss: 184.1901\n",
      "Epoch 137/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 97.7025 - val_loss: 302.8074\n",
      "Epoch 138/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 98.2125 - val_loss: 110.2444\n",
      "Epoch 139/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 98.1510 - val_loss: 188.0338\n",
      "Epoch 140/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 96.1501 - val_loss: 149.5421\n",
      "Epoch 141/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 99.8113 - val_loss: 143.0676\n",
      "Epoch 142/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 97.5235 - val_loss: 112.1942\n",
      "Epoch 143/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 97.8626 - val_loss: 205.5215\n",
      "Epoch 144/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 92.7798 - val_loss: 135.1449\n",
      "Epoch 145/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 97.4347 - val_loss: 196.3674\n",
      "Epoch 146/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 94.5437 - val_loss: 127.0798\n",
      "Epoch 147/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 6ms/step - loss: 94.7594 - val_loss: 138.8077\n",
      "Epoch 148/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 92.0829 - val_loss: 197.7938\n",
      "Epoch 149/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 90.9097 - val_loss: 215.2166\n",
      "Epoch 150/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 92.9369 - val_loss: 196.2108\n",
      "Epoch 151/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 92.9078 - val_loss: 133.2754\n",
      "Epoch 152/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 88.8766 - val_loss: 154.7815\n",
      "Epoch 153/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 93.8998 - val_loss: 217.0054\n",
      "Epoch 154/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 90.0482 - val_loss: 174.6668\n",
      "Epoch 155/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 87.3483 - val_loss: 147.6659\n",
      "Epoch 156/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 91.6060 - val_loss: 142.7870\n",
      "Epoch 157/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 88.8776 - val_loss: 513.2384\n",
      "Epoch 158/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 90.2537 - val_loss: 122.6039\n",
      "Epoch 159/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 87.3504 - val_loss: 198.9544\n",
      "Epoch 160/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 90.7196 - val_loss: 119.9000\n",
      "Epoch 161/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 87.7792 - val_loss: 231.2765\n",
      "Epoch 162/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 89.4099 - val_loss: 192.8491\n",
      "Epoch 163/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 91.1075 - val_loss: 171.5499\n",
      "Epoch 164/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 85.4877 - val_loss: 145.9282\n",
      "Epoch 165/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 86.7466 - val_loss: 177.1032\n",
      "Epoch 166/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 85.4087 - val_loss: 228.3990\n",
      "Epoch 167/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 85.8228 - val_loss: 223.0299\n",
      "Epoch 168/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 88.6545 - val_loss: 141.2930\n",
      "Epoch 169/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 109.9872 - val_loss: 122.2488\n",
      "Epoch 170/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 85.2657 - val_loss: 193.6316\n",
      "Epoch 171/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 83.6567 - val_loss: 139.3656\n",
      "Epoch 172/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 85.2828 - val_loss: 351.1582\n",
      "Epoch 173/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 82.5478 - val_loss: 126.3791\n",
      "Epoch 174/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 85.5506 - val_loss: 178.6724\n",
      "Epoch 175/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 81.9017 - val_loss: 156.0878\n",
      "Epoch 176/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 82.8930 - val_loss: 140.5611\n",
      "Epoch 177/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 83.3519 - val_loss: 145.2953\n",
      "Epoch 178/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 82.0513 - val_loss: 231.5756\n",
      "Epoch 179/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 80.3668 - val_loss: 241.3842\n",
      "Epoch 180/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 82.6455 - val_loss: 185.5465\n",
      "Epoch 181/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 83.7027 - val_loss: 173.1170\n",
      "Epoch 182/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 86.6289 - val_loss: 124.9811\n",
      "Epoch 183/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 82.8418 - val_loss: 217.1209\n",
      "Epoch 184/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 80.7615 - val_loss: 154.8691\n",
      "Epoch 185/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 78.5260 - val_loss: 149.8940\n",
      "Epoch 186/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 79.8651 - val_loss: 149.2513\n",
      "Epoch 187/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 79.9835 - val_loss: 143.4825\n",
      "Epoch 188/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 82.7150 - val_loss: 157.0518\n",
      "Epoch 189/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 87.1729 - val_loss: 173.4361\n",
      "Epoch 190/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 104.8642 - val_loss: 149.5115\n",
      "Epoch 191/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 93.4000 - val_loss: 131.4705\n",
      "Epoch 192/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 86.1116 - val_loss: 144.5077\n",
      "Epoch 193/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 82.7131 - val_loss: 150.0405\n",
      "Epoch 194/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 87.5556 - val_loss: 146.8690\n",
      "Epoch 195/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 84.5308 - val_loss: 133.5383\n",
      "Epoch 196/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 81.2178 - val_loss: 175.4622\n",
      "Epoch 197/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 85.2070 - val_loss: 206.2948\n",
      "Epoch 198/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 84.3012 - val_loss: 190.2058\n",
      "Epoch 199/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 82.9138 - val_loss: 138.1052\n",
      "Epoch 200/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 79.2829 - val_loss: 220.4970\n",
      "Epoch 201/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 81.6622 - val_loss: 133.6769\n",
      "Epoch 202/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 82.6137 - val_loss: 122.8020\n",
      "Epoch 203/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 80.6990 - val_loss: 189.7527\n",
      "Epoch 204/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 78.0493 - val_loss: 122.6422\n",
      "Epoch 205/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 77.2629 - val_loss: 112.8282\n",
      "Epoch 206/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 80.7313 - val_loss: 135.4854\n",
      "Epoch 207/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 78.5801 - val_loss: 183.8828\n",
      "Epoch 208/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 76.5924 - val_loss: 134.5152\n",
      "Epoch 209/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 78.5998 - val_loss: 165.7067\n",
      "Epoch 210/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 78.3793 - val_loss: 148.9169\n",
      "Epoch 211/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 78.5198 - val_loss: 195.0591\n",
      "Epoch 212/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 77.9720 - val_loss: 112.4887\n",
      "Epoch 213/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 78.3181 - val_loss: 132.4425\n",
      "Epoch 214/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 75.1423 - val_loss: 206.5097\n",
      "Epoch 215/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 77.4807 - val_loss: 130.6314\n",
      "Epoch 216/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 75.7330 - val_loss: 151.2096\n",
      "Epoch 217/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 78.1902 - val_loss: 102.7714\n",
      "Epoch 218/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 75.7982 - val_loss: 134.3176\n",
      "Epoch 219/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 77.5504 - val_loss: 113.2065\n",
      "Epoch 220/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 84.5238 - val_loss: 170.3566\n",
      "Epoch 221/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 79.7182 - val_loss: 174.6003\n",
      "Epoch 222/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 73.4050 - val_loss: 147.7720\n",
      "Epoch 223/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 76.1980 - val_loss: 207.7079\n",
      "Epoch 224/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 77.6526 - val_loss: 222.5934\n",
      "Epoch 225/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 75.6489 - val_loss: 160.0141\n",
      "Epoch 226/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 74.7466 - val_loss: 162.2675\n",
      "Epoch 227/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 73.5337 - val_loss: 136.8109\n",
      "Epoch 228/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 77.1259 - val_loss: 195.5114\n",
      "Epoch 229/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 75.6801 - val_loss: 205.2400\n",
      "Epoch 230/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 73.2931 - val_loss: 181.6897\n",
      "Epoch 231/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 75.2626 - val_loss: 190.4331\n",
      "Epoch 232/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 71.5994 - val_loss: 177.7542\n",
      "Epoch 233/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 71.5943 - val_loss: 121.4668\n",
      "Epoch 234/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 71.9992 - val_loss: 120.1731\n",
      "Epoch 235/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 74.0458 - val_loss: 104.2288\n",
      "Epoch 236/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 72.3317 - val_loss: 209.9899\n",
      "Epoch 237/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 72.2405 - val_loss: 197.7662\n",
      "Epoch 238/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 71.9827 - val_loss: 147.8063\n",
      "Epoch 239/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 69.0475 - val_loss: 110.9889\n",
      "Epoch 240/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 70.9591 - val_loss: 107.6912\n",
      "Epoch 241/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 71.7276 - val_loss: 226.4114\n",
      "Epoch 242/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 70.6975 - val_loss: 110.8227\n",
      "Epoch 243/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 73.0507 - val_loss: 135.8711\n",
      "Epoch 244/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 71.0631 - val_loss: 172.5295\n",
      "Epoch 245/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 70.3767 - val_loss: 203.4308\n",
      "Epoch 246/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 71.6095 - val_loss: 153.2690\n",
      "Epoch 247/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 68.5656 - val_loss: 353.6165\n",
      "Epoch 248/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 68.3018 - val_loss: 154.5667\n",
      "Epoch 249/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 68.0814 - val_loss: 311.5083\n",
      "Epoch 250/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 69.6080 - val_loss: 142.1657\n",
      "Epoch 251/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 67.8151 - val_loss: 186.9695\n",
      "Epoch 252/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 68.5390 - val_loss: 107.6745\n",
      "Epoch 253/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 67.5939 - val_loss: 147.7667\n",
      "Epoch 254/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 65.8594 - val_loss: 105.7393\n",
      "Epoch 255/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 64.4080 - val_loss: 138.7436\n",
      "Epoch 256/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 67.7074 - val_loss: 110.9029\n",
      "Epoch 257/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 63.9784 - val_loss: 104.4205\n",
      "Epoch 258/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 66.2216 - val_loss: 160.8905\n",
      "Epoch 259/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 65.1636 - val_loss: 101.9492\n",
      "Epoch 260/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 67.3467 - val_loss: 115.9583\n",
      "Epoch 261/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 64.2759 - val_loss: 130.0385\n",
      "Epoch 262/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 64.9120 - val_loss: 184.7646\n",
      "Epoch 263/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 66.1928 - val_loss: 137.3701\n",
      "Epoch 264/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 62.8648 - val_loss: 132.0353\n",
      "Epoch 265/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 64.6168 - val_loss: 103.5035\n",
      "Epoch 266/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 63.3124 - val_loss: 129.0182\n",
      "Epoch 267/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 62.7696 - val_loss: 105.3882\n",
      "Epoch 268/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 63.2640 - val_loss: 135.6047\n",
      "Epoch 269/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 63.1417 - val_loss: 136.1765\n",
      "Epoch 270/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 63.8515 - val_loss: 108.0884\n",
      "Epoch 271/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 66.1584 - val_loss: 100.6082\n",
      "Epoch 272/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 62.7605 - val_loss: 117.3714\n",
      "Epoch 273/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 64.7182 - val_loss: 102.8706\n",
      "Epoch 274/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 63.6508 - val_loss: 130.7973\n",
      "Epoch 275/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 64.5334 - val_loss: 153.0542\n",
      "Epoch 276/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 64.2155 - val_loss: 142.9663\n",
      "Epoch 277/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 63.0573 - val_loss: 159.9217\n",
      "Epoch 278/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 63.4143 - val_loss: 109.7201\n",
      "Epoch 279/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 62.9859 - val_loss: 164.6167\n",
      "Epoch 280/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 63.2086 - val_loss: 192.0489\n",
      "Epoch 281/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 64.5743 - val_loss: 152.7944\n",
      "Epoch 282/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 63.8753 - val_loss: 203.3634\n",
      "Epoch 283/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 63.4059 - val_loss: 141.6633\n",
      "Epoch 284/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 63.4013 - val_loss: 106.9499\n",
      "Epoch 285/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 62.3300 - val_loss: 130.7944\n",
      "Epoch 286/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 61.7513 - val_loss: 121.8431\n",
      "Epoch 287/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 60.7889 - val_loss: 148.6336\n",
      "Epoch 288/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 64.2042 - val_loss: 97.1581\n",
      "Epoch 289/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 62.7980 - val_loss: 156.6273\n",
      "Epoch 290/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 62.9140 - val_loss: 104.5726\n",
      "Epoch 291/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 60.8184 - val_loss: 181.5032\n",
      "Epoch 292/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 61.3093 - val_loss: 99.7076\n",
      "Epoch 293/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 62.9972 - val_loss: 154.6202\n",
      "Epoch 294/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 62.2046 - val_loss: 125.9097\n",
      "Epoch 295/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 62.6557 - val_loss: 134.7966\n",
      "Epoch 296/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 65.0203 - val_loss: 140.1800\n",
      "Epoch 297/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 62.1667 - val_loss: 110.5471\n",
      "Epoch 298/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 61.1293 - val_loss: 100.7202\n",
      "Epoch 299/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 61.7203 - val_loss: 112.5122\n",
      "Epoch 300/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 61.2202 - val_loss: 203.7601\n",
      "Epoch 301/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 62.4784 - val_loss: 183.0710\n",
      "Epoch 302/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 60.2900 - val_loss: 134.6347\n",
      "Epoch 303/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 61.6586 - val_loss: 113.9987\n",
      "Epoch 304/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 59.5741 - val_loss: 99.3094\n",
      "Epoch 305/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 61.3734 - val_loss: 139.7100\n",
      "Epoch 306/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 62.0058 - val_loss: 179.2345\n",
      "Epoch 307/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 60.2801 - val_loss: 130.7423\n",
      "Epoch 308/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 59.5648 - val_loss: 113.6894\n",
      "Epoch 309/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 60.4975 - val_loss: 146.0060\n",
      "Epoch 310/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 60.6920 - val_loss: 145.3580\n",
      "Epoch 311/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 62.6920 - val_loss: 110.0563\n",
      "Epoch 312/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 61.8095 - val_loss: 119.9577\n",
      "Epoch 313/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 61.3689 - val_loss: 99.5892\n",
      "Epoch 314/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 59.4064 - val_loss: 163.3168\n",
      "Epoch 315/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 60.5561 - val_loss: 103.5241\n",
      "Epoch 316/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 59.9658 - val_loss: 145.2987\n",
      "Epoch 317/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 61.6851 - val_loss: 139.2597\n",
      "Epoch 318/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 60.6394 - val_loss: 99.0455\n",
      "Epoch 319/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 67.4621 - val_loss: 132.9675\n",
      "Epoch 320/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 59.8114 - val_loss: 150.2536\n",
      "Epoch 321/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 60.0652 - val_loss: 108.1133\n",
      "Epoch 322/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 59.9408 - val_loss: 109.0125\n",
      "Epoch 323/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 60.0871 - val_loss: 118.3083\n",
      "Epoch 324/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 60.1444 - val_loss: 154.6007\n",
      "Epoch 325/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 60.4489 - val_loss: 100.8985\n",
      "Epoch 326/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 60.0508 - val_loss: 107.1899\n",
      "Epoch 327/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 60.9380 - val_loss: 127.6919\n",
      "Epoch 328/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 58.2341 - val_loss: 177.0044\n",
      "Epoch 329/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 60.3904 - val_loss: 105.9673\n",
      "Epoch 330/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 60.2066 - val_loss: 109.5536\n",
      "Epoch 331/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 58.9371 - val_loss: 104.1423\n",
      "Epoch 332/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 59.1682 - val_loss: 103.0348\n",
      "Epoch 333/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 61.1189 - val_loss: 127.7872\n",
      "Epoch 334/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 59.9344 - val_loss: 138.8488\n",
      "Epoch 335/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 58.9940 - val_loss: 101.3147\n",
      "Epoch 336/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 60.0114 - val_loss: 102.4112\n",
      "Epoch 337/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 78.9755 - val_loss: 106.2930\n",
      "Epoch 338/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 59.0404 - val_loss: 158.6379\n",
      "Epoch 339/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 60.4897 - val_loss: 102.4556\n",
      "Epoch 340/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 59.9237 - val_loss: 134.0205\n",
      "Epoch 341/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 59.1549 - val_loss: 100.1489\n",
      "Epoch 342/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 61.7636 - val_loss: 101.0915\n",
      "Epoch 343/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 78.8997 - val_loss: 132.0744\n",
      "Epoch 344/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 60.0846 - val_loss: 100.5150\n",
      "Epoch 345/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 59.5414 - val_loss: 111.4491\n",
      "Epoch 346/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 58.7561 - val_loss: 142.8684\n",
      "Epoch 347/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 59.9904 - val_loss: 105.7307\n",
      "Epoch 348/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 64.5030 - val_loss: 179.2367\n",
      "Epoch 349/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 59.2469 - val_loss: 124.6842\n",
      "Epoch 350/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 58.0008 - val_loss: 117.3410\n",
      "Epoch 351/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 58.8976 - val_loss: 165.6442\n",
      "Epoch 352/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 59.1111 - val_loss: 171.3253\n",
      "Epoch 353/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 58.7708 - val_loss: 98.6108\n",
      "Epoch 354/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 57.7509 - val_loss: 203.0917\n",
      "Epoch 355/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 58.8590 - val_loss: 155.0314\n",
      "Epoch 356/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 61.5257 - val_loss: 121.7339\n",
      "Epoch 357/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 58.9391 - val_loss: 101.8396\n",
      "Epoch 358/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 58.3024 - val_loss: 118.4141\n",
      "Epoch 359/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 57.4433 - val_loss: 157.2036\n",
      "Epoch 360/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 57.4522 - val_loss: 116.0503\n",
      "Epoch 361/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 63.7382 - val_loss: 115.3800\n",
      "Epoch 362/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 59.8735 - val_loss: 134.0153\n",
      "Epoch 363/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 59.4465 - val_loss: 107.4502\n",
      "Epoch 364/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 57.3097 - val_loss: 136.4977\n",
      "Epoch 365/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 60.9587 - val_loss: 157.2267\n",
      "Epoch 366/2000\n",
      "152/152 [==============================] - ETA: 0s - loss: 57.42 - 1s 7ms/step - loss: 57.9077 - val_loss: 134.4376\n",
      "Epoch 367/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 56.6138 - val_loss: 98.8463\n",
      "Epoch 368/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 58.7967 - val_loss: 100.6506\n",
      "Epoch 369/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 58.4584 - val_loss: 129.0645\n",
      "Epoch 370/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 58.7918 - val_loss: 100.5792\n",
      "Epoch 371/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 70.6113 - val_loss: 117.9471\n",
      "Epoch 372/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 64.7698 - val_loss: 153.1802\n",
      "Epoch 373/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 58.2613 - val_loss: 141.6475\n",
      "Epoch 374/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 59.7053 - val_loss: 124.4483\n",
      "Epoch 375/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 59.8291 - val_loss: 107.3287\n",
      "Epoch 376/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 56.4869 - val_loss: 144.0263\n",
      "Epoch 377/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 59.5229 - val_loss: 142.7104\n",
      "Epoch 378/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 57.9880 - val_loss: 115.5163\n",
      "Epoch 379/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 59.0382 - val_loss: 106.1060\n",
      "Epoch 380/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 56.2995 - val_loss: 143.1041\n",
      "Epoch 381/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 56.5740 - val_loss: 113.0773\n",
      "Epoch 382/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 58.9479 - val_loss: 104.1252\n",
      "Epoch 383/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 56.9892 - val_loss: 125.2614\n",
      "Epoch 384/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 58.7965 - val_loss: 105.3606\n",
      "Epoch 385/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 56.2890 - val_loss: 125.7218\n",
      "Epoch 386/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 56.3589 - val_loss: 101.1075\n",
      "Epoch 387/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 56.8705 - val_loss: 134.3717\n",
      "Epoch 388/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 57.4484 - val_loss: 138.9813\n",
      "Epoch 389/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 55.8945 - val_loss: 99.8399\n",
      "Epoch 390/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 56.6801 - val_loss: 147.7840\n",
      "Epoch 391/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 59.3211 - val_loss: 150.6322\n",
      "Epoch 392/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 57.3621 - val_loss: 152.1118\n",
      "Epoch 393/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 57.9530 - val_loss: 145.4893\n",
      "Epoch 394/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 57.5109 - val_loss: 106.8813\n",
      "Epoch 395/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 57.8124 - val_loss: 102.8294\n",
      "Epoch 396/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 55.3707 - val_loss: 123.8109\n",
      "Epoch 397/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 56.9399 - val_loss: 110.7585\n",
      "Epoch 398/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 57.0424 - val_loss: 135.1396\n",
      "Epoch 399/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 56.7969 - val_loss: 105.8615\n",
      "Epoch 400/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 57.8703 - val_loss: 121.8204\n",
      "Epoch 401/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 55.3518 - val_loss: 123.8572\n",
      "Epoch 402/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 58.3030 - val_loss: 137.2729\n",
      "Epoch 403/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 58.0254 - val_loss: 157.2075\n",
      "Epoch 404/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 58.2484 - val_loss: 148.0255\n",
      "Epoch 405/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 57.2967 - val_loss: 130.8244\n",
      "Epoch 406/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 55.9866 - val_loss: 119.7555\n",
      "Epoch 407/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 55.3913 - val_loss: 130.3255\n",
      "Epoch 408/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 56.6831 - val_loss: 132.4792\n",
      "Epoch 409/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 65.6758 - val_loss: 120.3727\n",
      "Epoch 410/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 56.1838 - val_loss: 136.0611\n",
      "Epoch 411/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 56.4707 - val_loss: 116.8465\n",
      "Epoch 412/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 57.2060 - val_loss: 130.0753\n",
      "Epoch 413/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 56.0013 - val_loss: 119.0253\n",
      "Epoch 414/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 54.6005 - val_loss: 134.5174\n",
      "Epoch 415/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 56.8676 - val_loss: 172.8840\n",
      "Epoch 416/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 55.7901 - val_loss: 121.3641\n",
      "Epoch 417/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 56.4640 - val_loss: 204.6832\n",
      "Epoch 418/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 54.8009 - val_loss: 105.4586\n",
      "Epoch 419/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 57.9592 - val_loss: 153.8678\n",
      "Epoch 420/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 54.3559 - val_loss: 106.3109\n",
      "Epoch 421/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 54.7050 - val_loss: 130.3372\n",
      "Epoch 422/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 56.5402 - val_loss: 163.4608\n",
      "Epoch 423/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 57.0700 - val_loss: 121.0307\n",
      "Epoch 424/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 54.7644 - val_loss: 161.1335\n",
      "Epoch 425/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 59.6260 - val_loss: 166.0999\n",
      "Epoch 426/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 57.1931 - val_loss: 111.7393\n",
      "Epoch 427/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 55.2254 - val_loss: 137.5381\n",
      "Epoch 428/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 58.2295 - val_loss: 123.4231\n",
      "Epoch 429/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 54.8434 - val_loss: 112.8897\n",
      "Epoch 430/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 56.5941 - val_loss: 131.9764\n",
      "Epoch 431/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 55.6870 - val_loss: 130.2632\n",
      "Epoch 432/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 56.1828 - val_loss: 121.9012\n",
      "Epoch 433/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 58.3747 - val_loss: 128.8688\n",
      "Epoch 434/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 55.3421 - val_loss: 143.7814\n",
      "Epoch 435/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 55.1150 - val_loss: 143.2115\n",
      "Epoch 436/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 54.8008 - val_loss: 110.3076\n",
      "Epoch 437/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 56.0887 - val_loss: 101.3251\n",
      "Epoch 438/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 54.0437 - val_loss: 133.5697\n",
      "Epoch 439/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 55.7795 - val_loss: 206.4964\n",
      "Epoch 440/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 56.6124 - val_loss: 107.9878\n",
      "Epoch 441/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 54.9847 - val_loss: 125.6088\n",
      "Epoch 442/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 54.8090 - val_loss: 132.0382\n",
      "Epoch 443/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 56.0466 - val_loss: 111.1740\n",
      "Epoch 444/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 61.7478 - val_loss: 143.5280\n",
      "Epoch 445/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 56.4140 - val_loss: 130.5663\n",
      "Epoch 446/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 56.0486 - val_loss: 119.9225\n",
      "Epoch 447/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 54.8937 - val_loss: 168.0105\n",
      "Epoch 448/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 54.3681 - val_loss: 132.5658\n",
      "Epoch 449/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 56.5485 - val_loss: 158.3109\n",
      "Epoch 450/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 55.5942 - val_loss: 115.9504\n",
      "Epoch 451/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 6ms/step - loss: 54.5506 - val_loss: 161.2464\n",
      "Epoch 452/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 57.0696 - val_loss: 121.5273\n",
      "Epoch 453/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 55.8294 - val_loss: 139.3509\n",
      "Epoch 454/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 55.9333 - val_loss: 111.3858\n",
      "Epoch 455/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 55.8267 - val_loss: 105.5217\n",
      "Epoch 456/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 54.5760 - val_loss: 142.2714\n",
      "Epoch 457/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 55.5840 - val_loss: 127.1232\n",
      "Epoch 458/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 56.3944 - val_loss: 174.4410\n",
      "Epoch 459/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 55.0173 - val_loss: 134.3802\n",
      "Epoch 460/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 58.2311 - val_loss: 101.7365\n",
      "Epoch 461/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 54.3062 - val_loss: 122.3004\n",
      "Epoch 462/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 55.4806 - val_loss: 121.6206\n",
      "Epoch 463/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 54.1646 - val_loss: 147.4810\n",
      "Epoch 464/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 56.9487 - val_loss: 120.7965\n",
      "Epoch 465/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 54.3372 - val_loss: 103.1811\n",
      "Epoch 466/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 53.8196 - val_loss: 107.2917\n",
      "Epoch 467/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 56.3186 - val_loss: 104.9909\n",
      "Epoch 468/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 56.1263 - val_loss: 183.4946\n",
      "Epoch 469/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 54.0328 - val_loss: 112.4181\n",
      "Epoch 470/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 55.5727 - val_loss: 121.0943\n",
      "Epoch 471/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 55.5134 - val_loss: 153.9910\n",
      "Epoch 472/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 55.6602 - val_loss: 116.8801\n",
      "Epoch 473/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 55.2803 - val_loss: 171.5548\n",
      "Epoch 474/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 58.2765 - val_loss: 149.9026\n",
      "Epoch 475/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 56.9947 - val_loss: 137.5955\n",
      "Epoch 476/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 57.4074 - val_loss: 148.6709\n",
      "Epoch 477/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 56.9925 - val_loss: 136.0552\n",
      "Epoch 478/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 55.8252 - val_loss: 150.4845\n",
      "Epoch 479/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 57.3660 - val_loss: 130.3326\n",
      "Epoch 480/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 53.7138 - val_loss: 106.7846\n",
      "Epoch 481/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 54.3139 - val_loss: 136.5564\n",
      "Epoch 482/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 57.0358 - val_loss: 174.8997\n",
      "Epoch 483/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 53.7580 - val_loss: 175.7245\n",
      "Epoch 484/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 57.4992 - val_loss: 109.3132\n",
      "Epoch 485/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 56.0887 - val_loss: 145.1090\n",
      "Epoch 486/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 53.2333 - val_loss: 112.9340\n",
      "Epoch 487/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 58.1743 - val_loss: 104.6369\n",
      "Epoch 488/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 55.4220 - val_loss: 118.6231\n",
      "Epoch 489/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 54.3647 - val_loss: 126.6048\n",
      "Epoch 490/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 53.7282 - val_loss: 98.2361\n",
      "Epoch 491/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 54.5970 - val_loss: 126.6176\n",
      "Epoch 492/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 53.6899 - val_loss: 109.9749\n",
      "Epoch 493/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 53.4885 - val_loss: 110.0806\n",
      "Epoch 494/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 54.1057 - val_loss: 120.5603\n",
      "Epoch 495/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 57.8672 - val_loss: 106.8009\n",
      "Epoch 496/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 52.6988 - val_loss: 101.5919\n",
      "Epoch 497/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 52.9715 - val_loss: 119.7468\n",
      "Epoch 498/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 54.6190 - val_loss: 143.3685\n",
      "Epoch 499/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 58.8064 - val_loss: 107.9260\n",
      "Epoch 500/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 55.0621 - val_loss: 142.4413\n",
      "Epoch 501/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 52.7199 - val_loss: 109.1708\n",
      "Epoch 502/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 55.6793 - val_loss: 138.2357\n",
      "Epoch 503/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 52.9743 - val_loss: 110.2653\n",
      "Epoch 504/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 52.3930 - val_loss: 152.5391\n",
      "Epoch 505/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 52.5105 - val_loss: 159.8261\n",
      "Epoch 506/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 53.1330 - val_loss: 127.1399\n",
      "Epoch 507/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 51.8250 - val_loss: 126.9228\n",
      "Epoch 508/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 55.6051 - val_loss: 148.0593\n",
      "Epoch 509/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 51.8834 - val_loss: 117.9209\n",
      "Epoch 510/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 52.1986 - val_loss: 103.0867\n",
      "Epoch 511/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 51.8050 - val_loss: 116.9514\n",
      "Epoch 512/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 58.2140 - val_loss: 107.1346\n",
      "Epoch 513/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 53.1638 - val_loss: 117.2681\n",
      "Epoch 514/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 53.4026 - val_loss: 102.0353\n",
      "Epoch 515/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 52.7500 - val_loss: 106.1002\n",
      "Epoch 516/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 52.1712 - val_loss: 145.3326\n",
      "Epoch 517/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 52.5011 - val_loss: 133.9610\n",
      "Epoch 518/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 52.4268 - val_loss: 148.2739\n",
      "Epoch 519/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 51.8000 - val_loss: 134.6151\n",
      "Epoch 520/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 51.3250 - val_loss: 144.9416\n",
      "Epoch 521/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 52.3398 - val_loss: 135.4845\n",
      "Epoch 522/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 51.6407 - val_loss: 113.3748\n",
      "Epoch 523/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 52.5456 - val_loss: 106.8443\n",
      "Epoch 524/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 51.6490 - val_loss: 143.9286\n",
      "Epoch 525/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 53.3505 - val_loss: 120.4176\n",
      "Epoch 526/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 51.4387 - val_loss: 127.9224\n",
      "Epoch 527/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 51.8433 - val_loss: 144.8002\n",
      "Epoch 528/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 51.3077 - val_loss: 129.7950\n",
      "Epoch 529/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 51.9110 - val_loss: 118.5332\n",
      "Epoch 530/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 52.0707 - val_loss: 129.3843\n",
      "Epoch 531/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 51.5692 - val_loss: 132.4302\n",
      "Epoch 532/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 51.1669 - val_loss: 118.4976\n",
      "Epoch 533/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 51.8575 - val_loss: 154.0016\n",
      "Epoch 534/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 51.2470 - val_loss: 140.0392\n",
      "Epoch 535/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 51.1037 - val_loss: 125.1500\n",
      "Epoch 536/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 50.5179 - val_loss: 101.3007\n",
      "Epoch 537/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 51.2150 - val_loss: 106.2503\n",
      "Epoch 538/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.9157 - val_loss: 137.7419\n",
      "Epoch 539/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 50.7467 - val_loss: 131.4468\n",
      "Epoch 540/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.8494 - val_loss: 110.7352\n",
      "Epoch 541/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 52.7590 - val_loss: 103.3703\n",
      "Epoch 542/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 53.1413 - val_loss: 117.6514\n",
      "Epoch 543/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 50.5738 - val_loss: 127.1060\n",
      "Epoch 544/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 50.1249 - val_loss: 107.0625\n",
      "Epoch 545/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 51.2357 - val_loss: 103.6886\n",
      "Epoch 546/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 50.4337 - val_loss: 152.1646\n",
      "Epoch 547/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 50.9748 - val_loss: 90.0425\n",
      "Epoch 548/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 51.1212 - val_loss: 122.6214\n",
      "Epoch 549/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.6829 - val_loss: 132.5157\n",
      "Epoch 550/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 51.3605 - val_loss: 116.5086\n",
      "Epoch 551/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 49.7566 - val_loss: 155.3566\n",
      "Epoch 552/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 50.9784 - val_loss: 135.7727\n",
      "Epoch 553/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 51.1325 - val_loss: 107.7110\n",
      "Epoch 554/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 50.4553 - val_loss: 115.1367\n",
      "Epoch 555/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.0562 - val_loss: 142.7970\n",
      "Epoch 556/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 51.3879 - val_loss: 124.9892\n",
      "Epoch 557/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 50.6004 - val_loss: 121.8569\n",
      "Epoch 558/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.8850 - val_loss: 114.6994\n",
      "Epoch 559/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.3508 - val_loss: 129.7747\n",
      "Epoch 560/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.7470 - val_loss: 103.3881\n",
      "Epoch 561/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 51.2467 - val_loss: 119.5079\n",
      "Epoch 562/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.7121 - val_loss: 130.2536\n",
      "Epoch 563/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 50.2240 - val_loss: 127.5733\n",
      "Epoch 564/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.8406 - val_loss: 108.4249\n",
      "Epoch 565/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.8652 - val_loss: 104.0699\n",
      "Epoch 566/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.7504 - val_loss: 100.2747\n",
      "Epoch 567/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 51.0675 - val_loss: 118.0703\n",
      "Epoch 568/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.6274 - val_loss: 139.3864\n",
      "Epoch 569/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.8288 - val_loss: 111.6528\n",
      "Epoch 570/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 51.6985 - val_loss: 102.9137\n",
      "Epoch 571/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 50.8083 - val_loss: 134.3544\n",
      "Epoch 572/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 50.0501 - val_loss: 117.8049\n",
      "Epoch 573/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.8558 - val_loss: 115.6652\n",
      "Epoch 574/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.5293 - val_loss: 101.5753\n",
      "Epoch 575/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.3081 - val_loss: 105.8986\n",
      "Epoch 576/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 49.0452 - val_loss: 105.1865\n",
      "Epoch 577/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 50.1072 - val_loss: 104.4639\n",
      "Epoch 578/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 49.3208 - val_loss: 100.8300\n",
      "Epoch 579/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 49.9754 - val_loss: 122.7766\n",
      "Epoch 580/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 50.3884 - val_loss: 103.4901\n",
      "Epoch 581/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.0929 - val_loss: 115.3152\n",
      "Epoch 582/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.2413 - val_loss: 132.3643\n",
      "Epoch 583/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 52.4229 - val_loss: 108.7206\n",
      "Epoch 584/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.2865 - val_loss: 107.9916\n",
      "Epoch 585/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.9490 - val_loss: 135.8589\n",
      "Epoch 586/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 50.5624 - val_loss: 208.1985\n",
      "Epoch 587/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 62.1243 - val_loss: 142.4013\n",
      "Epoch 588/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.3034 - val_loss: 120.9611\n",
      "Epoch 589/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 52.7866 - val_loss: 104.5519\n",
      "Epoch 590/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.7710 - val_loss: 112.8903\n",
      "Epoch 591/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 49.4873 - val_loss: 119.6265\n",
      "Epoch 592/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.9585 - val_loss: 114.4059\n",
      "Epoch 593/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.1495 - val_loss: 113.7384\n",
      "Epoch 594/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.9367 - val_loss: 104.8143\n",
      "Epoch 595/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.4591 - val_loss: 120.8693\n",
      "Epoch 596/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.5882 - val_loss: 107.9818\n",
      "Epoch 597/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.6797 - val_loss: 137.9272\n",
      "Epoch 598/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.4725 - val_loss: 106.1818\n",
      "Epoch 599/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.6011 - val_loss: 140.9287\n",
      "Epoch 600/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.8239 - val_loss: 117.5886\n",
      "Epoch 601/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.6512 - val_loss: 140.2146\n",
      "Epoch 602/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.2782 - val_loss: 119.6250\n",
      "Epoch 603/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 6ms/step - loss: 49.0851 - val_loss: 103.6788\n",
      "Epoch 604/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 50.2609 - val_loss: 130.5107\n",
      "Epoch 605/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.6536 - val_loss: 107.2967\n",
      "Epoch 606/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.7631 - val_loss: 116.4315\n",
      "Epoch 607/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 56.6648 - val_loss: 169.1738\n",
      "Epoch 608/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 62.7436 - val_loss: 132.3495\n",
      "Epoch 609/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 49.9392 - val_loss: 114.9461\n",
      "Epoch 610/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.8743 - val_loss: 132.9996\n",
      "Epoch 611/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.8462 - val_loss: 122.9395\n",
      "Epoch 612/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 52.6923 - val_loss: 111.9461\n",
      "Epoch 613/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.3158 - val_loss: 147.2151\n",
      "Epoch 614/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 53.5098 - val_loss: 105.5984\n",
      "Epoch 615/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 49.4510 - val_loss: 116.1583\n",
      "Epoch 616/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.3944 - val_loss: 102.5816\n",
      "Epoch 617/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 59.4831 - val_loss: 127.7759\n",
      "Epoch 618/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 49.8587 - val_loss: 112.8677\n",
      "Epoch 619/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 52.8121 - val_loss: 138.3842\n",
      "Epoch 620/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 49.6531 - val_loss: 128.9214\n",
      "Epoch 621/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.1884 - val_loss: 144.7275\n",
      "Epoch 622/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.8523 - val_loss: 118.0756\n",
      "Epoch 623/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 51.5838 - val_loss: 129.1630\n",
      "Epoch 624/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.5020 - val_loss: 156.8627\n",
      "Epoch 625/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.1163 - val_loss: 101.5052\n",
      "Epoch 626/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 49.2054 - val_loss: 103.7469\n",
      "Epoch 627/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.8196 - val_loss: 105.4360\n",
      "Epoch 628/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.8645 - val_loss: 212.9193\n",
      "Epoch 629/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 50.2434 - val_loss: 118.5662\n",
      "Epoch 630/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.3024 - val_loss: 115.2703\n",
      "Epoch 631/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 53.1172 - val_loss: 127.7633\n",
      "Epoch 632/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 52.7766 - val_loss: 116.0685\n",
      "Epoch 633/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.1419 - val_loss: 123.0483\n",
      "Epoch 634/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.7162 - val_loss: 107.2878\n",
      "Epoch 635/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 49.3076 - val_loss: 158.7820\n",
      "Epoch 636/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 49.8657 - val_loss: 127.5708\n",
      "Epoch 637/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.2626 - val_loss: 130.9346\n",
      "Epoch 638/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.0648 - val_loss: 249.0899\n",
      "Epoch 639/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 51.3569 - val_loss: 145.7453\n",
      "Epoch 640/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.9616 - val_loss: 149.3693\n",
      "Epoch 641/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.1895 - val_loss: 103.4680\n",
      "Epoch 642/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.7447 - val_loss: 103.1666\n",
      "Epoch 643/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.7778 - val_loss: 103.8917\n",
      "Epoch 644/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.3488 - val_loss: 127.6735\n",
      "Epoch 645/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 49.6075 - val_loss: 126.5952\n",
      "Epoch 646/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.0757 - val_loss: 135.2147\n",
      "Epoch 647/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 49.1571 - val_loss: 103.9151\n",
      "Epoch 648/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.3706 - val_loss: 100.6800\n",
      "Epoch 649/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.4410 - val_loss: 95.3491\n",
      "Epoch 650/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.2685 - val_loss: 142.2972\n",
      "Epoch 651/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.6812 - val_loss: 134.3101\n",
      "Epoch 652/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 49.0115 - val_loss: 126.7923\n",
      "Epoch 653/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.5481 - val_loss: 118.4116\n",
      "Epoch 654/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.6755 - val_loss: 110.4847\n",
      "Epoch 655/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 53.4244 - val_loss: 114.5463\n",
      "Epoch 656/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.1837 - val_loss: 135.6802\n",
      "Epoch 657/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.9172 - val_loss: 135.1900\n",
      "Epoch 658/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.0580 - val_loss: 132.7927\n",
      "Epoch 659/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 50.1545 - val_loss: 117.9717\n",
      "Epoch 660/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.3409 - val_loss: 115.8143\n",
      "Epoch 661/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.8880 - val_loss: 103.4344\n",
      "Epoch 662/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.7414 - val_loss: 113.8588\n",
      "Epoch 663/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.5068 - val_loss: 162.6103\n",
      "Epoch 664/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.2991 - val_loss: 107.6225\n",
      "Epoch 665/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.8354 - val_loss: 122.5143\n",
      "Epoch 666/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.1096 - val_loss: 129.5826\n",
      "Epoch 667/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.2501 - val_loss: 121.5011\n",
      "Epoch 668/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 49.2401 - val_loss: 145.4585\n",
      "Epoch 669/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.7363 - val_loss: 137.5596\n",
      "Epoch 670/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.1260 - val_loss: 132.7899\n",
      "Epoch 671/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.5393 - val_loss: 127.9366\n",
      "Epoch 672/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.9680 - val_loss: 152.0533\n",
      "Epoch 673/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.6037 - val_loss: 108.9655\n",
      "Epoch 674/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.6233 - val_loss: 134.5136\n",
      "Epoch 675/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.5552 - val_loss: 123.9436\n",
      "Epoch 676/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.6489 - val_loss: 158.3847\n",
      "Epoch 677/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.7054 - val_loss: 134.2603\n",
      "Epoch 678/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.1611 - val_loss: 131.4331\n",
      "Epoch 679/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.2260 - val_loss: 107.2314\n",
      "Epoch 680/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.6162 - val_loss: 149.2000\n",
      "Epoch 681/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.9700 - val_loss: 111.9908\n",
      "Epoch 682/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.5879 - val_loss: 122.7044\n",
      "Epoch 683/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.6001 - val_loss: 118.0990\n",
      "Epoch 684/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.7336 - val_loss: 106.1756\n",
      "Epoch 685/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.5929 - val_loss: 124.1742\n",
      "Epoch 686/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.6578 - val_loss: 141.1115\n",
      "Epoch 687/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.0608 - val_loss: 136.7473\n",
      "Epoch 688/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.7181 - val_loss: 107.1156\n",
      "Epoch 689/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 50.7876 - val_loss: 109.7523\n",
      "Epoch 690/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.1438 - val_loss: 131.6320\n",
      "Epoch 691/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.7917 - val_loss: 128.2202\n",
      "Epoch 692/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.5153 - val_loss: 108.7035\n",
      "Epoch 693/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 54.4381 - val_loss: 111.8060\n",
      "Epoch 694/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.7151 - val_loss: 138.9193\n",
      "Epoch 695/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.2386 - val_loss: 133.0735\n",
      "Epoch 696/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.9991 - val_loss: 109.0647\n",
      "Epoch 697/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.5309 - val_loss: 156.8558\n",
      "Epoch 698/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 54.2048 - val_loss: 146.0398\n",
      "Epoch 699/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.8132 - val_loss: 105.9271\n",
      "Epoch 700/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.9603 - val_loss: 124.0639\n",
      "Epoch 701/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.8551 - val_loss: 106.9577\n",
      "Epoch 702/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.6297 - val_loss: 108.2513\n",
      "Epoch 703/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 51.4844 - val_loss: 110.0089\n",
      "Epoch 704/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.0869 - val_loss: 142.2330\n",
      "Epoch 705/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.1344 - val_loss: 109.2086\n",
      "Epoch 706/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.3753 - val_loss: 122.0556\n",
      "Epoch 707/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.6992 - val_loss: 106.3928\n",
      "Epoch 708/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.2143 - val_loss: 124.6162\n",
      "Epoch 709/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.1807 - val_loss: 105.1708\n",
      "Epoch 710/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.2326 - val_loss: 119.8456\n",
      "Epoch 711/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.2783 - val_loss: 168.9281\n",
      "Epoch 712/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.8668 - val_loss: 100.5700\n",
      "Epoch 713/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.5210 - val_loss: 132.5735\n",
      "Epoch 714/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.9991 - val_loss: 143.8438\n",
      "Epoch 715/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.4049 - val_loss: 104.7090\n",
      "Epoch 716/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.8056 - val_loss: 132.0002\n",
      "Epoch 717/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.4548 - val_loss: 122.9413\n",
      "Epoch 718/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.7647 - val_loss: 143.0375\n",
      "Epoch 719/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.6003 - val_loss: 166.3994\n",
      "Epoch 720/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.0809 - val_loss: 191.4223\n",
      "Epoch 721/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.4314 - val_loss: 115.8063\n",
      "Epoch 722/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.2423 - val_loss: 117.1012\n",
      "Epoch 723/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.9367 - val_loss: 119.7424\n",
      "Epoch 724/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.2384 - val_loss: 108.6202\n",
      "Epoch 725/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.1553 - val_loss: 110.9906\n",
      "Epoch 726/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.2807 - val_loss: 123.1740\n",
      "Epoch 727/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.4270 - val_loss: 113.3809\n",
      "Epoch 728/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.8596 - val_loss: 112.6262\n",
      "Epoch 729/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.6310 - val_loss: 141.9849\n",
      "Epoch 730/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.0257 - val_loss: 104.7196\n",
      "Epoch 731/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.6283 - val_loss: 131.1796\n",
      "Epoch 732/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.6568 - val_loss: 108.9702\n",
      "Epoch 733/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.6470 - val_loss: 108.2470\n",
      "Epoch 734/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.5957 - val_loss: 112.4787\n",
      "Epoch 735/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.6499 - val_loss: 118.3849\n",
      "Epoch 736/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.0359 - val_loss: 105.4029\n",
      "Epoch 737/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.4010 - val_loss: 106.3909\n",
      "Epoch 738/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.8995 - val_loss: 118.2705\n",
      "Epoch 739/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 52.1059 - val_loss: 104.3297\n",
      "Epoch 740/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.4575 - val_loss: 112.8403\n",
      "Epoch 741/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.7980 - val_loss: 105.4113\n",
      "Epoch 742/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.4993 - val_loss: 104.1075\n",
      "Epoch 743/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.2777 - val_loss: 149.4011\n",
      "Epoch 744/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.7549 - val_loss: 107.4958\n",
      "Epoch 745/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.0221 - val_loss: 107.7879\n",
      "Epoch 746/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.4487 - val_loss: 109.3776\n",
      "Epoch 747/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.7999 - val_loss: 117.5800\n",
      "Epoch 748/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 49.8106 - val_loss: 151.1358\n",
      "Epoch 749/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7180 - val_loss: 133.7006\n",
      "Epoch 750/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.3802 - val_loss: 127.5768\n",
      "Epoch 751/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.0299 - val_loss: 101.5886\n",
      "Epoch 752/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.4042 - val_loss: 133.7630\n",
      "Epoch 753/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.7624 - val_loss: 118.3998\n",
      "Epoch 754/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.9399 - val_loss: 116.7951\n",
      "Epoch 755/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 47.5699 - val_loss: 122.5763\n",
      "Epoch 756/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.3119 - val_loss: 114.7784\n",
      "Epoch 757/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4511 - val_loss: 116.5438\n",
      "Epoch 758/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.4345 - val_loss: 116.4033\n",
      "Epoch 759/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.9512 - val_loss: 130.5498\n",
      "Epoch 760/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.3913 - val_loss: 105.9935\n",
      "Epoch 761/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.6763 - val_loss: 129.0233\n",
      "Epoch 762/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.1676 - val_loss: 160.8153\n",
      "Epoch 763/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.7206 - val_loss: 137.1283\n",
      "Epoch 764/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.4634 - val_loss: 131.5648\n",
      "Epoch 765/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.8361 - val_loss: 111.1470\n",
      "Epoch 766/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7735 - val_loss: 139.7296\n",
      "Epoch 767/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.7534 - val_loss: 120.5134\n",
      "Epoch 768/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.9577 - val_loss: 132.2424\n",
      "Epoch 769/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.1916 - val_loss: 109.0641\n",
      "Epoch 770/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.0778 - val_loss: 101.8045\n",
      "Epoch 771/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.5991 - val_loss: 161.1232\n",
      "Epoch 772/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.7820 - val_loss: 110.2143\n",
      "Epoch 773/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.4456 - val_loss: 141.2054\n",
      "Epoch 774/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.8971 - val_loss: 127.9405\n",
      "Epoch 775/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.3208 - val_loss: 152.2275\n",
      "Epoch 776/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.6102 - val_loss: 123.5255\n",
      "Epoch 777/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.9417 - val_loss: 133.2730\n",
      "Epoch 778/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.8630 - val_loss: 109.4282\n",
      "Epoch 779/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.6486 - val_loss: 106.0331\n",
      "Epoch 780/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.4888 - val_loss: 105.8967\n",
      "Epoch 781/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.6582 - val_loss: 113.7267\n",
      "Epoch 782/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.5712 - val_loss: 147.0633\n",
      "Epoch 783/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 49.6912 - val_loss: 132.0792\n",
      "Epoch 784/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.6635 - val_loss: 106.0293\n",
      "Epoch 785/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.7427 - val_loss: 141.0090\n",
      "Epoch 786/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.9924 - val_loss: 128.1930\n",
      "Epoch 787/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.0677 - val_loss: 134.6865\n",
      "Epoch 788/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.2570 - val_loss: 108.8753\n",
      "Epoch 789/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.4968 - val_loss: 142.0552\n",
      "Epoch 790/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.4436 - val_loss: 153.2108\n",
      "Epoch 791/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.2690 - val_loss: 102.8624\n",
      "Epoch 792/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0268 - val_loss: 141.3617\n",
      "Epoch 793/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.6450 - val_loss: 157.9657\n",
      "Epoch 794/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0945 - val_loss: 146.9255\n",
      "Epoch 795/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.2461 - val_loss: 126.0186\n",
      "Epoch 796/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.2714 - val_loss: 113.1858\n",
      "Epoch 797/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.8292 - val_loss: 103.3407\n",
      "Epoch 798/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.1203 - val_loss: 133.9634\n",
      "Epoch 799/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.8762 - val_loss: 108.1715\n",
      "Epoch 800/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.7500 - val_loss: 141.6128\n",
      "Epoch 801/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.8918 - val_loss: 103.9608\n",
      "Epoch 802/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.2896 - val_loss: 105.9098\n",
      "Epoch 803/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.6008 - val_loss: 107.5567\n",
      "Epoch 804/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.2815 - val_loss: 143.9211\n",
      "Epoch 805/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.4020 - val_loss: 179.3729\n",
      "Epoch 806/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.6572 - val_loss: 112.2795\n",
      "Epoch 807/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.2117 - val_loss: 139.0115\n",
      "Epoch 808/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.8663 - val_loss: 111.1806\n",
      "Epoch 809/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.4552 - val_loss: 107.3499\n",
      "Epoch 810/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.3349 - val_loss: 104.6790\n",
      "Epoch 811/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.6506 - val_loss: 112.9406\n",
      "Epoch 812/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.9836 - val_loss: 115.5084\n",
      "Epoch 813/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.4904 - val_loss: 111.9514\n",
      "Epoch 814/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.3625 - val_loss: 130.0428\n",
      "Epoch 815/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.9136 - val_loss: 104.6908\n",
      "Epoch 816/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.6749 - val_loss: 105.9577\n",
      "Epoch 817/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.4413 - val_loss: 111.1094\n",
      "Epoch 818/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0874 - val_loss: 132.1672\n",
      "Epoch 819/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.1955 - val_loss: 114.7140\n",
      "Epoch 820/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.9300 - val_loss: 125.3958\n",
      "Epoch 821/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.3620 - val_loss: 129.0071\n",
      "Epoch 822/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.6800 - val_loss: 139.0245\n",
      "Epoch 823/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.9934 - val_loss: 104.4229\n",
      "Epoch 824/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.6220 - val_loss: 122.5033\n",
      "Epoch 825/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.8601 - val_loss: 106.5630\n",
      "Epoch 826/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4091 - val_loss: 110.1604\n",
      "Epoch 827/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.9125 - val_loss: 121.2866\n",
      "Epoch 828/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.2393 - val_loss: 122.0948\n",
      "Epoch 829/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4834 - val_loss: 114.2808\n",
      "Epoch 830/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.3537 - val_loss: 99.9656\n",
      "Epoch 831/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4490 - val_loss: 178.4759\n",
      "Epoch 832/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.6484 - val_loss: 141.4002\n",
      "Epoch 833/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.0100 - val_loss: 119.1306\n",
      "Epoch 834/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.8607 - val_loss: 103.9472\n",
      "Epoch 835/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.3757 - val_loss: 115.4319\n",
      "Epoch 836/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.5692 - val_loss: 163.3497\n",
      "Epoch 837/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.3261 - val_loss: 134.5605\n",
      "Epoch 838/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.3657 - val_loss: 107.5825\n",
      "Epoch 839/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.5080 - val_loss: 100.3303\n",
      "Epoch 840/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.2631 - val_loss: 121.4062\n",
      "Epoch 841/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.5332 - val_loss: 157.7523\n",
      "Epoch 842/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.4025 - val_loss: 125.9098\n",
      "Epoch 843/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.0949 - val_loss: 119.1096\n",
      "Epoch 844/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.3389 - val_loss: 154.9100\n",
      "Epoch 845/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.0843 - val_loss: 122.7468\n",
      "Epoch 846/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.3049 - val_loss: 298.6273\n",
      "Epoch 847/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.4836 - val_loss: 125.3303\n",
      "Epoch 848/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.1067 - val_loss: 108.9672\n",
      "Epoch 849/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.5712 - val_loss: 101.7547\n",
      "Epoch 850/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.9579 - val_loss: 107.6530\n",
      "Epoch 851/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.3643 - val_loss: 127.3936\n",
      "Epoch 852/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.8675 - val_loss: 106.4556\n",
      "Epoch 853/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.3465 - val_loss: 115.4454\n",
      "Epoch 854/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.2514 - val_loss: 107.3960\n",
      "Epoch 855/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.8440 - val_loss: 155.4896\n",
      "Epoch 856/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.5445 - val_loss: 107.0702\n",
      "Epoch 857/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.3662 - val_loss: 111.1076\n",
      "Epoch 858/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.1176 - val_loss: 108.4862\n",
      "Epoch 859/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.7555 - val_loss: 131.0162\n",
      "Epoch 860/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.0602 - val_loss: 114.6343\n",
      "Epoch 861/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.1003 - val_loss: 126.5051\n",
      "Epoch 862/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.4133 - val_loss: 122.9990\n",
      "Epoch 863/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0044 - val_loss: 143.3539\n",
      "Epoch 864/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.9751 - val_loss: 123.0035\n",
      "Epoch 865/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.7310 - val_loss: 127.2530\n",
      "Epoch 866/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.5025 - val_loss: 103.0946\n",
      "Epoch 867/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.8553 - val_loss: 128.4312\n",
      "Epoch 868/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.4270 - val_loss: 110.8158\n",
      "Epoch 869/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.3667 - val_loss: 113.1877\n",
      "Epoch 870/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.8543 - val_loss: 122.0978\n",
      "Epoch 871/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.0450 - val_loss: 142.3850\n",
      "Epoch 872/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.6379 - val_loss: 147.5373\n",
      "Epoch 873/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.8828 - val_loss: 105.4960\n",
      "Epoch 874/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.6203 - val_loss: 112.6790\n",
      "Epoch 875/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.5664 - val_loss: 100.7890\n",
      "Epoch 876/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.6671 - val_loss: 99.9414\n",
      "Epoch 877/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0899 - val_loss: 105.1384\n",
      "Epoch 878/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.1780 - val_loss: 109.6645\n",
      "Epoch 879/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.3564 - val_loss: 102.3791\n",
      "Epoch 880/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.5815 - val_loss: 133.0173\n",
      "Epoch 881/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.1021 - val_loss: 140.4273\n",
      "Epoch 882/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.1164 - val_loss: 118.0076\n",
      "Epoch 883/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.7137 - val_loss: 128.4357\n",
      "Epoch 884/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.6231 - val_loss: 116.0516\n",
      "Epoch 885/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.5092 - val_loss: 99.8482\n",
      "Epoch 886/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.4342 - val_loss: 106.5768\n",
      "Epoch 887/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.6349 - val_loss: 133.3242\n",
      "Epoch 888/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8209 - val_loss: 150.6544\n",
      "Epoch 889/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.8378 - val_loss: 107.9965\n",
      "Epoch 890/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.9989 - val_loss: 105.3392\n",
      "Epoch 891/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.3084 - val_loss: 152.9851\n",
      "Epoch 892/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0310 - val_loss: 126.4642\n",
      "Epoch 893/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 45.4833 - val_loss: 111.4509\n",
      "Epoch 894/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.2305 - val_loss: 110.4358\n",
      "Epoch 895/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.8256 - val_loss: 108.9642\n",
      "Epoch 896/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4810 - val_loss: 105.5286\n",
      "Epoch 897/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.7923 - val_loss: 113.7598\n",
      "Epoch 898/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.9321 - val_loss: 109.7385\n",
      "Epoch 899/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.7451 - val_loss: 149.7935\n",
      "Epoch 900/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.4512 - val_loss: 156.9622\n",
      "Epoch 901/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.7938 - val_loss: 115.3706\n",
      "Epoch 902/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.3208 - val_loss: 117.6769\n",
      "Epoch 903/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.1817 - val_loss: 125.8720\n",
      "Epoch 904/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.9118 - val_loss: 111.4948\n",
      "Epoch 905/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.4160 - val_loss: 145.2697\n",
      "Epoch 906/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.7083 - val_loss: 104.6255\n",
      "Epoch 907/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 47.0755 - val_loss: 119.2341\n",
      "Epoch 908/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.4482 - val_loss: 105.8801\n",
      "Epoch 909/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.7859 - val_loss: 140.2843\n",
      "Epoch 910/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.4492 - val_loss: 112.4591\n",
      "Epoch 911/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.9300 - val_loss: 128.5870\n",
      "Epoch 912/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.2533 - val_loss: 108.7891\n",
      "Epoch 913/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.7315 - val_loss: 111.4971\n",
      "Epoch 914/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.3249 - val_loss: 123.3265\n",
      "Epoch 915/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 49.2633 - val_loss: 114.7709\n",
      "Epoch 916/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4690 - val_loss: 125.7645\n",
      "Epoch 917/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.6893 - val_loss: 108.6233\n",
      "Epoch 918/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.3303 - val_loss: 133.5593\n",
      "Epoch 919/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.2183 - val_loss: 123.3787\n",
      "Epoch 920/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.2211 - val_loss: 123.2551\n",
      "Epoch 921/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.2420 - val_loss: 108.6086\n",
      "Epoch 922/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.8573 - val_loss: 97.7776\n",
      "Epoch 923/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.2399 - val_loss: 119.8179\n",
      "Epoch 924/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 45.3530 - val_loss: 112.6341\n",
      "Epoch 925/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.1389 - val_loss: 150.1027\n",
      "Epoch 926/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.5264 - val_loss: 102.7981\n",
      "Epoch 927/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0124 - val_loss: 112.5919\n",
      "Epoch 928/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.9679 - val_loss: 112.0802\n",
      "Epoch 929/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.4845 - val_loss: 113.6003\n",
      "Epoch 930/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.2448 - val_loss: 153.8021\n",
      "Epoch 931/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.4298 - val_loss: 127.5118\n",
      "Epoch 932/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.0438 - val_loss: 110.4640\n",
      "Epoch 933/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.4985 - val_loss: 113.9361\n",
      "Epoch 934/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.8604 - val_loss: 101.3229\n",
      "Epoch 935/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1790 - val_loss: 138.4388\n",
      "Epoch 936/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.8506 - val_loss: 137.6065\n",
      "Epoch 937/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.8251 - val_loss: 104.7379\n",
      "Epoch 938/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.4362 - val_loss: 105.6204\n",
      "Epoch 939/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4232 - val_loss: 115.0521\n",
      "Epoch 940/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.7242 - val_loss: 117.7969\n",
      "Epoch 941/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.2473 - val_loss: 148.4939\n",
      "Epoch 942/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.9100 - val_loss: 101.3080\n",
      "Epoch 943/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.8305 - val_loss: 158.3782\n",
      "Epoch 944/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.8633 - val_loss: 145.1167\n",
      "Epoch 945/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0524 - val_loss: 127.8724\n",
      "Epoch 946/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 46.3811 - val_loss: 108.5817\n",
      "Epoch 947/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.8883 - val_loss: 107.6364\n",
      "Epoch 948/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.4530 - val_loss: 105.5770\n",
      "Epoch 949/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.7565 - val_loss: 102.7907\n",
      "Epoch 950/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.8693 - val_loss: 120.8468\n",
      "Epoch 951/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6096 - val_loss: 202.6260\n",
      "Epoch 952/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.1989 - val_loss: 141.0288\n",
      "Epoch 953/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7508 - val_loss: 111.1540\n",
      "Epoch 954/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.9024 - val_loss: 124.0967\n",
      "Epoch 955/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7472 - val_loss: 110.7634\n",
      "Epoch 956/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1121 - val_loss: 124.1274\n",
      "Epoch 957/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.2935 - val_loss: 107.9634\n",
      "Epoch 958/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.8458 - val_loss: 137.8310\n",
      "Epoch 959/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.1780 - val_loss: 100.0898\n",
      "Epoch 960/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.0632 - val_loss: 130.6795\n",
      "Epoch 961/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.4999 - val_loss: 147.2544\n",
      "Epoch 962/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7852 - val_loss: 118.5830\n",
      "Epoch 963/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.1674 - val_loss: 113.6887\n",
      "Epoch 964/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0288 - val_loss: 116.0549\n",
      "Epoch 965/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.1256 - val_loss: 128.4843\n",
      "Epoch 966/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.0658 - val_loss: 108.4555\n",
      "Epoch 967/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7013 - val_loss: 109.2828\n",
      "Epoch 968/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.8201 - val_loss: 133.2910\n",
      "Epoch 969/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8810 - val_loss: 146.9634\n",
      "Epoch 970/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.9433 - val_loss: 129.3336\n",
      "Epoch 971/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4537 - val_loss: 133.4546\n",
      "Epoch 972/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0262 - val_loss: 147.5137\n",
      "Epoch 973/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.7115 - val_loss: 106.8875\n",
      "Epoch 974/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2543 - val_loss: 119.7841\n",
      "Epoch 975/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.2690 - val_loss: 120.8435\n",
      "Epoch 976/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.9868 - val_loss: 103.8538\n",
      "Epoch 977/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4043 - val_loss: 134.4419\n",
      "Epoch 978/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.4716 - val_loss: 112.6059\n",
      "Epoch 979/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.6344 - val_loss: 112.3406\n",
      "Epoch 980/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2512 - val_loss: 131.6242\n",
      "Epoch 981/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2671 - val_loss: 123.4924\n",
      "Epoch 982/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.4309 - val_loss: 115.7340\n",
      "Epoch 983/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.2718 - val_loss: 138.6226\n",
      "Epoch 984/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.4552 - val_loss: 118.2871\n",
      "Epoch 985/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2626 - val_loss: 120.2607\n",
      "Epoch 986/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3861 - val_loss: 116.1047\n",
      "Epoch 987/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1354 - val_loss: 116.8117\n",
      "Epoch 988/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.5277 - val_loss: 123.3770\n",
      "Epoch 989/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.2869 - val_loss: 107.4786\n",
      "Epoch 990/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8298 - val_loss: 114.5061\n",
      "Epoch 991/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.3605 - val_loss: 116.5365\n",
      "Epoch 992/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.6925 - val_loss: 115.4697\n",
      "Epoch 993/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0313 - val_loss: 107.1562\n",
      "Epoch 994/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.6485 - val_loss: 126.0744\n",
      "Epoch 995/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7628 - val_loss: 145.4395\n",
      "Epoch 996/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.7744 - val_loss: 118.9874\n",
      "Epoch 997/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7417 - val_loss: 118.8773\n",
      "Epoch 998/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.7075 - val_loss: 151.4867\n",
      "Epoch 999/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.6956 - val_loss: 107.3761\n",
      "Epoch 1000/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.1585 - val_loss: 104.0381\n",
      "Epoch 1001/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.2054 - val_loss: 108.5128\n",
      "Epoch 1002/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1704 - val_loss: 102.5822\n",
      "Epoch 1003/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.8158 - val_loss: 133.7745\n",
      "Epoch 1004/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.2289 - val_loss: 113.7235\n",
      "Epoch 1005/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.3419 - val_loss: 103.3247\n",
      "Epoch 1006/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8838 - val_loss: 113.8491\n",
      "Epoch 1007/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.3287 - val_loss: 119.3885\n",
      "Epoch 1008/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.4999 - val_loss: 104.0280\n",
      "Epoch 1009/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7023 - val_loss: 124.4919\n",
      "Epoch 1010/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.8902 - val_loss: 102.9903\n",
      "Epoch 1011/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.6757 - val_loss: 148.3371\n",
      "Epoch 1012/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0788 - val_loss: 119.4957\n",
      "Epoch 1013/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.0712 - val_loss: 115.3960\n",
      "Epoch 1014/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.6879 - val_loss: 109.0078\n",
      "Epoch 1015/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1525 - val_loss: 107.2857\n",
      "Epoch 1016/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0924 - val_loss: 120.7413\n",
      "Epoch 1017/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3494 - val_loss: 105.0743\n",
      "Epoch 1018/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7493 - val_loss: 126.2678\n",
      "Epoch 1019/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.5759 - val_loss: 167.3618\n",
      "Epoch 1020/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0929 - val_loss: 109.4354\n",
      "Epoch 1021/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.2092 - val_loss: 135.0915\n",
      "Epoch 1022/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.7587 - val_loss: 139.1353\n",
      "Epoch 1023/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.6608 - val_loss: 120.7280\n",
      "Epoch 1024/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7870 - val_loss: 113.0901\n",
      "Epoch 1025/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0968 - val_loss: 106.8480\n",
      "Epoch 1026/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1373 - val_loss: 98.7330\n",
      "Epoch 1027/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4050 - val_loss: 114.5901\n",
      "Epoch 1028/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3250 - val_loss: 118.9494\n",
      "Epoch 1029/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.7140 - val_loss: 114.0870\n",
      "Epoch 1030/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.0741 - val_loss: 131.3451\n",
      "Epoch 1031/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.6449 - val_loss: 104.8091\n",
      "Epoch 1032/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.5193 - val_loss: 125.3938\n",
      "Epoch 1033/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4264 - val_loss: 131.5366\n",
      "Epoch 1034/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.7916 - val_loss: 101.8924\n",
      "Epoch 1035/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.0250 - val_loss: 134.9563\n",
      "Epoch 1036/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.6347 - val_loss: 117.7448\n",
      "Epoch 1037/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.7170 - val_loss: 130.8803\n",
      "Epoch 1038/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.7336 - val_loss: 106.9642\n",
      "Epoch 1039/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.6914 - val_loss: 166.3105\n",
      "Epoch 1040/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.5908 - val_loss: 154.9774\n",
      "Epoch 1041/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3943 - val_loss: 116.2459\n",
      "Epoch 1042/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.4416 - val_loss: 152.0714\n",
      "Epoch 1043/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.6807 - val_loss: 106.6568\n",
      "Epoch 1044/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.9936 - val_loss: 140.7095\n",
      "Epoch 1045/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.6237 - val_loss: 118.2388\n",
      "Epoch 1046/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4709 - val_loss: 106.2539\n",
      "Epoch 1047/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3252 - val_loss: 123.7585\n",
      "Epoch 1048/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.9608 - val_loss: 121.1730\n",
      "Epoch 1049/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.2539 - val_loss: 132.9016\n",
      "Epoch 1050/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.8700 - val_loss: 102.4592\n",
      "Epoch 1051/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7971 - val_loss: 107.2886\n",
      "Epoch 1052/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6086 - val_loss: 110.5999\n",
      "Epoch 1053/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.6764 - val_loss: 140.3411\n",
      "Epoch 1054/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.2445 - val_loss: 119.9394\n",
      "Epoch 1055/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.8300 - val_loss: 105.8774\n",
      "Epoch 1056/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.1751 - val_loss: 105.8566\n",
      "Epoch 1057/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.9617 - val_loss: 123.0343\n",
      "Epoch 1058/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3416 - val_loss: 105.4090\n",
      "Epoch 1059/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 46.3065 - val_loss: 110.8267\n",
      "Epoch 1060/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3379 - val_loss: 113.5493\n",
      "Epoch 1061/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.4792 - val_loss: 110.5947\n",
      "Epoch 1062/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.8678 - val_loss: 103.7315\n",
      "Epoch 1063/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.9122 - val_loss: 138.8386\n",
      "Epoch 1064/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7429 - val_loss: 125.6936\n",
      "Epoch 1065/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.9811 - val_loss: 125.9081\n",
      "Epoch 1066/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.1534 - val_loss: 110.4677\n",
      "Epoch 1067/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.1287 - val_loss: 109.7830\n",
      "Epoch 1068/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1773 - val_loss: 110.3133\n",
      "Epoch 1069/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.8794 - val_loss: 123.7988\n",
      "Epoch 1070/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7829 - val_loss: 102.6457\n",
      "Epoch 1071/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.9164 - val_loss: 113.3630\n",
      "Epoch 1072/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4373 - val_loss: 105.3703\n",
      "Epoch 1073/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.0629 - val_loss: 111.9232\n",
      "Epoch 1074/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.1059 - val_loss: 122.7315\n",
      "Epoch 1075/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 52.6591 - val_loss: 149.5278\n",
      "Epoch 1076/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.9882 - val_loss: 100.4636\n",
      "Epoch 1077/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8511 - val_loss: 128.1432\n",
      "Epoch 1078/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2337 - val_loss: 102.3609\n",
      "Epoch 1079/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.9804 - val_loss: 151.2416\n",
      "Epoch 1080/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7037 - val_loss: 164.9689\n",
      "Epoch 1081/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.6160 - val_loss: 138.4531\n",
      "Epoch 1082/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.2135 - val_loss: 142.8290\n",
      "Epoch 1083/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4348 - val_loss: 108.5265\n",
      "Epoch 1084/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.6849 - val_loss: 109.0762\n",
      "Epoch 1085/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5417 - val_loss: 110.1873\n",
      "Epoch 1086/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.6437 - val_loss: 108.0038\n",
      "Epoch 1087/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.6775 - val_loss: 114.7362\n",
      "Epoch 1088/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4750 - val_loss: 112.5890\n",
      "Epoch 1089/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.5015 - val_loss: 104.7581\n",
      "Epoch 1090/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.3150 - val_loss: 116.0622\n",
      "Epoch 1091/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1746 - val_loss: 120.4997\n",
      "Epoch 1092/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.1947 - val_loss: 106.8730\n",
      "Epoch 1093/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.3686 - val_loss: 103.1442\n",
      "Epoch 1094/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7839 - val_loss: 110.0630\n",
      "Epoch 1095/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.2221 - val_loss: 141.2958\n",
      "Epoch 1096/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.8866 - val_loss: 155.5626\n",
      "Epoch 1097/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.2052 - val_loss: 107.0610\n",
      "Epoch 1098/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.2345 - val_loss: 117.9356\n",
      "Epoch 1099/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7807 - val_loss: 141.2706\n",
      "Epoch 1100/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.6185 - val_loss: 103.0719\n",
      "Epoch 1101/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2770 - val_loss: 101.5504\n",
      "Epoch 1102/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.4973 - val_loss: 104.9767\n",
      "Epoch 1103/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.2158 - val_loss: 104.0583\n",
      "Epoch 1104/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.8391 - val_loss: 139.1052\n",
      "Epoch 1105/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.9468 - val_loss: 124.5979\n",
      "Epoch 1106/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.4993 - val_loss: 137.9797\n",
      "Epoch 1107/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.2484 - val_loss: 116.7605\n",
      "Epoch 1108/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.0595 - val_loss: 101.6813\n",
      "Epoch 1109/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7347 - val_loss: 103.0607\n",
      "Epoch 1110/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.6283 - val_loss: 160.1955\n",
      "Epoch 1111/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2905 - val_loss: 157.6319\n",
      "Epoch 1112/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.6696 - val_loss: 100.7082\n",
      "Epoch 1113/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6756 - val_loss: 120.5156\n",
      "Epoch 1114/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2334 - val_loss: 115.8184\n",
      "Epoch 1115/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.9942 - val_loss: 108.2194\n",
      "Epoch 1116/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3147 - val_loss: 141.7918\n",
      "Epoch 1117/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7402 - val_loss: 102.7252\n",
      "Epoch 1118/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.1473 - val_loss: 132.7961\n",
      "Epoch 1119/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2817 - val_loss: 123.3150\n",
      "Epoch 1120/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0297 - val_loss: 143.9722\n",
      "Epoch 1121/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.9102 - val_loss: 103.9699\n",
      "Epoch 1122/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4192 - val_loss: 146.2373\n",
      "Epoch 1123/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.4258 - val_loss: 124.3627\n",
      "Epoch 1124/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.7507 - val_loss: 152.6715\n",
      "Epoch 1125/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1356 - val_loss: 105.8426\n",
      "Epoch 1126/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.9719 - val_loss: 104.8393\n",
      "Epoch 1127/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.5433 - val_loss: 131.0042\n",
      "Epoch 1128/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4185 - val_loss: 110.3789\n",
      "Epoch 1129/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.4570 - val_loss: 145.2336\n",
      "Epoch 1130/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0065 - val_loss: 123.6530\n",
      "Epoch 1131/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.6519 - val_loss: 106.0769\n",
      "Epoch 1132/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.2789 - val_loss: 111.9595\n",
      "Epoch 1133/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.1350 - val_loss: 120.7395\n",
      "Epoch 1134/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.6640 - val_loss: 146.1105\n",
      "Epoch 1135/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 6ms/step - loss: 45.3406 - val_loss: 104.6657\n",
      "Epoch 1136/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.6051 - val_loss: 120.1432\n",
      "Epoch 1137/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.8837 - val_loss: 109.6840\n",
      "Epoch 1138/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.9329 - val_loss: 99.6966\n",
      "Epoch 1139/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.0509 - val_loss: 101.6686\n",
      "Epoch 1140/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.5880 - val_loss: 108.8166\n",
      "Epoch 1141/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.7890 - val_loss: 100.8063\n",
      "Epoch 1142/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.1486 - val_loss: 102.8998\n",
      "Epoch 1143/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.5207 - val_loss: 87.0663\n",
      "Epoch 1144/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5105 - val_loss: 129.5498\n",
      "Epoch 1145/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.5961 - val_loss: 132.1596\n",
      "Epoch 1146/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.1985 - val_loss: 117.7136\n",
      "Epoch 1147/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.9863 - val_loss: 103.1219\n",
      "Epoch 1148/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2269 - val_loss: 145.3235\n",
      "Epoch 1149/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.0275 - val_loss: 115.1963\n",
      "Epoch 1150/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3094 - val_loss: 139.7975\n",
      "Epoch 1151/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.5959 - val_loss: 108.4847\n",
      "Epoch 1152/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.0986 - val_loss: 125.6296\n",
      "Epoch 1153/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0162 - val_loss: 111.3564\n",
      "Epoch 1154/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.9659 - val_loss: 162.2814\n",
      "Epoch 1155/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.8941 - val_loss: 105.1170\n",
      "Epoch 1156/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2002 - val_loss: 104.2744\n",
      "Epoch 1157/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.5421 - val_loss: 102.7914\n",
      "Epoch 1158/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3749 - val_loss: 138.8243\n",
      "Epoch 1159/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.5596 - val_loss: 134.8197\n",
      "Epoch 1160/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3661 - val_loss: 108.5298\n",
      "Epoch 1161/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1266 - val_loss: 101.7939\n",
      "Epoch 1162/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.7232 - val_loss: 118.2791\n",
      "Epoch 1163/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.6425 - val_loss: 117.5494\n",
      "Epoch 1164/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5824 - val_loss: 101.0082\n",
      "Epoch 1165/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4582 - val_loss: 131.7797\n",
      "Epoch 1166/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3205 - val_loss: 102.7282\n",
      "Epoch 1167/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0191 - val_loss: 98.8042\n",
      "Epoch 1168/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.5830 - val_loss: 177.5904\n",
      "Epoch 1169/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0071 - val_loss: 123.6226\n",
      "Epoch 1170/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.6322 - val_loss: 109.1763\n",
      "Epoch 1171/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.8799 - val_loss: 108.3949\n",
      "Epoch 1172/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.2850 - val_loss: 112.4788\n",
      "Epoch 1173/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2211 - val_loss: 135.1733\n",
      "Epoch 1174/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.6427 - val_loss: 125.3177\n",
      "Epoch 1175/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.1213 - val_loss: 143.0003\n",
      "Epoch 1176/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1615 - val_loss: 103.5814\n",
      "Epoch 1177/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.5789 - val_loss: 113.5877\n",
      "Epoch 1178/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.3807 - val_loss: 103.0701\n",
      "Epoch 1179/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.4016 - val_loss: 105.9709\n",
      "Epoch 1180/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.9222 - val_loss: 113.3915\n",
      "Epoch 1181/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2051 - val_loss: 141.3785\n",
      "Epoch 1182/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6275 - val_loss: 105.3651\n",
      "Epoch 1183/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.3388 - val_loss: 105.9300\n",
      "Epoch 1184/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.5653 - val_loss: 104.0172\n",
      "Epoch 1185/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5742 - val_loss: 104.2877\n",
      "Epoch 1186/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6746 - val_loss: 150.8903\n",
      "Epoch 1187/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.6744 - val_loss: 107.1296\n",
      "Epoch 1188/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4963 - val_loss: 104.6136\n",
      "Epoch 1189/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4020 - val_loss: 139.5471\n",
      "Epoch 1190/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.9339 - val_loss: 128.0452\n",
      "Epoch 1191/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1269 - val_loss: 103.1962\n",
      "Epoch 1192/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.5758 - val_loss: 111.7649\n",
      "Epoch 1193/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.5211 - val_loss: 145.8680\n",
      "Epoch 1194/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.4980 - val_loss: 100.6989\n",
      "Epoch 1195/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7094 - val_loss: 107.3956\n",
      "Epoch 1196/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2836 - val_loss: 110.0986\n",
      "Epoch 1197/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.9428 - val_loss: 153.7051\n",
      "Epoch 1198/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.7996 - val_loss: 146.2346\n",
      "Epoch 1199/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4649 - val_loss: 109.7104\n",
      "Epoch 1200/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.7129 - val_loss: 145.3149\n",
      "Epoch 1201/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.6651 - val_loss: 139.8064\n",
      "Epoch 1202/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0878 - val_loss: 126.5105\n",
      "Epoch 1203/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3971 - val_loss: 101.0101\n",
      "Epoch 1204/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4328 - val_loss: 114.7333\n",
      "Epoch 1205/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7165 - val_loss: 147.1687\n",
      "Epoch 1206/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3232 - val_loss: 129.7315\n",
      "Epoch 1207/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4245 - val_loss: 146.6466\n",
      "Epoch 1208/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.8185 - val_loss: 117.1343\n",
      "Epoch 1209/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0767 - val_loss: 110.0289\n",
      "Epoch 1210/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6507 - val_loss: 109.9727\n",
      "Epoch 1211/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 46.7544 - val_loss: 114.3813\n",
      "Epoch 1212/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.9698 - val_loss: 137.0712\n",
      "Epoch 1213/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.5632 - val_loss: 120.1345\n",
      "Epoch 1214/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.1257 - val_loss: 140.2039\n",
      "Epoch 1215/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.0500 - val_loss: 139.0413\n",
      "Epoch 1216/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.5924 - val_loss: 149.3132\n",
      "Epoch 1217/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7574 - val_loss: 150.5798\n",
      "Epoch 1218/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.9239 - val_loss: 100.8165\n",
      "Epoch 1219/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.9325 - val_loss: 98.1026\n",
      "Epoch 1220/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.4792 - val_loss: 104.1378\n",
      "Epoch 1221/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8301 - val_loss: 157.3028\n",
      "Epoch 1222/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4943 - val_loss: 151.9359\n",
      "Epoch 1223/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.8938 - val_loss: 164.7666\n",
      "Epoch 1224/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2643 - val_loss: 128.1894\n",
      "Epoch 1225/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.6854 - val_loss: 139.5698\n",
      "Epoch 1226/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.1134 - val_loss: 132.5847\n",
      "Epoch 1227/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4463 - val_loss: 113.4778\n",
      "Epoch 1228/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1242 - val_loss: 117.0978\n",
      "Epoch 1229/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8008 - val_loss: 120.8835\n",
      "Epoch 1230/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4489 - val_loss: 138.2391\n",
      "Epoch 1231/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3814 - val_loss: 106.9457\n",
      "Epoch 1232/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7068 - val_loss: 106.2704\n",
      "Epoch 1233/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.3085 - val_loss: 157.8968\n",
      "Epoch 1234/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.5153 - val_loss: 118.7676\n",
      "Epoch 1235/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0015 - val_loss: 103.0004\n",
      "Epoch 1236/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.2546 - val_loss: 141.3921\n",
      "Epoch 1237/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4622 - val_loss: 128.0820\n",
      "Epoch 1238/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7070 - val_loss: 103.0109\n",
      "Epoch 1239/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.6191 - val_loss: 118.6436\n",
      "Epoch 1240/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.9194 - val_loss: 118.7223\n",
      "Epoch 1241/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7457 - val_loss: 143.9050\n",
      "Epoch 1242/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8576 - val_loss: 122.0459\n",
      "Epoch 1243/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.2233 - val_loss: 100.5077\n",
      "Epoch 1244/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3528 - val_loss: 122.5235\n",
      "Epoch 1245/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2225 - val_loss: 147.7580\n",
      "Epoch 1246/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2969 - val_loss: 103.5137\n",
      "Epoch 1247/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3470 - val_loss: 112.7720\n",
      "Epoch 1248/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1773 - val_loss: 119.2615\n",
      "Epoch 1249/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.1844 - val_loss: 166.6853\n",
      "Epoch 1250/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.3197 - val_loss: 101.4211\n",
      "Epoch 1251/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1622 - val_loss: 98.9921\n",
      "Epoch 1252/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3408 - val_loss: 151.8986\n",
      "Epoch 1253/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3121 - val_loss: 103.3188\n",
      "Epoch 1254/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.5839 - val_loss: 129.0781\n",
      "Epoch 1255/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7155 - val_loss: 166.2929\n",
      "Epoch 1256/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1005 - val_loss: 108.2290\n",
      "Epoch 1257/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.5970 - val_loss: 150.8977\n",
      "Epoch 1258/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.9723 - val_loss: 123.6766\n",
      "Epoch 1259/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.5213 - val_loss: 123.2772\n",
      "Epoch 1260/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2816 - val_loss: 105.3623\n",
      "Epoch 1261/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1372 - val_loss: 116.7093\n",
      "Epoch 1262/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.9774 - val_loss: 98.5795\n",
      "Epoch 1263/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6737 - val_loss: 106.6495\n",
      "Epoch 1264/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6884 - val_loss: 103.2383\n",
      "Epoch 1265/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5525 - val_loss: 121.8625\n",
      "Epoch 1266/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.6698 - val_loss: 115.1894\n",
      "Epoch 1267/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.0245 - val_loss: 115.2682\n",
      "Epoch 1268/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.5729 - val_loss: 134.8190\n",
      "Epoch 1269/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.2630 - val_loss: 102.1260\n",
      "Epoch 1270/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8468 - val_loss: 118.5674\n",
      "Epoch 1271/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.8308 - val_loss: 145.8681\n",
      "Epoch 1272/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.4528 - val_loss: 138.0391\n",
      "Epoch 1273/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.3444 - val_loss: 106.3831\n",
      "Epoch 1274/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.0291 - val_loss: 125.4700\n",
      "Epoch 1275/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0032 - val_loss: 103.7260\n",
      "Epoch 1276/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.8869 - val_loss: 110.2032\n",
      "Epoch 1277/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3899 - val_loss: 102.8661\n",
      "Epoch 1278/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7145 - val_loss: 107.3024\n",
      "Epoch 1279/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4177 - val_loss: 123.1104\n",
      "Epoch 1280/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7424 - val_loss: 123.1662\n",
      "Epoch 1281/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.5284 - val_loss: 152.8658\n",
      "Epoch 1282/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.0236 - val_loss: 131.6133\n",
      "Epoch 1283/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.9394 - val_loss: 132.9072\n",
      "Epoch 1284/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.2009 - val_loss: 124.9761\n",
      "Epoch 1285/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2493 - val_loss: 110.2276\n",
      "Epoch 1286/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1645 - val_loss: 125.2066\n",
      "Epoch 1287/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 6ms/step - loss: 46.1132 - val_loss: 113.6530\n",
      "Epoch 1288/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.3958 - val_loss: 102.8454\n",
      "Epoch 1289/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.1574 - val_loss: 131.2843\n",
      "Epoch 1290/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.3651 - val_loss: 115.6704\n",
      "Epoch 1291/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.7044 - val_loss: 99.8815\n",
      "Epoch 1292/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.2837 - val_loss: 113.1980\n",
      "Epoch 1293/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.7688 - val_loss: 109.0651\n",
      "Epoch 1294/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.1890 - val_loss: 156.1605\n",
      "Epoch 1295/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.3944 - val_loss: 105.3458\n",
      "Epoch 1296/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.8660 - val_loss: 122.2152\n",
      "Epoch 1297/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.3751 - val_loss: 112.7117\n",
      "Epoch 1298/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.0755 - val_loss: 121.3010\n",
      "Epoch 1299/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.4779 - val_loss: 119.9665\n",
      "Epoch 1300/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.6491 - val_loss: 98.5063\n",
      "Epoch 1301/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8867 - val_loss: 115.8985\n",
      "Epoch 1302/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.1887 - val_loss: 100.2709\n",
      "Epoch 1303/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.6748 - val_loss: 101.8125\n",
      "Epoch 1304/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8109 - val_loss: 101.5822\n",
      "Epoch 1305/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4187 - val_loss: 106.2683\n",
      "Epoch 1306/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.6444 - val_loss: 122.0110\n",
      "Epoch 1307/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7551 - val_loss: 100.4356\n",
      "Epoch 1308/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3715 - val_loss: 100.4764\n",
      "Epoch 1309/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6833 - val_loss: 131.5707\n",
      "Epoch 1310/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2553 - val_loss: 106.1774\n",
      "Epoch 1311/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.1059 - val_loss: 239.3495\n",
      "Epoch 1312/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.5580 - val_loss: 97.9977\n",
      "Epoch 1313/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 43.8769 - val_loss: 127.7156\n",
      "Epoch 1314/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4781 - val_loss: 114.1305\n",
      "Epoch 1315/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6742 - val_loss: 117.2143\n",
      "Epoch 1316/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.2928 - val_loss: 103.7524\n",
      "Epoch 1317/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.4469 - val_loss: 124.6181\n",
      "Epoch 1318/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3023 - val_loss: 103.1543\n",
      "Epoch 1319/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5297 - val_loss: 145.7160\n",
      "Epoch 1320/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.9619 - val_loss: 110.5196\n",
      "Epoch 1321/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.4363 - val_loss: 108.4651\n",
      "Epoch 1322/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.3145 - val_loss: 83.4011\n",
      "Epoch 1323/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3598 - val_loss: 118.6284\n",
      "Epoch 1324/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7268 - val_loss: 107.6684\n",
      "Epoch 1325/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.5431 - val_loss: 130.1326\n",
      "Epoch 1326/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.4317 - val_loss: 130.2335\n",
      "Epoch 1327/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.2302 - val_loss: 111.9865\n",
      "Epoch 1328/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 42.9602 - val_loss: 129.6283\n",
      "Epoch 1329/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7260 - val_loss: 117.3718\n",
      "Epoch 1330/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3164 - val_loss: 111.5293\n",
      "Epoch 1331/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 43.2629 - val_loss: 113.1953\n",
      "Epoch 1332/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.5259 - val_loss: 137.8560\n",
      "Epoch 1333/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8544 - val_loss: 100.4757\n",
      "Epoch 1334/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.1172 - val_loss: 129.7594\n",
      "Epoch 1335/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.4089 - val_loss: 149.8219\n",
      "Epoch 1336/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2628 - val_loss: 101.4178\n",
      "Epoch 1337/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3820 - val_loss: 93.5528\n",
      "Epoch 1338/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1891 - val_loss: 128.9119\n",
      "Epoch 1339/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3137 - val_loss: 102.1453\n",
      "Epoch 1340/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.6388 - val_loss: 123.6617\n",
      "Epoch 1341/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.2307 - val_loss: 139.2718\n",
      "Epoch 1342/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.4774 - val_loss: 115.6080\n",
      "Epoch 1343/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.5305 - val_loss: 100.2789\n",
      "Epoch 1344/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8479 - val_loss: 148.4113\n",
      "Epoch 1345/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2460 - val_loss: 124.2960\n",
      "Epoch 1346/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.4819 - val_loss: 123.2045\n",
      "Epoch 1347/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7315 - val_loss: 146.8223\n",
      "Epoch 1348/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3977 - val_loss: 114.8057\n",
      "Epoch 1349/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.7916 - val_loss: 129.1222\n",
      "Epoch 1350/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.8079 - val_loss: 108.6740\n",
      "Epoch 1351/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.9134 - val_loss: 150.7373\n",
      "Epoch 1352/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.2944 - val_loss: 111.7557\n",
      "Epoch 1353/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5511 - val_loss: 120.9440\n",
      "Epoch 1354/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6916 - val_loss: 103.3008\n",
      "Epoch 1355/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2460 - val_loss: 101.9380\n",
      "Epoch 1356/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3486 - val_loss: 100.7393\n",
      "Epoch 1357/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8610 - val_loss: 128.9385\n",
      "Epoch 1358/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.8742 - val_loss: 109.7928\n",
      "Epoch 1359/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.1630 - val_loss: 105.6230\n",
      "Epoch 1360/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8884 - val_loss: 109.7211\n",
      "Epoch 1361/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1148 - val_loss: 235.4123\n",
      "Epoch 1362/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.4179 - val_loss: 145.5857\n",
      "Epoch 1363/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4407 - val_loss: 105.2140\n",
      "Epoch 1364/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6072 - val_loss: 131.5278\n",
      "Epoch 1365/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.5557 - val_loss: 117.0115\n",
      "Epoch 1366/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.3985 - val_loss: 99.9736\n",
      "Epoch 1367/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.5254 - val_loss: 149.0654\n",
      "Epoch 1368/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.0193 - val_loss: 126.7775\n",
      "Epoch 1369/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.1171 - val_loss: 97.9149\n",
      "Epoch 1370/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.6754 - val_loss: 101.4966\n",
      "Epoch 1371/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.4548 - val_loss: 100.6398\n",
      "Epoch 1372/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.4807 - val_loss: 105.1488\n",
      "Epoch 1373/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.1082 - val_loss: 151.7218\n",
      "Epoch 1374/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.8446 - val_loss: 128.3128\n",
      "Epoch 1375/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6301 - val_loss: 119.2520\n",
      "Epoch 1376/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.4386 - val_loss: 291.9357\n",
      "Epoch 1377/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8871 - val_loss: 114.4317\n",
      "Epoch 1378/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.9366 - val_loss: 137.7776\n",
      "Epoch 1379/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5560 - val_loss: 176.6328\n",
      "Epoch 1380/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8614 - val_loss: 115.4256\n",
      "Epoch 1381/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.1802 - val_loss: 127.7404\n",
      "Epoch 1382/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.3679 - val_loss: 113.8045\n",
      "Epoch 1383/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.0463 - val_loss: 122.2245\n",
      "Epoch 1384/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.0576 - val_loss: 118.4653\n",
      "Epoch 1385/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.3420 - val_loss: 123.4367\n",
      "Epoch 1386/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.3924 - val_loss: 121.5236\n",
      "Epoch 1387/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.0367 - val_loss: 102.3952\n",
      "Epoch 1388/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1220 - val_loss: 123.3315\n",
      "Epoch 1389/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6557 - val_loss: 103.2329\n",
      "Epoch 1390/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7443 - val_loss: 112.2889\n",
      "Epoch 1391/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 48.0828 - val_loss: 109.6798\n",
      "Epoch 1392/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.9115 - val_loss: 119.1512\n",
      "Epoch 1393/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.9141 - val_loss: 120.2696\n",
      "Epoch 1394/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3833 - val_loss: 110.4712\n",
      "Epoch 1395/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.9773 - val_loss: 117.8411\n",
      "Epoch 1396/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3263 - val_loss: 161.9338\n",
      "Epoch 1397/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.2038 - val_loss: 105.4399\n",
      "Epoch 1398/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.6650 - val_loss: 104.2319\n",
      "Epoch 1399/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.7851 - val_loss: 107.9336\n",
      "Epoch 1400/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.3806 - val_loss: 130.9120\n",
      "Epoch 1401/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2719 - val_loss: 128.4791\n",
      "Epoch 1402/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.0355 - val_loss: 97.4845\n",
      "Epoch 1403/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.3619 - val_loss: 108.1071\n",
      "Epoch 1404/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3048 - val_loss: 255.4560\n",
      "Epoch 1405/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.7755 - val_loss: 127.0601\n",
      "Epoch 1406/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6625 - val_loss: 104.0612\n",
      "Epoch 1407/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8926 - val_loss: 101.0812\n",
      "Epoch 1408/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7754 - val_loss: 104.2520\n",
      "Epoch 1409/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.9007 - val_loss: 136.6737\n",
      "Epoch 1410/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8699 - val_loss: 159.6179\n",
      "Epoch 1411/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8607 - val_loss: 103.6514\n",
      "Epoch 1412/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4006 - val_loss: 116.7184\n",
      "Epoch 1413/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.6651 - val_loss: 149.6415\n",
      "Epoch 1414/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.4105 - val_loss: 119.9272\n",
      "Epoch 1415/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3898 - val_loss: 152.7912\n",
      "Epoch 1416/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.8740 - val_loss: 111.7321\n",
      "Epoch 1417/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.9735 - val_loss: 114.9609\n",
      "Epoch 1418/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7541 - val_loss: 125.2167\n",
      "Epoch 1419/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.5235 - val_loss: 111.6199\n",
      "Epoch 1420/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2068 - val_loss: 105.0311\n",
      "Epoch 1421/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.4314 - val_loss: 144.0135\n",
      "Epoch 1422/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.3914 - val_loss: 103.2455\n",
      "Epoch 1423/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7447 - val_loss: 103.2378\n",
      "Epoch 1424/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.3894 - val_loss: 120.9084\n",
      "Epoch 1425/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5133 - val_loss: 132.5322\n",
      "Epoch 1426/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2892 - val_loss: 104.9125\n",
      "Epoch 1427/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1317 - val_loss: 113.0462\n",
      "Epoch 1428/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6606 - val_loss: 105.3695\n",
      "Epoch 1429/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5250 - val_loss: 100.0403\n",
      "Epoch 1430/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.1731 - val_loss: 105.8957\n",
      "Epoch 1431/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.5496 - val_loss: 109.1204\n",
      "Epoch 1432/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5278 - val_loss: 122.8016\n",
      "Epoch 1433/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8577 - val_loss: 115.1700\n",
      "Epoch 1434/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.0352 - val_loss: 101.2121\n",
      "Epoch 1435/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.9901 - val_loss: 156.6856\n",
      "Epoch 1436/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2863 - val_loss: 138.6427\n",
      "Epoch 1437/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.7417 - val_loss: 101.1896\n",
      "Epoch 1438/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 45.5074 - val_loss: 103.9756\n",
      "Epoch 1439/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 8ms/step - loss: 44.4633 - val_loss: 265.5033\n",
      "Epoch 1440/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1616 - val_loss: 110.7546\n",
      "Epoch 1441/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 54.6545 - val_loss: 131.4540\n",
      "Epoch 1442/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.9095 - val_loss: 106.4348\n",
      "Epoch 1443/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0662 - val_loss: 169.0566\n",
      "Epoch 1444/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.0571 - val_loss: 130.6935\n",
      "Epoch 1445/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.2582 - val_loss: 110.8501\n",
      "Epoch 1446/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.2335 - val_loss: 99.8652\n",
      "Epoch 1447/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.7233 - val_loss: 133.2740\n",
      "Epoch 1448/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4146 - val_loss: 101.7245\n",
      "Epoch 1449/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.0529 - val_loss: 135.7449\n",
      "Epoch 1450/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.1186 - val_loss: 103.2916\n",
      "Epoch 1451/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.0038 - val_loss: 98.8487\n",
      "Epoch 1452/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.8129 - val_loss: 142.6661\n",
      "Epoch 1453/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.4624 - val_loss: 110.0436\n",
      "Epoch 1454/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.0373 - val_loss: 112.0648\n",
      "Epoch 1455/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.3716 - val_loss: 113.5160\n",
      "Epoch 1456/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5597 - val_loss: 135.0105\n",
      "Epoch 1457/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.0998 - val_loss: 142.3921\n",
      "Epoch 1458/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 47.5604 - val_loss: 103.1567\n",
      "Epoch 1459/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2262 - val_loss: 116.3200\n",
      "Epoch 1460/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2677 - val_loss: 138.8474\n",
      "Epoch 1461/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.5533 - val_loss: 101.5616\n",
      "Epoch 1462/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3898 - val_loss: 108.6744\n",
      "Epoch 1463/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.5953 - val_loss: 98.4923\n",
      "Epoch 1464/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.9834 - val_loss: 114.9546\n",
      "Epoch 1465/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.5807 - val_loss: 105.5022\n",
      "Epoch 1466/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.9976 - val_loss: 115.6291\n",
      "Epoch 1467/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5093 - val_loss: 158.3467\n",
      "Epoch 1468/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7313 - val_loss: 116.6720\n",
      "Epoch 1469/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.2107 - val_loss: 182.6438\n",
      "Epoch 1470/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7462 - val_loss: 116.8674\n",
      "Epoch 1471/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.6916 - val_loss: 114.8153\n",
      "Epoch 1472/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1202 - val_loss: 118.6857\n",
      "Epoch 1473/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.0821 - val_loss: 112.4552\n",
      "Epoch 1474/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.1901 - val_loss: 103.4136\n",
      "Epoch 1475/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3861 - val_loss: 108.2197\n",
      "Epoch 1476/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1358 - val_loss: 122.2961\n",
      "Epoch 1477/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2430 - val_loss: 94.2653\n",
      "Epoch 1478/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3313 - val_loss: 101.6156\n",
      "Epoch 1479/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.9864 - val_loss: 123.6743\n",
      "Epoch 1480/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.0918 - val_loss: 126.3971\n",
      "Epoch 1481/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.2257 - val_loss: 106.6288\n",
      "Epoch 1482/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.6732 - val_loss: 100.5560\n",
      "Epoch 1483/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.4465 - val_loss: 156.0710\n",
      "Epoch 1484/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.0994 - val_loss: 101.9721\n",
      "Epoch 1485/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.5983 - val_loss: 117.3715\n",
      "Epoch 1486/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8962 - val_loss: 155.9166\n",
      "Epoch 1487/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.7016 - val_loss: 103.0195\n",
      "Epoch 1488/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5831 - val_loss: 127.6046\n",
      "Epoch 1489/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.0953 - val_loss: 104.1821\n",
      "Epoch 1490/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.5778 - val_loss: 106.8189\n",
      "Epoch 1491/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.8132 - val_loss: 113.7134\n",
      "Epoch 1492/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.2289 - val_loss: 146.7192\n",
      "Epoch 1493/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5174 - val_loss: 152.8409\n",
      "Epoch 1494/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.3961 - val_loss: 102.7980\n",
      "Epoch 1495/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7404 - val_loss: 108.3457\n",
      "Epoch 1496/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2425 - val_loss: 104.2793\n",
      "Epoch 1497/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.9409 - val_loss: 127.8755\n",
      "Epoch 1498/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.8861 - val_loss: 126.2144\n",
      "Epoch 1499/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.2164 - val_loss: 116.3720\n",
      "Epoch 1500/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3661 - val_loss: 125.0164\n",
      "Epoch 1501/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.6188 - val_loss: 99.8651\n",
      "Epoch 1502/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.4838 - val_loss: 109.9113\n",
      "Epoch 1503/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.0554 - val_loss: 116.6462\n",
      "Epoch 1504/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.4773 - val_loss: 145.2180\n",
      "Epoch 1505/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.1310 - val_loss: 110.3344\n",
      "Epoch 1506/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.1592 - val_loss: 104.1169\n",
      "Epoch 1507/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0989 - val_loss: 127.7312\n",
      "Epoch 1508/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.7736 - val_loss: 133.9029\n",
      "Epoch 1509/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.6216 - val_loss: 137.3477\n",
      "Epoch 1510/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3724 - val_loss: 109.2667\n",
      "Epoch 1511/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.2718 - val_loss: 105.0722\n",
      "Epoch 1512/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3059 - val_loss: 116.3533\n",
      "Epoch 1513/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5659 - val_loss: 104.7390\n",
      "Epoch 1514/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2945 - val_loss: 103.3931\n",
      "Epoch 1515/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 44.2619 - val_loss: 134.3172\n",
      "Epoch 1516/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.7330 - val_loss: 98.5199\n",
      "Epoch 1517/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2231 - val_loss: 133.0098\n",
      "Epoch 1518/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.6326 - val_loss: 128.2908\n",
      "Epoch 1519/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.2830 - val_loss: 97.2151\n",
      "Epoch 1520/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8008 - val_loss: 111.5005\n",
      "Epoch 1521/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.1684 - val_loss: 119.9065\n",
      "Epoch 1522/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3757 - val_loss: 120.3720\n",
      "Epoch 1523/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.2369 - val_loss: 98.3390\n",
      "Epoch 1524/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.5289 - val_loss: 130.3328\n",
      "Epoch 1525/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4785 - val_loss: 106.8364\n",
      "Epoch 1526/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7883 - val_loss: 159.6300\n",
      "Epoch 1527/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.4729 - val_loss: 126.8668\n",
      "Epoch 1528/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.8821 - val_loss: 111.1043\n",
      "Epoch 1529/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6327 - val_loss: 99.0421\n",
      "Epoch 1530/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.4003 - val_loss: 112.2056\n",
      "Epoch 1531/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8647 - val_loss: 121.9118\n",
      "Epoch 1532/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.0221 - val_loss: 96.0294\n",
      "Epoch 1533/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.8953 - val_loss: 121.2320\n",
      "Epoch 1534/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.6135 - val_loss: 98.0047\n",
      "Epoch 1535/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3264 - val_loss: 131.3255\n",
      "Epoch 1536/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8740 - val_loss: 113.4177\n",
      "Epoch 1537/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.6412 - val_loss: 109.1687\n",
      "Epoch 1538/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.9969 - val_loss: 106.7758\n",
      "Epoch 1539/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.9772 - val_loss: 230.9766\n",
      "Epoch 1540/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.2896 - val_loss: 121.7059\n",
      "Epoch 1541/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.1004 - val_loss: 151.7469\n",
      "Epoch 1542/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.2416 - val_loss: 124.9657\n",
      "Epoch 1543/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.5292 - val_loss: 117.6124\n",
      "Epoch 1544/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1028 - val_loss: 92.6104\n",
      "Epoch 1545/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.1396 - val_loss: 116.9159\n",
      "Epoch 1546/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5723 - val_loss: 106.0984\n",
      "Epoch 1547/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1223 - val_loss: 98.2826\n",
      "Epoch 1548/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5358 - val_loss: 109.2950\n",
      "Epoch 1549/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.6334 - val_loss: 118.7403\n",
      "Epoch 1550/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4393 - val_loss: 119.4731\n",
      "Epoch 1551/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2734 - val_loss: 126.3782\n",
      "Epoch 1552/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6361 - val_loss: 118.9305\n",
      "Epoch 1553/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3785 - val_loss: 119.4387\n",
      "Epoch 1554/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3045 - val_loss: 99.4598\n",
      "Epoch 1555/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.3129 - val_loss: 137.6497\n",
      "Epoch 1556/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5775 - val_loss: 129.7574\n",
      "Epoch 1557/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.0246 - val_loss: 98.0814\n",
      "Epoch 1558/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.1439 - val_loss: 146.5768\n",
      "Epoch 1559/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6541 - val_loss: 103.5196\n",
      "Epoch 1560/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7434 - val_loss: 113.6186\n",
      "Epoch 1561/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.4460 - val_loss: 102.5484\n",
      "Epoch 1562/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.6936 - val_loss: 104.4084\n",
      "Epoch 1563/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.5058 - val_loss: 144.6834\n",
      "Epoch 1564/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7882 - val_loss: 136.8045\n",
      "Epoch 1565/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8350 - val_loss: 103.5364\n",
      "Epoch 1566/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.9408 - val_loss: 104.9825\n",
      "Epoch 1567/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7759 - val_loss: 145.6408\n",
      "Epoch 1568/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.5882 - val_loss: 104.5717\n",
      "Epoch 1569/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7875 - val_loss: 104.4548\n",
      "Epoch 1570/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.1453 - val_loss: 103.7036\n",
      "Epoch 1571/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.9639 - val_loss: 100.5848\n",
      "Epoch 1572/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5171 - val_loss: 104.2112\n",
      "Epoch 1573/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.8035 - val_loss: 96.3539\n",
      "Epoch 1574/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4390 - val_loss: 106.8542\n",
      "Epoch 1575/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4872 - val_loss: 124.8517\n",
      "Epoch 1576/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8205 - val_loss: 144.5295\n",
      "Epoch 1577/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0103 - val_loss: 147.4455\n",
      "Epoch 1578/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.5578 - val_loss: 107.8543\n",
      "Epoch 1579/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6290 - val_loss: 129.8248\n",
      "Epoch 1580/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3487 - val_loss: 126.5119\n",
      "Epoch 1581/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.7885 - val_loss: 103.4123\n",
      "Epoch 1582/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3810 - val_loss: 116.4986\n",
      "Epoch 1583/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.9328 - val_loss: 137.1502\n",
      "Epoch 1584/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.2165 - val_loss: 111.9253\n",
      "Epoch 1585/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3665 - val_loss: 137.5700\n",
      "Epoch 1586/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8739 - val_loss: 138.3219\n",
      "Epoch 1587/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.7068 - val_loss: 149.9141\n",
      "Epoch 1588/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.7776 - val_loss: 108.3549\n",
      "Epoch 1589/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7395 - val_loss: 102.3661\n",
      "Epoch 1590/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.5526 - val_loss: 148.2473\n",
      "Epoch 1591/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 6ms/step - loss: 44.7347 - val_loss: 135.6458\n",
      "Epoch 1592/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.2546 - val_loss: 126.5874\n",
      "Epoch 1593/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.1446 - val_loss: 99.4560\n",
      "Epoch 1594/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.3975 - val_loss: 103.4186\n",
      "Epoch 1595/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4301 - val_loss: 103.9354\n",
      "Epoch 1596/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1299 - val_loss: 200.4107\n",
      "Epoch 1597/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.0138 - val_loss: 118.9144\n",
      "Epoch 1598/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.2344 - val_loss: 119.9196\n",
      "Epoch 1599/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6934 - val_loss: 108.9672\n",
      "Epoch 1600/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.5491 - val_loss: 103.0542\n",
      "Epoch 1601/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.1770 - val_loss: 134.8008\n",
      "Epoch 1602/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1747 - val_loss: 134.4252\n",
      "Epoch 1603/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8117 - val_loss: 105.6272\n",
      "Epoch 1604/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6028 - val_loss: 126.1032\n",
      "Epoch 1605/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.8831 - val_loss: 107.3026\n",
      "Epoch 1606/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3978 - val_loss: 127.9657\n",
      "Epoch 1607/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.8442 - val_loss: 136.7377\n",
      "Epoch 1608/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2257 - val_loss: 105.5079\n",
      "Epoch 1609/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.4121 - val_loss: 142.9074\n",
      "Epoch 1610/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.3458 - val_loss: 119.2328\n",
      "Epoch 1611/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7146 - val_loss: 116.3098\n",
      "Epoch 1612/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.9156 - val_loss: 123.3266\n",
      "Epoch 1613/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5408 - val_loss: 113.1646\n",
      "Epoch 1614/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7701 - val_loss: 127.6261\n",
      "Epoch 1615/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.2408 - val_loss: 100.3539\n",
      "Epoch 1616/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5739 - val_loss: 106.0944\n",
      "Epoch 1617/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.2064 - val_loss: 103.9269\n",
      "Epoch 1618/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.8819 - val_loss: 98.5354\n",
      "Epoch 1619/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8516 - val_loss: 130.4015\n",
      "Epoch 1620/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.1970 - val_loss: 105.3320\n",
      "Epoch 1621/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 43.9670 - val_loss: 114.3029\n",
      "Epoch 1622/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 43.7385 - val_loss: 105.9523\n",
      "Epoch 1623/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.4268 - val_loss: 117.7742\n",
      "Epoch 1624/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5172 - val_loss: 124.2542\n",
      "Epoch 1625/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.3773 - val_loss: 149.0328\n",
      "Epoch 1626/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5077 - val_loss: 104.2759\n",
      "Epoch 1627/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.4859 - val_loss: 131.8656\n",
      "Epoch 1628/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.3049 - val_loss: 141.2760\n",
      "Epoch 1629/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.9434 - val_loss: 113.7292\n",
      "Epoch 1630/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.1815 - val_loss: 95.7371\n",
      "Epoch 1631/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.0128 - val_loss: 103.0366\n",
      "Epoch 1632/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.2492 - val_loss: 119.2239\n",
      "Epoch 1633/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0307 - val_loss: 99.2120\n",
      "Epoch 1634/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 43.8221 - val_loss: 105.5123\n",
      "Epoch 1635/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4668 - val_loss: 93.0389\n",
      "Epoch 1636/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.6995 - val_loss: 207.0522\n",
      "Epoch 1637/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3872 - val_loss: 106.0155\n",
      "Epoch 1638/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 43.6863 - val_loss: 127.4591\n",
      "Epoch 1639/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.3853 - val_loss: 189.4990\n",
      "Epoch 1640/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.1028 - val_loss: 112.1405\n",
      "Epoch 1641/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.1639 - val_loss: 100.9281\n",
      "Epoch 1642/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3204 - val_loss: 126.2694\n",
      "Epoch 1643/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.1935 - val_loss: 133.7425\n",
      "Epoch 1644/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7101 - val_loss: 98.5989\n",
      "Epoch 1645/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0779 - val_loss: 114.9862\n",
      "Epoch 1646/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.9938 - val_loss: 102.9981\n",
      "Epoch 1647/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3629 - val_loss: 97.4823\n",
      "Epoch 1648/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.2121 - val_loss: 95.4242\n",
      "Epoch 1649/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 43.4371 - val_loss: 100.5004\n",
      "Epoch 1650/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.9148 - val_loss: 120.2054\n",
      "Epoch 1651/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.3124 - val_loss: 104.3699\n",
      "Epoch 1652/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.0978 - val_loss: 125.7659\n",
      "Epoch 1653/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7904 - val_loss: 98.5438\n",
      "Epoch 1654/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.0446 - val_loss: 144.7076\n",
      "Epoch 1655/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.5981 - val_loss: 109.9492\n",
      "Epoch 1656/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.5765 - val_loss: 95.5619\n",
      "Epoch 1657/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.7183 - val_loss: 111.1737\n",
      "Epoch 1658/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 43.8176 - val_loss: 103.1879\n",
      "Epoch 1659/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.8225 - val_loss: 102.5515\n",
      "Epoch 1660/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.1242 - val_loss: 97.2223\n",
      "Epoch 1661/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.8487 - val_loss: 88.1937\n",
      "Epoch 1662/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.0472 - val_loss: 104.7093\n",
      "Epoch 1663/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 42.8273 - val_loss: 112.3052\n",
      "Epoch 1664/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6432 - val_loss: 120.9751\n",
      "Epoch 1665/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2264 - val_loss: 137.7241\n",
      "Epoch 1666/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4068 - val_loss: 114.0242\n",
      "Epoch 1667/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 44.2033 - val_loss: 100.2487\n",
      "Epoch 1668/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2577 - val_loss: 98.2861\n",
      "Epoch 1669/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.7946 - val_loss: 135.6958\n",
      "Epoch 1670/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.6227 - val_loss: 128.9852\n",
      "Epoch 1671/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.4986 - val_loss: 126.9084\n",
      "Epoch 1672/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.5084 - val_loss: 100.5072\n",
      "Epoch 1673/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3783 - val_loss: 114.3397\n",
      "Epoch 1674/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.5147 - val_loss: 118.0157\n",
      "Epoch 1675/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.1127 - val_loss: 133.9944\n",
      "Epoch 1676/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2583 - val_loss: 104.0434\n",
      "Epoch 1677/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6581 - val_loss: 121.1129\n",
      "Epoch 1678/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.4583 - val_loss: 142.4828\n",
      "Epoch 1679/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.1123 - val_loss: 97.1590\n",
      "Epoch 1680/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3539 - val_loss: 193.0640\n",
      "Epoch 1681/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3431 - val_loss: 111.5121\n",
      "Epoch 1682/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6936 - val_loss: 121.7134\n",
      "Epoch 1683/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.9668 - val_loss: 103.9857\n",
      "Epoch 1684/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 43.0231 - val_loss: 157.3755\n",
      "Epoch 1685/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.0241 - val_loss: 88.3482\n",
      "Epoch 1686/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3075 - val_loss: 106.5874\n",
      "Epoch 1687/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 47.6314 - val_loss: 139.0403\n",
      "Epoch 1688/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.8701 - val_loss: 135.4564\n",
      "Epoch 1689/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3420 - val_loss: 105.6539\n",
      "Epoch 1690/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8441 - val_loss: 103.4723\n",
      "Epoch 1691/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3267 - val_loss: 119.8168\n",
      "Epoch 1692/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.1686 - val_loss: 155.2312\n",
      "Epoch 1693/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6889 - val_loss: 122.4340\n",
      "Epoch 1694/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.4251 - val_loss: 97.9712\n",
      "Epoch 1695/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.3018 - val_loss: 113.6407\n",
      "Epoch 1696/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.0671 - val_loss: 104.9397\n",
      "Epoch 1697/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.1168 - val_loss: 116.1533\n",
      "Epoch 1698/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.7894 - val_loss: 97.2015\n",
      "Epoch 1699/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3172 - val_loss: 105.5507\n",
      "Epoch 1700/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.5715 - val_loss: 118.9015\n",
      "Epoch 1701/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5180 - val_loss: 114.6958\n",
      "Epoch 1702/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.3896 - val_loss: 106.0758\n",
      "Epoch 1703/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.9366 - val_loss: 103.7259\n",
      "Epoch 1704/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5412 - val_loss: 96.6753\n",
      "Epoch 1705/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.0038 - val_loss: 130.9133\n",
      "Epoch 1706/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.6073 - val_loss: 118.5567\n",
      "Epoch 1707/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.6259 - val_loss: 159.8511\n",
      "Epoch 1708/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.4979 - val_loss: 116.6875\n",
      "Epoch 1709/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.9776 - val_loss: 98.0304\n",
      "Epoch 1710/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.9009 - val_loss: 138.4732\n",
      "Epoch 1711/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.0641 - val_loss: 101.3102\n",
      "Epoch 1712/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2221 - val_loss: 101.1191\n",
      "Epoch 1713/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 42.7469 - val_loss: 102.1152\n",
      "Epoch 1714/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.9134 - val_loss: 98.2176\n",
      "Epoch 1715/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.2070 - val_loss: 121.3156\n",
      "Epoch 1716/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.7770 - val_loss: 100.0605\n",
      "Epoch 1717/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.1857 - val_loss: 129.5407\n",
      "Epoch 1718/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.9444 - val_loss: 126.5772\n",
      "Epoch 1719/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.9460 - val_loss: 115.0225\n",
      "Epoch 1720/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4965 - val_loss: 100.4746\n",
      "Epoch 1721/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.3356 - val_loss: 131.0191\n",
      "Epoch 1722/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.1553 - val_loss: 126.9376\n",
      "Epoch 1723/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.9510 - val_loss: 122.6581\n",
      "Epoch 1724/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.9199 - val_loss: 141.1154\n",
      "Epoch 1725/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0126 - val_loss: 117.9116\n",
      "Epoch 1726/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.6716 - val_loss: 124.7597\n",
      "Epoch 1727/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.3137 - val_loss: 121.2658\n",
      "Epoch 1728/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.7899 - val_loss: 100.2789\n",
      "Epoch 1729/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.1426 - val_loss: 146.6857\n",
      "Epoch 1730/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.9761 - val_loss: 101.7336\n",
      "Epoch 1731/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.3255 - val_loss: 151.8823\n",
      "Epoch 1732/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.9325 - val_loss: 110.6340\n",
      "Epoch 1733/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.7306 - val_loss: 127.6496\n",
      "Epoch 1734/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5843 - val_loss: 126.9418\n",
      "Epoch 1735/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7813 - val_loss: 141.7385\n",
      "Epoch 1736/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8681 - val_loss: 96.0530\n",
      "Epoch 1737/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6672 - val_loss: 112.3104\n",
      "Epoch 1738/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8477 - val_loss: 99.0255\n",
      "Epoch 1739/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.0359 - val_loss: 135.4175\n",
      "Epoch 1740/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.9669 - val_loss: 106.0741\n",
      "Epoch 1741/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.4835 - val_loss: 110.7269\n",
      "Epoch 1742/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.5580 - val_loss: 98.5805\n",
      "Epoch 1743/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 45.8371 - val_loss: 157.9175\n",
      "Epoch 1744/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.2401 - val_loss: 160.1542\n",
      "Epoch 1745/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.5847 - val_loss: 263.2790\n",
      "Epoch 1746/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 43.8025 - val_loss: 125.3603\n",
      "Epoch 1747/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.9430 - val_loss: 101.5011\n",
      "Epoch 1748/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.1146 - val_loss: 103.8442\n",
      "Epoch 1749/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.8046 - val_loss: 126.7003\n",
      "Epoch 1750/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4269 - val_loss: 113.7095\n",
      "Epoch 1751/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0081 - val_loss: 110.3176\n",
      "Epoch 1752/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.5635 - val_loss: 102.2439\n",
      "Epoch 1753/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.4375 - val_loss: 122.3958\n",
      "Epoch 1754/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5406 - val_loss: 117.9098\n",
      "Epoch 1755/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7458 - val_loss: 132.4194\n",
      "Epoch 1756/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5483 - val_loss: 106.5196\n",
      "Epoch 1757/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.4755 - val_loss: 115.1292\n",
      "Epoch 1758/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.0730 - val_loss: 127.1371\n",
      "Epoch 1759/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.1141 - val_loss: 100.6492\n",
      "Epoch 1760/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.0322 - val_loss: 116.1849\n",
      "Epoch 1761/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.4817 - val_loss: 99.6284\n",
      "Epoch 1762/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.1645 - val_loss: 102.6138\n",
      "Epoch 1763/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 43.9448 - val_loss: 120.9248\n",
      "Epoch 1764/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.4242 - val_loss: 159.4989\n",
      "Epoch 1765/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.2218 - val_loss: 98.0120\n",
      "Epoch 1766/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.3160 - val_loss: 126.7824\n",
      "Epoch 1767/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.8846 - val_loss: 112.0142\n",
      "Epoch 1768/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3484 - val_loss: 115.1184\n",
      "Epoch 1769/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.4148 - val_loss: 106.2845\n",
      "Epoch 1770/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.9147 - val_loss: 112.7165\n",
      "Epoch 1771/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7262 - val_loss: 95.7058\n",
      "Epoch 1772/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7017 - val_loss: 97.5919\n",
      "Epoch 1773/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.9510 - val_loss: 143.7751\n",
      "Epoch 1774/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.0886 - val_loss: 111.5210\n",
      "Epoch 1775/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.3776 - val_loss: 108.0912\n",
      "Epoch 1776/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.2198 - val_loss: 140.3089\n",
      "Epoch 1777/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 43.9179 - val_loss: 127.3651\n",
      "Epoch 1778/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.5308 - val_loss: 102.8858\n",
      "Epoch 1779/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.4154 - val_loss: 155.3591\n",
      "Epoch 1780/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.6919 - val_loss: 106.5488\n",
      "Epoch 1781/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.6359 - val_loss: 130.4849\n",
      "Epoch 1782/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.3546 - val_loss: 116.1604\n",
      "Epoch 1783/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1641 - val_loss: 147.0834\n",
      "Epoch 1784/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 43.3380 - val_loss: 111.6068\n",
      "Epoch 1785/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 43.3758 - val_loss: 104.4640\n",
      "Epoch 1786/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.4096 - val_loss: 103.5590\n",
      "Epoch 1787/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.6446 - val_loss: 95.0172\n",
      "Epoch 1788/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.5056 - val_loss: 103.1448\n",
      "Epoch 1789/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.9979 - val_loss: 99.9030\n",
      "Epoch 1790/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.7062 - val_loss: 155.4111\n",
      "Epoch 1791/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7769 - val_loss: 125.7123\n",
      "Epoch 1792/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.2874 - val_loss: 107.3555\n",
      "Epoch 1793/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 42.9737 - val_loss: 103.7357\n",
      "Epoch 1794/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7058 - val_loss: 95.9294\n",
      "Epoch 1795/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8799 - val_loss: 109.8718\n",
      "Epoch 1796/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.0728 - val_loss: 100.6920\n",
      "Epoch 1797/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.6757 - val_loss: 109.3920\n",
      "Epoch 1798/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 43.7618 - val_loss: 141.3662\n",
      "Epoch 1799/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.9042 - val_loss: 131.8916\n",
      "Epoch 1800/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 43.4092 - val_loss: 111.0580\n",
      "Epoch 1801/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6138 - val_loss: 98.0185\n",
      "Epoch 1802/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.2412 - val_loss: 147.3307\n",
      "Epoch 1803/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.8332 - val_loss: 104.2087\n",
      "Epoch 1804/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.1610 - val_loss: 123.9295\n",
      "Epoch 1805/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.5960 - val_loss: 100.2632\n",
      "Epoch 1806/2000\n",
      "152/152 [==============================] - -1s -3792us/step - loss: 44.2874 - val_loss: 117.9229\n",
      "Epoch 1807/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.0823 - val_loss: 123.1040\n",
      "Epoch 1808/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.3594 - val_loss: 128.3368\n",
      "Epoch 1809/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3674 - val_loss: 132.1820\n",
      "Epoch 1810/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.7896 - val_loss: 101.8515\n",
      "Epoch 1811/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4071 - val_loss: 101.1544\n",
      "Epoch 1812/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.9903 - val_loss: 101.8999\n",
      "Epoch 1813/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.6141 - val_loss: 181.9047\n",
      "Epoch 1814/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.8692 - val_loss: 124.5788\n",
      "Epoch 1815/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.9448 - val_loss: 110.2007\n",
      "Epoch 1816/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.4362 - val_loss: 96.3316\n",
      "Epoch 1817/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3919 - val_loss: 102.4666\n",
      "Epoch 1818/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.6732 - val_loss: 96.8272\n",
      "Epoch 1819/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 43.5406 - val_loss: 110.2605\n",
      "Epoch 1820/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3173 - val_loss: 113.1307\n",
      "Epoch 1821/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2782 - val_loss: 179.4650\n",
      "Epoch 1822/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.6305 - val_loss: 114.2540\n",
      "Epoch 1823/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0943 - val_loss: 136.8259\n",
      "Epoch 1824/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5921 - val_loss: 120.9298\n",
      "Epoch 1825/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3411 - val_loss: 106.0041\n",
      "Epoch 1826/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5101 - val_loss: 123.8117\n",
      "Epoch 1827/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.4706 - val_loss: 115.4865\n",
      "Epoch 1828/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.9032 - val_loss: 110.9619\n",
      "Epoch 1829/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.2216 - val_loss: 164.4810\n",
      "Epoch 1830/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.3919 - val_loss: 118.8299\n",
      "Epoch 1831/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.1640 - val_loss: 152.0526\n",
      "Epoch 1832/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7926 - val_loss: 108.0986\n",
      "Epoch 1833/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.1681 - val_loss: 123.9755\n",
      "Epoch 1834/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 43.1826 - val_loss: 108.1256\n",
      "Epoch 1835/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.5465 - val_loss: 105.7661\n",
      "Epoch 1836/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 46.0920 - val_loss: 98.8658\n",
      "Epoch 1837/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.3250 - val_loss: 99.1788\n",
      "Epoch 1838/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.9166 - val_loss: 122.8252\n",
      "Epoch 1839/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.0635 - val_loss: 132.8079\n",
      "Epoch 1840/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7247 - val_loss: 98.5067\n",
      "Epoch 1841/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3153 - val_loss: 102.6765\n",
      "Epoch 1842/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.6065 - val_loss: 105.7153\n",
      "Epoch 1843/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 43.6679 - val_loss: 130.4182\n",
      "Epoch 1844/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 42.9814 - val_loss: 112.2991\n",
      "Epoch 1845/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.8823 - val_loss: 104.8840\n",
      "Epoch 1846/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3351 - val_loss: 111.3439\n",
      "Epoch 1847/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.5284 - val_loss: 117.4357\n",
      "Epoch 1848/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.0578 - val_loss: 94.3433\n",
      "Epoch 1849/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.9716 - val_loss: 110.3037\n",
      "Epoch 1850/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5013 - val_loss: 94.0518\n",
      "Epoch 1851/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6739 - val_loss: 101.9428\n",
      "Epoch 1852/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.4881 - val_loss: 166.3834\n",
      "Epoch 1853/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.1008 - val_loss: 99.5894\n",
      "Epoch 1854/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6002 - val_loss: 112.0805\n",
      "Epoch 1855/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.9821 - val_loss: 101.9309\n",
      "Epoch 1856/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3057 - val_loss: 126.1902\n",
      "Epoch 1857/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 43.1292 - val_loss: 129.9078\n",
      "Epoch 1858/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.5667 - val_loss: 104.4032\n",
      "Epoch 1859/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.5139 - val_loss: 116.5704\n",
      "Epoch 1860/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.8087 - val_loss: 95.9062\n",
      "Epoch 1861/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.8352 - val_loss: 91.8125\n",
      "Epoch 1862/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.2354 - val_loss: 124.1419\n",
      "Epoch 1863/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4834 - val_loss: 123.2348\n",
      "Epoch 1864/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.9043 - val_loss: 174.2932\n",
      "Epoch 1865/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.8188 - val_loss: 140.6839\n",
      "Epoch 1866/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1671 - val_loss: 112.0059\n",
      "Epoch 1867/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.9703 - val_loss: 104.2047\n",
      "Epoch 1868/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5601 - val_loss: 124.6445\n",
      "Epoch 1869/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7393 - val_loss: 96.3685\n",
      "Epoch 1870/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6143 - val_loss: 124.3193\n",
      "Epoch 1871/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.8478 - val_loss: 119.6537\n",
      "Epoch 1872/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6152 - val_loss: 120.8511\n",
      "Epoch 1873/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.3538 - val_loss: 107.7480\n",
      "Epoch 1874/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.1342 - val_loss: 153.7678\n",
      "Epoch 1875/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.2087 - val_loss: 117.0493\n",
      "Epoch 1876/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.3013 - val_loss: 112.8187\n",
      "Epoch 1877/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.8011 - val_loss: 126.9837\n",
      "Epoch 1878/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.0917 - val_loss: 145.3420\n",
      "Epoch 1879/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.7589 - val_loss: 120.2813\n",
      "Epoch 1880/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 43.9920 - val_loss: 132.3818\n",
      "Epoch 1881/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8481 - val_loss: 102.8811\n",
      "Epoch 1882/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.6740 - val_loss: 117.9636\n",
      "Epoch 1883/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.5130 - val_loss: 104.7352\n",
      "Epoch 1884/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6217 - val_loss: 98.3670\n",
      "Epoch 1885/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.5099 - val_loss: 153.1122\n",
      "Epoch 1886/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.4702 - val_loss: 111.2875\n",
      "Epoch 1887/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3968 - val_loss: 137.8869\n",
      "Epoch 1888/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.6807 - val_loss: 136.6953\n",
      "Epoch 1889/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.4598 - val_loss: 126.5989\n",
      "Epoch 1890/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.0375 - val_loss: 143.7611\n",
      "Epoch 1891/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6065 - val_loss: 111.7026\n",
      "Epoch 1892/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7031 - val_loss: 114.2133\n",
      "Epoch 1893/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.4682 - val_loss: 107.3671\n",
      "Epoch 1894/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.7375 - val_loss: 112.3556\n",
      "Epoch 1895/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 43.0531 - val_loss: 176.7837\n",
      "Epoch 1896/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.6388 - val_loss: 134.3532\n",
      "Epoch 1897/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.3274 - val_loss: 115.1422\n",
      "Epoch 1898/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.4597 - val_loss: 133.1031\n",
      "Epoch 1899/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.8054 - val_loss: 128.0914\n",
      "Epoch 1900/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 42.8334 - val_loss: 101.3383\n",
      "Epoch 1901/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.3386 - val_loss: 139.0287\n",
      "Epoch 1902/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 42.9641 - val_loss: 111.3140\n",
      "Epoch 1903/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.0216 - val_loss: 101.4564\n",
      "Epoch 1904/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5596 - val_loss: 99.9098\n",
      "Epoch 1905/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.2403 - val_loss: 121.8687\n",
      "Epoch 1906/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.4535 - val_loss: 99.4056\n",
      "Epoch 1907/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.6033 - val_loss: 98.8208\n",
      "Epoch 1908/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.3608 - val_loss: 119.2090\n",
      "Epoch 1909/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.0378 - val_loss: 123.9471\n",
      "Epoch 1910/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 43.4151 - val_loss: 105.5564\n",
      "Epoch 1911/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.3044 - val_loss: 112.9538\n",
      "Epoch 1912/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.2915 - val_loss: 117.0125\n",
      "Epoch 1913/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5554 - val_loss: 117.7391\n",
      "Epoch 1914/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5420 - val_loss: 114.0012\n",
      "Epoch 1915/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.9658 - val_loss: 114.5261\n",
      "Epoch 1916/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.1248 - val_loss: 105.1694\n",
      "Epoch 1917/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.8226 - val_loss: 100.6259\n",
      "Epoch 1918/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.6257 - val_loss: 128.3618\n",
      "Epoch 1919/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.4945 - val_loss: 98.3420\n",
      "Epoch 1920/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.3216 - val_loss: 134.3003\n",
      "Epoch 1921/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.4567 - val_loss: 109.7240\n",
      "Epoch 1922/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.4151 - val_loss: 135.4472\n",
      "Epoch 1923/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.8032 - val_loss: 97.4364\n",
      "Epoch 1924/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.2841 - val_loss: 101.4056\n",
      "Epoch 1925/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5407 - val_loss: 99.9983\n",
      "Epoch 1926/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7591 - val_loss: 132.5971\n",
      "Epoch 1927/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.2694 - val_loss: 151.3243\n",
      "Epoch 1928/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.6553 - val_loss: 100.7508\n",
      "Epoch 1929/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7698 - val_loss: 96.4103\n",
      "Epoch 1930/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 43.4761 - val_loss: 114.5393\n",
      "Epoch 1931/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.3950 - val_loss: 100.3138\n",
      "Epoch 1932/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.7528 - val_loss: 183.4240\n",
      "Epoch 1933/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 43.3516 - val_loss: 133.7366\n",
      "Epoch 1934/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.2495 - val_loss: 140.8892\n",
      "Epoch 1935/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.5530 - val_loss: 149.5853\n",
      "Epoch 1936/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7391 - val_loss: 93.9810\n",
      "Epoch 1937/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 42.8692 - val_loss: 101.8917\n",
      "Epoch 1938/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.0282 - val_loss: 111.3033\n",
      "Epoch 1939/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.9168 - val_loss: 123.2727\n",
      "Epoch 1940/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.0347 - val_loss: 131.2210\n",
      "Epoch 1941/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.7174 - val_loss: 144.0474\n",
      "Epoch 1942/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.2124 - val_loss: 120.7274\n",
      "Epoch 1943/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.1025 - val_loss: 153.5752\n",
      "Epoch 1944/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.9546 - val_loss: 117.2817\n",
      "Epoch 1945/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.9151 - val_loss: 105.8808\n",
      "Epoch 1946/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8644 - val_loss: 99.8600\n",
      "Epoch 1947/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 43.4063 - val_loss: 113.5280\n",
      "Epoch 1948/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.3203 - val_loss: 111.3141\n",
      "Epoch 1949/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.2909 - val_loss: 108.7060\n",
      "Epoch 1950/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.9359 - val_loss: 103.8354\n",
      "Epoch 1951/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.6541 - val_loss: 105.2708\n",
      "Epoch 1952/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.5906 - val_loss: 116.5648\n",
      "Epoch 1953/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.3217 - val_loss: 121.8312\n",
      "Epoch 1954/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.7716 - val_loss: 116.8987\n",
      "Epoch 1955/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.6618 - val_loss: 103.7939\n",
      "Epoch 1956/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.3309 - val_loss: 143.1784\n",
      "Epoch 1957/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6287 - val_loss: 90.6703\n",
      "Epoch 1958/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3615 - val_loss: 100.2981\n",
      "Epoch 1959/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 42.6997 - val_loss: 123.0354\n",
      "Epoch 1960/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.5165 - val_loss: 102.9731\n",
      "Epoch 1961/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.6661 - val_loss: 176.9781\n",
      "Epoch 1962/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.2180 - val_loss: 107.3129\n",
      "Epoch 1963/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.5832 - val_loss: 125.9419\n",
      "Epoch 1964/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.4566 - val_loss: 146.3176\n",
      "Epoch 1965/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.0902 - val_loss: 112.6578\n",
      "Epoch 1966/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.0103 - val_loss: 97.7211\n",
      "Epoch 1967/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.9212 - val_loss: 94.2077\n",
      "Epoch 1968/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.1197 - val_loss: 131.3298\n",
      "Epoch 1969/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.5228 - val_loss: 169.7817\n",
      "Epoch 1970/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.1230 - val_loss: 104.6324\n",
      "Epoch 1971/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 43.7709 - val_loss: 124.8437\n",
      "Epoch 1972/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.2244 - val_loss: 104.9053\n",
      "Epoch 1973/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.6546 - val_loss: 113.7225\n",
      "Epoch 1974/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.1841 - val_loss: 113.5104\n",
      "Epoch 1975/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 42.7874 - val_loss: 152.4182\n",
      "Epoch 1976/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.9741 - val_loss: 127.5591\n",
      "Epoch 1977/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.3501 - val_loss: 118.1731\n",
      "Epoch 1978/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.8606 - val_loss: 110.3616\n",
      "Epoch 1979/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.0799 - val_loss: 171.4660\n",
      "Epoch 1980/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.2485 - val_loss: 100.7630\n",
      "Epoch 1981/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 43.6621 - val_loss: 97.6247\n",
      "Epoch 1982/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.7511 - val_loss: 115.3845\n",
      "Epoch 1983/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.2789 - val_loss: 102.8211\n",
      "Epoch 1984/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.3905 - val_loss: 115.0232\n",
      "Epoch 1985/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.2992 - val_loss: 123.2235\n",
      "Epoch 1986/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 42.8613 - val_loss: 104.4261\n",
      "Epoch 1987/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 43.5147 - val_loss: 115.1419\n",
      "Epoch 1988/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.1751 - val_loss: 111.6384\n",
      "Epoch 1989/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.8379 - val_loss: 106.0089\n",
      "Epoch 1990/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 42.9873 - val_loss: 105.6343\n",
      "Epoch 1991/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7082 - val_loss: 101.7288\n",
      "Epoch 1992/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.4330 - val_loss: 140.7089\n",
      "Epoch 1993/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.2415 - val_loss: 102.6143\n",
      "Epoch 1994/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.5650 - val_loss: 104.7152\n",
      "Epoch 1995/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.7444 - val_loss: 99.5987\n",
      "Epoch 1996/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8732 - val_loss: 96.7479\n",
      "Epoch 1997/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.3382 - val_loss: 174.8216\n",
      "Epoch 1998/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3265 - val_loss: 139.0208\n",
      "Epoch 1999/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 44.8105 - val_loss: 100.3587\n",
      "Epoch 2000/2000\n",
      "152/152 [==============================] - 1s 6ms/step - loss: 45.0815 - val_loss: 97.0850\n"
     ]
    }
   ],
   "source": [
    "model_2 = None\n",
    "model_history_2 = pd.DataFrame()\n",
    "\n",
    "if os.path.exists(model_name_2):\n",
    "    print(\"Model Found: Loading...\")\n",
    "    model_2 = load_model(model_name_2)\n",
    "    model_history_2 = pd.read_csv(history_name_2)\n",
    "    print(model_2.summary())\n",
    "    print(\"Model Loaded!\")\n",
    "else:\n",
    "    print(\"Model not Found. Fitting model...\")\n",
    "    model_2, model_history_2 = stock_model(num_features, epochs, optimizer_2, model_name_2, history_name_2)\n",
    "    model_history_2 = model_history_2.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f95d494e3ce6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_history_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'--'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Baseline Val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_history_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Baseline Train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mae\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "plt.plot(np.arange(0,epochs,1), model_history_2['val_loss'],'--', label='Baseline Val')\n",
    "plt.plot(np.arange(0,epochs,1), model_history_2['loss'], color='blue', label='Baseline Train')\n",
    "plt.ylabel(\"mae\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.xlim([0,max(np.arange(0,epochs,1))])\n",
    "plt.ylim(50000)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................- 20\n",
      "....................- 40\n",
      "....................- 60\n",
      "....................- 80\n",
      "....................- 100\n",
      "....................- 120\n",
      "....................- 140\n",
      "....................- 160\n",
      "....................- 180\n",
      "....................- 200\n",
      "....................- 220\n",
      "....................- 240\n",
      ".- 242\n",
      "End of data prediction!\n"
     ]
    }
   ],
   "source": [
    "predicted_y_2 = check_all_test_data(test_x, model_2)\n",
    "print(\"End of data prediction!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f259275c18>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.arange(1,len(actual_y)+1)\n",
    "plt.plot(x_axis, predicted_y_2[:,0], label='predicted data')\n",
    "plt.plot(x_axis, actual_y[:,0], label='actual data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE =  150.41829196854792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f25ca9bef0>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print RMSE\n",
    "mse = mean_squared_error(actual_y, predicted_y_2)\n",
    "rmse = math.sqrt(mse)\n",
    "print(\"RMSE = \",rmse)\n",
    "\n",
    "def percent_diff(actual, predicted):\n",
    "    return ((actual-predicted)/actual) * 100\n",
    "\n",
    "#get percent difference between actual and predicted\n",
    "difference = []\n",
    "for i in range(0,len(actual_y)):\n",
    "    difference.append(percent_diff(actual_y[i],predicted_y_2[i]))\n",
    "\n",
    "x_axis = np.arange(1,len(actual_y)+1)\n",
    "plt.plot(x_axis, difference, label='percent difference')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM MODEL (2000 Epochs with SGD)\n",
    "Creating a 5 day closing stock price forecasting model with LSTM with 2000 epochs using nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_3 = \"nadam\"\n",
    "model_name_3 = \"stock_model_3.h5\"\n",
    "history_name_3 = \"stock_model_history_3.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model not Found. Fitting model...\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 100)               42400     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 5)                 505       \n",
      "=================================================================\n",
      "Total params: 42,905\n",
      "Trainable params: 42,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/2000\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 89493.6328 - val_loss: 36761.5508\n",
      "Epoch 2/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 13021.7871 - val_loss: 11513.5635\n",
      "Epoch 3/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4950.2563 - val_loss: 7498.3857\n",
      "Epoch 4/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3429.2930 - val_loss: 6636.0557\n",
      "Epoch 5/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 4496.9531 - val_loss: 12587.1943\n",
      "Epoch 6/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 8669.6641 - val_loss: 8131.2671\n",
      "Epoch 7/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 3559.3882 - val_loss: 4116.8325\n",
      "Epoch 8/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2247.0903 - val_loss: 3984.6611\n",
      "Epoch 9/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 2144.0754 - val_loss: 4714.0737\n",
      "Epoch 10/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1606.6660 - val_loss: 2941.8770\n",
      "Epoch 11/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1538.5652 - val_loss: 2982.3206\n",
      "Epoch 12/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1452.8391 - val_loss: 1905.4045\n",
      "Epoch 13/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1336.3883 - val_loss: 2663.1743\n",
      "Epoch 14/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1289.5975 - val_loss: 2432.7097\n",
      "Epoch 15/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1262.4388 - val_loss: 2067.2341\n",
      "Epoch 16/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1445.3066 - val_loss: 2087.9507\n",
      "Epoch 17/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1180.3025 - val_loss: 1655.3896\n",
      "Epoch 18/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1328.8683 - val_loss: 2897.7781\n",
      "Epoch 19/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1405.6809 - val_loss: 1977.9850\n",
      "Epoch 20/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 1108.2421 - val_loss: 2086.7434\n",
      "Epoch 21/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 1130.2502 - val_loss: 1824.0776\n",
      "Epoch 22/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 969.6525 - val_loss: 1652.1660\n",
      "Epoch 23/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 842.5263 - val_loss: 1632.4255\n",
      "Epoch 24/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 826.2759 - val_loss: 1164.5743\n",
      "Epoch 25/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 790.5285 - val_loss: 1005.0375\n",
      "Epoch 26/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 760.0140 - val_loss: 1150.6553\n",
      "Epoch 27/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 749.1847 - val_loss: 1416.9651\n",
      "Epoch 28/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 737.6685 - val_loss: 1095.4840\n",
      "Epoch 29/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 731.2134 - val_loss: 1181.9316\n",
      "Epoch 30/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 724.5267 - val_loss: 1037.1311\n",
      "Epoch 31/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 719.2200 - val_loss: 992.8218\n",
      "Epoch 32/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 723.2955 - val_loss: 985.2670\n",
      "Epoch 33/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 715.6222 - val_loss: 989.2483\n",
      "Epoch 34/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 733.3594 - val_loss: 989.3915\n",
      "Epoch 35/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 663.2795 - val_loss: 1825.2285\n",
      "Epoch 36/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 679.8714 - val_loss: 1024.6580\n",
      "Epoch 37/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 604.0029 - val_loss: 799.0729\n",
      "Epoch 38/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 548.1016 - val_loss: 719.7976\n",
      "Epoch 39/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 458.3782 - val_loss: 423.2374\n",
      "Epoch 40/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 402.9114 - val_loss: 520.4155\n",
      "Epoch 41/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 345.6011 - val_loss: 695.6285\n",
      "Epoch 42/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 336.5697 - val_loss: 549.8529\n",
      "Epoch 43/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 505.6126 - val_loss: 373.2027\n",
      "Epoch 44/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 341.2827 - val_loss: 473.5751\n",
      "Epoch 45/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 289.6967 - val_loss: 250.1133\n",
      "Epoch 46/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 273.0146 - val_loss: 393.2718\n",
      "Epoch 47/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 268.5793 - val_loss: 256.0757\n",
      "Epoch 48/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 264.2511 - val_loss: 501.2549\n",
      "Epoch 49/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 232.4253 - val_loss: 510.5038\n",
      "Epoch 50/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 229.4313 - val_loss: 284.9568\n",
      "Epoch 51/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 214.7128 - val_loss: 241.4958\n",
      "Epoch 52/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 212.7362 - val_loss: 427.5164\n",
      "Epoch 53/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 199.4949 - val_loss: 349.2729\n",
      "Epoch 54/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 202.4219 - val_loss: 490.3322\n",
      "Epoch 55/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 194.7029 - val_loss: 469.3255\n",
      "Epoch 56/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 199.6030 - val_loss: 402.9646\n",
      "Epoch 57/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 184.4281 - val_loss: 211.6845\n",
      "Epoch 58/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 184.7194 - val_loss: 250.8361\n",
      "Epoch 59/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 178.6704 - val_loss: 395.4354\n",
      "Epoch 60/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 175.1082 - val_loss: 186.3852\n",
      "Epoch 61/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 178.0633 - val_loss: 247.6795\n",
      "Epoch 62/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 167.2854 - val_loss: 253.3929\n",
      "Epoch 63/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 168.4694 - val_loss: 424.5949\n",
      "Epoch 64/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 160.3530 - val_loss: 209.0956\n",
      "Epoch 65/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 161.1919 - val_loss: 153.0108\n",
      "Epoch 66/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 157.5134 - val_loss: 214.4859\n",
      "Epoch 67/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 154.5607 - val_loss: 277.0605\n",
      "Epoch 68/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 154.2761 - val_loss: 272.9307\n",
      "Epoch 69/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 153.8235 - val_loss: 272.6874\n",
      "Epoch 70/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 148.6354 - val_loss: 211.1260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 145.9763 - val_loss: 274.8338\n",
      "Epoch 72/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 141.5575 - val_loss: 133.5639\n",
      "Epoch 73/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 138.5992 - val_loss: 149.7804\n",
      "Epoch 74/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 138.9025 - val_loss: 135.5716\n",
      "Epoch 75/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 132.8860 - val_loss: 315.2443\n",
      "Epoch 76/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 132.8852 - val_loss: 354.5755\n",
      "Epoch 77/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 131.1393 - val_loss: 232.0331\n",
      "Epoch 78/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 127.8920 - val_loss: 269.3506\n",
      "Epoch 79/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 125.1589 - val_loss: 191.6813\n",
      "Epoch 80/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 122.2250 - val_loss: 199.2660\n",
      "Epoch 81/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 118.1698 - val_loss: 140.8956\n",
      "Epoch 82/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 119.8129 - val_loss: 245.1500\n",
      "Epoch 83/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 118.0443 - val_loss: 277.9772\n",
      "Epoch 84/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 116.5171 - val_loss: 193.0587\n",
      "Epoch 85/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 111.8145 - val_loss: 119.7494\n",
      "Epoch 86/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 113.1257 - val_loss: 294.0122\n",
      "Epoch 87/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 111.8955 - val_loss: 306.8530\n",
      "Epoch 88/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 108.8534 - val_loss: 153.7819\n",
      "Epoch 89/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 105.0478 - val_loss: 267.5374\n",
      "Epoch 90/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 106.4551 - val_loss: 206.9901\n",
      "Epoch 91/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 101.2669 - val_loss: 251.0914\n",
      "Epoch 92/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 99.4542 - val_loss: 162.5397\n",
      "Epoch 93/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 99.3907 - val_loss: 212.2634\n",
      "Epoch 94/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 95.0765 - val_loss: 151.1100\n",
      "Epoch 95/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 102.9539 - val_loss: 210.3558\n",
      "Epoch 96/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 93.4337 - val_loss: 128.6027\n",
      "Epoch 97/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 90.8030 - val_loss: 283.3053\n",
      "Epoch 98/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 93.6618 - val_loss: 149.9718\n",
      "Epoch 99/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 91.4419 - val_loss: 168.8637\n",
      "Epoch 100/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 90.4623 - val_loss: 116.4960\n",
      "Epoch 101/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 88.0926 - val_loss: 182.9085\n",
      "Epoch 102/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 85.9860 - val_loss: 224.1460\n",
      "Epoch 103/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 86.8804 - val_loss: 107.9455\n",
      "Epoch 104/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 82.9154 - val_loss: 196.3360\n",
      "Epoch 105/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 87.7837 - val_loss: 122.3968\n",
      "Epoch 106/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 83.4881 - val_loss: 155.7973\n",
      "Epoch 107/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 80.9277 - val_loss: 160.7618\n",
      "Epoch 108/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 79.4132 - val_loss: 214.8710\n",
      "Epoch 109/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 78.0390 - val_loss: 114.2430\n",
      "Epoch 110/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 74.3799 - val_loss: 142.5621\n",
      "Epoch 111/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 75.3259 - val_loss: 129.2688\n",
      "Epoch 112/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 73.8628 - val_loss: 103.0320\n",
      "Epoch 113/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 74.4860 - val_loss: 171.9818\n",
      "Epoch 114/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 70.2274 - val_loss: 155.8998\n",
      "Epoch 115/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 69.3401 - val_loss: 140.9868\n",
      "Epoch 116/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 71.2714 - val_loss: 97.8077\n",
      "Epoch 117/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 71.4026 - val_loss: 154.5912\n",
      "Epoch 118/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 75.6919 - val_loss: 106.2515\n",
      "Epoch 119/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 72.2482 - val_loss: 93.5009\n",
      "Epoch 120/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 70.8926 - val_loss: 118.2616\n",
      "Epoch 121/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 69.1417 - val_loss: 100.6137\n",
      "Epoch 122/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 68.8233 - val_loss: 140.2294\n",
      "Epoch 123/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 68.4070 - val_loss: 107.5604\n",
      "Epoch 124/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 68.2232 - val_loss: 154.4108\n",
      "Epoch 125/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 62.1895 - val_loss: 114.1715\n",
      "Epoch 126/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 66.3068 - val_loss: 167.4084\n",
      "Epoch 127/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 64.6796 - val_loss: 117.3306\n",
      "Epoch 128/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 63.4409 - val_loss: 120.5308\n",
      "Epoch 129/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 61.3982 - val_loss: 126.6392\n",
      "Epoch 130/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 62.9865 - val_loss: 124.6767\n",
      "Epoch 131/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 62.2745 - val_loss: 114.6375\n",
      "Epoch 132/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 70.5752 - val_loss: 101.2178\n",
      "Epoch 133/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 67.9362 - val_loss: 91.5847\n",
      "Epoch 134/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 64.8630 - val_loss: 104.6859\n",
      "Epoch 135/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 64.5292 - val_loss: 97.3877\n",
      "Epoch 136/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 64.1228 - val_loss: 126.2281\n",
      "Epoch 137/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 61.7957 - val_loss: 101.2530\n",
      "Epoch 138/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 60.8833 - val_loss: 93.7552\n",
      "Epoch 139/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 58.7684 - val_loss: 118.3517\n",
      "Epoch 140/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 59.2233 - val_loss: 141.6229\n",
      "Epoch 141/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 58.9554 - val_loss: 160.6657\n",
      "Epoch 142/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 58.4845 - val_loss: 141.4647\n",
      "Epoch 143/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 59.3423 - val_loss: 143.1310\n",
      "Epoch 144/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 58.3996 - val_loss: 113.9855\n",
      "Epoch 145/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 56.5885 - val_loss: 115.5321\n",
      "Epoch 146/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 53.8095 - val_loss: 109.2862\n",
      "Epoch 147/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 54.9950 - val_loss: 94.9414\n",
      "Epoch 148/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 54.7194 - val_loss: 96.5347\n",
      "Epoch 149/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 53.0699 - val_loss: 134.7426\n",
      "Epoch 150/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 52.5688 - val_loss: 128.4061\n",
      "Epoch 151/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 54.1479 - val_loss: 106.6871\n",
      "Epoch 152/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 52.4841 - val_loss: 97.1791\n",
      "Epoch 153/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 53.6002 - val_loss: 96.5923\n",
      "Epoch 154/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 51.4992 - val_loss: 88.7326\n",
      "Epoch 155/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 52.3259 - val_loss: 109.6538\n",
      "Epoch 156/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 52.9961 - val_loss: 99.0319\n",
      "Epoch 157/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 51.5911 - val_loss: 90.1172\n",
      "Epoch 158/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 51.7582 - val_loss: 117.2499\n",
      "Epoch 159/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 51.4711 - val_loss: 97.5547\n",
      "Epoch 160/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 51.9162 - val_loss: 106.3810\n",
      "Epoch 161/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 51.1173 - val_loss: 153.4122\n",
      "Epoch 162/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.5091 - val_loss: 155.2465\n",
      "Epoch 163/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.5168 - val_loss: 104.8235\n",
      "Epoch 164/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.5182 - val_loss: 113.6144\n",
      "Epoch 165/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.4567 - val_loss: 155.2487\n",
      "Epoch 166/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.4854 - val_loss: 105.5642\n",
      "Epoch 167/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.0245 - val_loss: 121.5126\n",
      "Epoch 168/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.1902 - val_loss: 96.4813\n",
      "Epoch 169/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.7704 - val_loss: 98.8065\n",
      "Epoch 170/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 50.1749 - val_loss: 112.8810\n",
      "Epoch 171/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.3769 - val_loss: 92.8956\n",
      "Epoch 172/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.7093 - val_loss: 94.3811\n",
      "Epoch 173/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 55.3260 - val_loss: 99.1225\n",
      "Epoch 174/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.9818 - val_loss: 107.2186\n",
      "Epoch 175/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.5192 - val_loss: 101.0972\n",
      "Epoch 176/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.9223 - val_loss: 103.8927\n",
      "Epoch 177/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.3353 - val_loss: 118.7292\n",
      "Epoch 178/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.6829 - val_loss: 89.6591\n",
      "Epoch 179/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.2142 - val_loss: 101.2233\n",
      "Epoch 180/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 49.0351 - val_loss: 114.6411\n",
      "Epoch 181/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 48.8941 - val_loss: 88.8980\n",
      "Epoch 182/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.0125 - val_loss: 94.1427\n",
      "Epoch 183/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.6309 - val_loss: 95.0685\n",
      "Epoch 184/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.6073 - val_loss: 108.3946\n",
      "Epoch 185/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.5970 - val_loss: 134.0630\n",
      "Epoch 186/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.9820 - val_loss: 120.7192\n",
      "Epoch 187/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.9541 - val_loss: 121.7100\n",
      "Epoch 188/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.5944 - val_loss: 105.3219\n",
      "Epoch 189/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.9758 - val_loss: 96.9534\n",
      "Epoch 190/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.5463 - val_loss: 94.4680\n",
      "Epoch 191/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.2469 - val_loss: 99.0408\n",
      "Epoch 192/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.9322 - val_loss: 94.3083\n",
      "Epoch 193/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.8432 - val_loss: 137.8853\n",
      "Epoch 194/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.9885 - val_loss: 110.5210\n",
      "Epoch 195/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.7458 - val_loss: 122.9263\n",
      "Epoch 196/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.2647 - val_loss: 97.9905\n",
      "Epoch 197/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.1999 - val_loss: 93.9837\n",
      "Epoch 198/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.2072 - val_loss: 102.7809\n",
      "Epoch 199/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.7201 - val_loss: 107.7157\n",
      "Epoch 200/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.1363 - val_loss: 102.2389\n",
      "Epoch 201/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 46.9601 - val_loss: 102.5697\n",
      "Epoch 202/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3351 - val_loss: 128.0588\n",
      "Epoch 203/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.8129 - val_loss: 98.2254\n",
      "Epoch 204/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.8426 - val_loss: 89.3701\n",
      "Epoch 205/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.9698 - val_loss: 113.4657\n",
      "Epoch 206/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.1377 - val_loss: 97.4204\n",
      "Epoch 207/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 42.8414 - val_loss: 96.2328\n",
      "Epoch 208/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.1416 - val_loss: 94.1505\n",
      "Epoch 209/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 42.3294 - val_loss: 100.1360\n",
      "Epoch 210/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.0111 - val_loss: 105.6392\n",
      "Epoch 211/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.1238 - val_loss: 114.7513\n",
      "Epoch 212/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 44.2765 - val_loss: 121.0641\n",
      "Epoch 213/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 42.9217 - val_loss: 99.8578\n",
      "Epoch 214/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 42.7870 - val_loss: 111.6598\n",
      "Epoch 215/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 42.5174 - val_loss: 101.8517\n",
      "Epoch 216/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.2671 - val_loss: 116.1380\n",
      "Epoch 217/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 42.3303 - val_loss: 98.8285\n",
      "Epoch 218/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 41.4990 - val_loss: 101.4558\n",
      "Epoch 219/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 43.0062 - val_loss: 96.6558\n",
      "Epoch 220/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 42.4073 - val_loss: 88.8224\n",
      "Epoch 221/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 42.0647 - val_loss: 93.4579\n",
      "Epoch 222/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 41.5250 - val_loss: 96.9659\n",
      "Epoch 223/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 41.5161 - val_loss: 131.5003\n",
      "Epoch 224/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 41.1807 - val_loss: 103.3171\n",
      "Epoch 225/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 41.0863 - val_loss: 88.2590\n",
      "Epoch 226/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 42.7649 - val_loss: 106.7787\n",
      "Epoch 227/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 41.0850 - val_loss: 109.6484\n",
      "Epoch 228/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 40.9049 - val_loss: 93.2958\n",
      "Epoch 229/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 41.8529 - val_loss: 111.5397\n",
      "Epoch 230/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 41.8716 - val_loss: 90.2773\n",
      "Epoch 231/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 41.7267 - val_loss: 120.0617\n",
      "Epoch 232/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 40.1029 - val_loss: 91.9657\n",
      "Epoch 233/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 42.0056 - val_loss: 122.0577\n",
      "Epoch 234/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 40.2783 - val_loss: 98.2983\n",
      "Epoch 235/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 41.0238 - val_loss: 105.8407\n",
      "Epoch 236/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 40.3590 - val_loss: 131.1996\n",
      "Epoch 237/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 40.5048 - val_loss: 141.0143\n",
      "Epoch 238/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 40.7348 - val_loss: 93.8253\n",
      "Epoch 239/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 39.1865 - val_loss: 113.9340\n",
      "Epoch 240/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 40.4439 - val_loss: 119.7939\n",
      "Epoch 241/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 41.2578 - val_loss: 141.7357\n",
      "Epoch 242/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 39.5692 - val_loss: 100.2633\n",
      "Epoch 243/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 39.4245 - val_loss: 87.9032\n",
      "Epoch 244/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 38.6340 - val_loss: 102.6404\n",
      "Epoch 245/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 38.7707 - val_loss: 98.2254\n",
      "Epoch 246/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 39.9546 - val_loss: 110.3168\n",
      "Epoch 247/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 40.0542 - val_loss: 122.6151\n",
      "Epoch 248/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 38.9733 - val_loss: 122.5864\n",
      "Epoch 249/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 38.8380 - val_loss: 93.8094\n",
      "Epoch 250/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 39.2047 - val_loss: 105.2251\n",
      "Epoch 251/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 39.6077 - val_loss: 108.2224\n",
      "Epoch 252/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 38.8688 - val_loss: 120.9921\n",
      "Epoch 253/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 38.8418 - val_loss: 91.5149\n",
      "Epoch 254/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 38.6962 - val_loss: 96.7827\n",
      "Epoch 255/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 39.0489 - val_loss: 98.1391\n",
      "Epoch 256/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 38.4373 - val_loss: 89.3951\n",
      "Epoch 257/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 40.2780 - val_loss: 97.9692\n",
      "Epoch 258/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 38.2377 - val_loss: 91.2525\n",
      "Epoch 259/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 38.6593 - val_loss: 100.4671\n",
      "Epoch 260/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 38.6602 - val_loss: 99.7607\n",
      "Epoch 261/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 38.3176 - val_loss: 91.6248\n",
      "Epoch 262/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 37.3689 - val_loss: 102.4847\n",
      "Epoch 263/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 39.0938 - val_loss: 115.2981\n",
      "Epoch 264/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 37.2846 - val_loss: 93.5733\n",
      "Epoch 265/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 39.3647 - val_loss: 92.1840\n",
      "Epoch 266/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 37.8293 - val_loss: 97.0363\n",
      "Epoch 267/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 37.7945 - val_loss: 96.9270\n",
      "Epoch 268/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 38.3789 - val_loss: 96.3766\n",
      "Epoch 269/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 38.2179 - val_loss: 95.9972\n",
      "Epoch 270/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 38.0054 - val_loss: 123.4747\n",
      "Epoch 271/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 37.4275 - val_loss: 104.2792\n",
      "Epoch 272/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 37.1789 - val_loss: 94.2187\n",
      "Epoch 273/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 37.2021 - val_loss: 87.9960\n",
      "Epoch 274/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 38.0277 - val_loss: 116.7896\n",
      "Epoch 275/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 38.0406 - val_loss: 107.3356\n",
      "Epoch 276/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 35.5844 - val_loss: 102.9051\n",
      "Epoch 277/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 37.5940 - val_loss: 110.9957\n",
      "Epoch 278/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 36.6409 - val_loss: 111.1266\n",
      "Epoch 279/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 37.4571 - val_loss: 97.0149\n",
      "Epoch 280/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 37.4761 - val_loss: 95.7723\n",
      "Epoch 281/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 36.6427 - val_loss: 93.6377\n",
      "Epoch 282/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 36.6264 - val_loss: 110.5345\n",
      "Epoch 283/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 36.1985 - val_loss: 109.1597\n",
      "Epoch 284/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 35.5996 - val_loss: 94.9986\n",
      "Epoch 285/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 37.0089 - val_loss: 91.4228\n",
      "Epoch 286/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 35.3680 - val_loss: 92.1118\n",
      "Epoch 287/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 35.3746 - val_loss: 109.1247\n",
      "Epoch 288/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 35.9456 - val_loss: 92.5755\n",
      "Epoch 289/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 36.5847 - val_loss: 98.8284\n",
      "Epoch 290/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 37.0215 - val_loss: 96.4666\n",
      "Epoch 291/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 36.5483 - val_loss: 103.5799\n",
      "Epoch 292/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 34.6330 - val_loss: 93.3231\n",
      "Epoch 293/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 35.3913 - val_loss: 100.1960\n",
      "Epoch 294/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 34.4392 - val_loss: 113.9058\n",
      "Epoch 295/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 36.6197 - val_loss: 99.0595\n",
      "Epoch 296/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 35.8420 - val_loss: 96.8956\n",
      "Epoch 297/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 35.7442 - val_loss: 95.5917\n",
      "Epoch 298/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 35.6034 - val_loss: 89.4041\n",
      "Epoch 299/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 35.3479 - val_loss: 92.1329\n",
      "Epoch 300/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 35.2473 - val_loss: 97.8264\n",
      "Epoch 301/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 35.3600 - val_loss: 108.1279\n",
      "Epoch 302/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 34.9139 - val_loss: 91.2378\n",
      "Epoch 303/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 35.5599 - val_loss: 105.3917\n",
      "Epoch 304/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 34.1477 - val_loss: 89.5748\n",
      "Epoch 305/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 35.0173 - val_loss: 101.4803\n",
      "Epoch 306/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 34.5398 - val_loss: 93.6726\n",
      "Epoch 307/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 35.1814 - val_loss: 91.1429\n",
      "Epoch 308/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 34.0822 - val_loss: 102.4264\n",
      "Epoch 309/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 33.8122 - val_loss: 90.8651\n",
      "Epoch 310/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 34.4641 - val_loss: 101.6702\n",
      "Epoch 311/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 33.8222 - val_loss: 96.1017\n",
      "Epoch 312/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 33.5261 - val_loss: 91.1040\n",
      "Epoch 313/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 34.4700 - val_loss: 93.9257\n",
      "Epoch 314/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 33.9557 - val_loss: 89.4120\n",
      "Epoch 315/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 34.2710 - val_loss: 96.5107\n",
      "Epoch 316/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 33.5916 - val_loss: 97.2507\n",
      "Epoch 317/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 33.8489 - val_loss: 96.3424\n",
      "Epoch 318/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 33.3382 - val_loss: 92.6055\n",
      "Epoch 319/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 33.7762 - val_loss: 89.3935\n",
      "Epoch 320/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 32.4901 - val_loss: 94.0026\n",
      "Epoch 321/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 34.1623 - val_loss: 104.8033\n",
      "Epoch 322/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 33.6508 - val_loss: 99.0639\n",
      "Epoch 323/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 33.1573 - val_loss: 95.7135\n",
      "Epoch 324/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 33.3998 - val_loss: 100.2939\n",
      "Epoch 325/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 33.3051 - val_loss: 92.4216\n",
      "Epoch 326/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 32.9851 - val_loss: 95.7358\n",
      "Epoch 327/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 32.8437 - val_loss: 89.7135\n",
      "Epoch 328/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 33.8579 - val_loss: 95.8647\n",
      "Epoch 329/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 32.2321 - val_loss: 93.4193\n",
      "Epoch 330/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 32.9918 - val_loss: 100.5001\n",
      "Epoch 331/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 32.7209 - val_loss: 94.4945\n",
      "Epoch 332/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 32.7193 - val_loss: 104.4308\n",
      "Epoch 333/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 32.0210 - val_loss: 96.3296\n",
      "Epoch 334/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.8536 - val_loss: 90.0123\n",
      "Epoch 335/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 33.2035 - val_loss: 98.2736\n",
      "Epoch 336/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 32.2217 - val_loss: 115.9584\n",
      "Epoch 337/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 33.2850 - val_loss: 99.2255\n",
      "Epoch 338/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 32.2996 - val_loss: 92.2795\n",
      "Epoch 339/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.0281 - val_loss: 94.4955\n",
      "Epoch 340/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 32.1163 - val_loss: 97.8189\n",
      "Epoch 341/2000\n",
      "152/152 [==============================] - ETA: 0s - loss: 30.83 - 1s 7ms/step - loss: 30.9380 - val_loss: 103.7607\n",
      "Epoch 342/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 32.4687 - val_loss: 93.2788\n",
      "Epoch 343/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 32.7014 - val_loss: 97.2844\n",
      "Epoch 344/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.5066 - val_loss: 93.7913\n",
      "Epoch 345/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.5848 - val_loss: 100.9658\n",
      "Epoch 346/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.9570 - val_loss: 102.1900\n",
      "Epoch 347/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.5297 - val_loss: 89.0894\n",
      "Epoch 348/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.4373 - val_loss: 106.6827\n",
      "Epoch 349/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.6788 - val_loss: 89.7905\n",
      "Epoch 350/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.3959 - val_loss: 104.8457\n",
      "Epoch 351/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.0284 - val_loss: 91.1446\n",
      "Epoch 352/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.1378 - val_loss: 119.6856\n",
      "Epoch 353/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.1216 - val_loss: 91.9903\n",
      "Epoch 354/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.1256 - val_loss: 89.4634\n",
      "Epoch 355/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.1196 - val_loss: 100.0909\n",
      "Epoch 356/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.8774 - val_loss: 93.0351\n",
      "Epoch 357/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.2089 - val_loss: 98.4745\n",
      "Epoch 358/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.2072 - val_loss: 91.1846\n",
      "Epoch 359/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.9980 - val_loss: 96.1528\n",
      "Epoch 360/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.4481 - val_loss: 91.2902\n",
      "Epoch 361/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.5080 - val_loss: 89.4330\n",
      "Epoch 362/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.8033 - val_loss: 94.2344\n",
      "Epoch 363/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.1948 - val_loss: 89.7922\n",
      "Epoch 364/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.0583 - val_loss: 104.4967\n",
      "Epoch 365/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.6569 - val_loss: 100.1257\n",
      "Epoch 366/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.2579 - val_loss: 109.2733\n",
      "Epoch 367/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.5938 - val_loss: 95.9878\n",
      "Epoch 368/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.0717 - val_loss: 97.3952\n",
      "Epoch 369/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.9746 - val_loss: 96.5342\n",
      "Epoch 370/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.7779 - val_loss: 93.8839\n",
      "Epoch 371/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.7693 - val_loss: 92.4934\n",
      "Epoch 372/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.0787 - val_loss: 92.7713\n",
      "Epoch 373/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.3769 - val_loss: 92.5126\n",
      "Epoch 374/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.5196 - val_loss: 93.1038\n",
      "Epoch 375/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 30.1804 - val_loss: 89.6700\n",
      "Epoch 376/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.4465 - val_loss: 97.2292\n",
      "Epoch 377/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.2413 - val_loss: 95.1286\n",
      "Epoch 378/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 28.9588 - val_loss: 92.1008\n",
      "Epoch 379/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.9157 - val_loss: 96.2217\n",
      "Epoch 380/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.8305 - val_loss: 96.8365\n",
      "Epoch 381/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.9552 - val_loss: 91.3030\n",
      "Epoch 382/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.6118 - val_loss: 105.8248\n",
      "Epoch 383/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.0184 - val_loss: 94.4372\n",
      "Epoch 384/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.4103 - val_loss: 92.3491\n",
      "Epoch 385/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.0262 - val_loss: 92.8831\n",
      "Epoch 386/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.2662 - val_loss: 91.1813\n",
      "Epoch 387/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.8642 - val_loss: 90.4129\n",
      "Epoch 388/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.4288 - val_loss: 91.7210\n",
      "Epoch 389/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.0574 - val_loss: 95.3576\n",
      "Epoch 390/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.6889 - val_loss: 91.3865\n",
      "Epoch 391/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.6094 - val_loss: 89.3004\n",
      "Epoch 392/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.9562 - val_loss: 94.4981\n",
      "Epoch 393/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 33.5135 - val_loss: 89.6981\n",
      "Epoch 394/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.7710 - val_loss: 94.0750\n",
      "Epoch 395/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.4876 - val_loss: 93.1819\n",
      "Epoch 396/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.7143 - val_loss: 91.9290\n",
      "Epoch 397/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.6627 - val_loss: 98.3464\n",
      "Epoch 398/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.6735 - val_loss: 96.6302\n",
      "Epoch 399/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.0909 - val_loss: 90.8714\n",
      "Epoch 400/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.2960 - val_loss: 92.6629\n",
      "Epoch 401/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.5256 - val_loss: 92.3849\n",
      "Epoch 402/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.6674 - val_loss: 91.2544\n",
      "Epoch 403/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.0581 - val_loss: 91.6424\n",
      "Epoch 404/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.5730 - val_loss: 90.9219\n",
      "Epoch 405/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.8420 - val_loss: 91.4536\n",
      "Epoch 406/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.6590 - val_loss: 94.0568\n",
      "Epoch 407/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.2301 - val_loss: 95.5652\n",
      "Epoch 408/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.8746 - val_loss: 92.1343\n",
      "Epoch 409/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.8296 - val_loss: 90.7171\n",
      "Epoch 410/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 32.2572 - val_loss: 91.1814\n",
      "Epoch 411/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.2164 - val_loss: 95.4657\n",
      "Epoch 412/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.7963 - val_loss: 91.1039\n",
      "Epoch 413/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.4336 - val_loss: 93.4100\n",
      "Epoch 414/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.4553 - val_loss: 90.9667\n",
      "Epoch 415/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.4018 - val_loss: 91.2721\n",
      "Epoch 416/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.4822 - val_loss: 91.0148\n",
      "Epoch 417/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.1948 - val_loss: 90.9207\n",
      "Epoch 418/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.1008 - val_loss: 91.1829\n",
      "Epoch 419/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8109 - val_loss: 109.5775\n",
      "Epoch 420/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.4057 - val_loss: 92.8297\n",
      "Epoch 421/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8943 - val_loss: 93.3854\n",
      "Epoch 422/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.2996 - val_loss: 108.1320\n",
      "Epoch 423/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.6192 - val_loss: 90.9487\n",
      "Epoch 424/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.6266 - val_loss: 89.8931\n",
      "Epoch 425/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.6593 - val_loss: 90.3504\n",
      "Epoch 426/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.6953 - val_loss: 90.9246\n",
      "Epoch 427/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.3761 - val_loss: 91.8565\n",
      "Epoch 428/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.1447 - val_loss: 91.6332\n",
      "Epoch 429/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.3317 - val_loss: 89.6985\n",
      "Epoch 430/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0288 - val_loss: 88.9896\n",
      "Epoch 431/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.6498 - val_loss: 91.0871\n",
      "Epoch 432/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.5523 - val_loss: 92.6502\n",
      "Epoch 433/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.2442 - val_loss: 98.4079\n",
      "Epoch 434/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.4272 - val_loss: 87.5245\n",
      "Epoch 435/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.9756 - val_loss: 108.4399\n",
      "Epoch 436/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.5550 - val_loss: 92.3305\n",
      "Epoch 437/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7374 - val_loss: 90.9113\n",
      "Epoch 438/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7554 - val_loss: 89.1171\n",
      "Epoch 439/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.2040 - val_loss: 93.2765\n",
      "Epoch 440/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.9107 - val_loss: 87.5035\n",
      "Epoch 441/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2986 - val_loss: 91.6189\n",
      "Epoch 442/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.1125 - val_loss: 88.5213\n",
      "Epoch 443/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.8974 - val_loss: 87.7745\n",
      "Epoch 444/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.5403 - val_loss: 87.0310\n",
      "Epoch 445/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8849 - val_loss: 94.9768\n",
      "Epoch 446/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0942 - val_loss: 88.9911\n",
      "Epoch 447/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8248 - val_loss: 87.2985\n",
      "Epoch 448/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0986 - val_loss: 90.8943\n",
      "Epoch 449/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0472 - val_loss: 89.2354\n",
      "Epoch 450/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6762 - val_loss: 87.7566\n",
      "Epoch 451/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8492 - val_loss: 86.1040\n",
      "Epoch 452/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.1313 - val_loss: 86.5283\n",
      "Epoch 453/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8949 - val_loss: 89.5404\n",
      "Epoch 454/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5124 - val_loss: 93.7276\n",
      "Epoch 455/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.5431 - val_loss: 90.4722\n",
      "Epoch 456/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5296 - val_loss: 88.0931\n",
      "Epoch 457/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.5295 - val_loss: 86.3607\n",
      "Epoch 458/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.3088 - val_loss: 87.6249\n",
      "Epoch 459/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 27.1708 - val_loss: 86.6443\n",
      "Epoch 460/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2281 - val_loss: 105.7205\n",
      "Epoch 461/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.3611 - val_loss: 90.7562\n",
      "Epoch 462/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.1778 - val_loss: 92.5719\n",
      "Epoch 463/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0999 - val_loss: 85.5381\n",
      "Epoch 464/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0774 - val_loss: 87.2008\n",
      "Epoch 465/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8837 - val_loss: 88.4506\n",
      "Epoch 466/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5930 - val_loss: 86.2686\n",
      "Epoch 467/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.0753 - val_loss: 94.0222\n",
      "Epoch 468/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6430 - val_loss: 85.4104\n",
      "Epoch 469/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.4741 - val_loss: 96.5661\n",
      "Epoch 470/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8359 - val_loss: 84.5688\n",
      "Epoch 471/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.0766 - val_loss: 84.9700\n",
      "Epoch 472/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6860 - val_loss: 84.3131\n",
      "Epoch 473/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.4164 - val_loss: 106.1563\n",
      "Epoch 474/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5598 - val_loss: 83.6103\n",
      "Epoch 475/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5213 - val_loss: 94.6302\n",
      "Epoch 476/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2427 - val_loss: 83.0737\n",
      "Epoch 477/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.9753 - val_loss: 88.2006\n",
      "Epoch 478/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5465 - val_loss: 86.0817\n",
      "Epoch 479/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.8407 - val_loss: 91.8123\n",
      "Epoch 480/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.8412 - val_loss: 85.3409\n",
      "Epoch 481/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.0290 - val_loss: 95.6428\n",
      "Epoch 482/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.8177 - val_loss: 85.8922\n",
      "Epoch 483/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7111 - val_loss: 84.2880\n",
      "Epoch 484/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.4126 - val_loss: 83.6441\n",
      "Epoch 485/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.9311 - val_loss: 87.0935\n",
      "Epoch 486/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.4924 - val_loss: 86.0865\n",
      "Epoch 487/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.0713 - val_loss: 96.0298\n",
      "Epoch 488/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.3717 - val_loss: 81.5552\n",
      "Epoch 489/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.3895 - val_loss: 81.7386\n",
      "Epoch 490/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7317 - val_loss: 87.7850\n",
      "Epoch 491/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.5896 - val_loss: 105.1568\n",
      "Epoch 492/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6287 - val_loss: 80.9638\n",
      "Epoch 493/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2254 - val_loss: 80.9272\n",
      "Epoch 494/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.9741 - val_loss: 80.7015\n",
      "Epoch 495/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.0033 - val_loss: 84.7711\n",
      "Epoch 496/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.7575 - val_loss: 92.0863\n",
      "Epoch 497/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.6472 - val_loss: 80.2367\n",
      "Epoch 498/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.7249 - val_loss: 92.2166\n",
      "Epoch 499/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.6978 - val_loss: 80.8334\n",
      "Epoch 500/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.6792 - val_loss: 87.4547\n",
      "Epoch 501/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.4015 - val_loss: 87.7297\n",
      "Epoch 502/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.7407 - val_loss: 85.6079\n",
      "Epoch 503/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.1286 - val_loss: 95.6615\n",
      "Epoch 504/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.1382 - val_loss: 93.7797\n",
      "Epoch 505/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.1219 - val_loss: 86.9923\n",
      "Epoch 506/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.1572 - val_loss: 85.9457\n",
      "Epoch 507/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8246 - val_loss: 79.6371\n",
      "Epoch 508/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.1272 - val_loss: 96.0278\n",
      "Epoch 509/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.9017 - val_loss: 90.6552\n",
      "Epoch 510/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.9583 - val_loss: 88.2361\n",
      "Epoch 511/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2101 - val_loss: 93.7648\n",
      "Epoch 512/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8513 - val_loss: 100.5358\n",
      "Epoch 513/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.0933 - val_loss: 110.6567\n",
      "Epoch 514/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.7441 - val_loss: 91.7988\n",
      "Epoch 515/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.4207 - val_loss: 92.8535\n",
      "Epoch 516/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.1155 - val_loss: 94.1749\n",
      "Epoch 517/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.3432 - val_loss: 94.4011\n",
      "Epoch 518/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0253 - val_loss: 92.7273\n",
      "Epoch 519/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.3359 - val_loss: 95.2264\n",
      "Epoch 520/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.9288 - val_loss: 97.5561\n",
      "Epoch 521/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.8636 - val_loss: 91.4025\n",
      "Epoch 522/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6049 - val_loss: 90.2546\n",
      "Epoch 523/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.9279 - val_loss: 89.2479\n",
      "Epoch 524/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.5779 - val_loss: 94.7035\n",
      "Epoch 525/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.6772 - val_loss: 106.9486\n",
      "Epoch 526/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.3958 - val_loss: 96.5520\n",
      "Epoch 527/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8502 - val_loss: 90.3717\n",
      "Epoch 528/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.7021 - val_loss: 95.7158\n",
      "Epoch 529/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.9205 - val_loss: 94.2193\n",
      "Epoch 530/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2553 - val_loss: 93.8256\n",
      "Epoch 531/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.4996 - val_loss: 81.1042\n",
      "Epoch 532/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7748 - val_loss: 100.4264\n",
      "Epoch 533/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.3192 - val_loss: 92.7909\n",
      "Epoch 534/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.5223 - val_loss: 109.2406\n",
      "Epoch 535/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.6867 - val_loss: 95.7659\n",
      "Epoch 536/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.6085 - val_loss: 96.3817\n",
      "Epoch 537/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.2168 - val_loss: 94.1912\n",
      "Epoch 538/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.3063 - val_loss: 93.2624\n",
      "Epoch 539/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.4540 - val_loss: 94.0115\n",
      "Epoch 540/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.4801 - val_loss: 94.2214\n",
      "Epoch 541/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.1576 - val_loss: 96.1421\n",
      "Epoch 542/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.4925 - val_loss: 98.1266\n",
      "Epoch 543/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.7552 - val_loss: 99.2304\n",
      "Epoch 544/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8040 - val_loss: 93.1602\n",
      "Epoch 545/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.7530 - val_loss: 99.7722\n",
      "Epoch 546/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.2185 - val_loss: 105.0757\n",
      "Epoch 547/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.6500 - val_loss: 106.7263\n",
      "Epoch 548/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.6339 - val_loss: 99.5618\n",
      "Epoch 549/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8376 - val_loss: 99.9760\n",
      "Epoch 550/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.2895 - val_loss: 94.4163\n",
      "Epoch 551/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.6993 - val_loss: 101.7977\n",
      "Epoch 552/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.0848 - val_loss: 96.7409\n",
      "Epoch 553/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5201 - val_loss: 97.2567\n",
      "Epoch 554/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.7367 - val_loss: 98.7934\n",
      "Epoch 555/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.8031 - val_loss: 97.0394\n",
      "Epoch 556/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.3515 - val_loss: 98.1964\n",
      "Epoch 557/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.8807 - val_loss: 98.5374\n",
      "Epoch 558/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.4215 - val_loss: 99.1788\n",
      "Epoch 559/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.7835 - val_loss: 94.8366\n",
      "Epoch 560/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.2196 - val_loss: 99.9090\n",
      "Epoch 561/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.7535 - val_loss: 97.5038\n",
      "Epoch 562/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.2964 - val_loss: 115.9839\n",
      "Epoch 563/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.6063 - val_loss: 95.9417\n",
      "Epoch 564/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.0497 - val_loss: 93.9226\n",
      "Epoch 565/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.3307 - val_loss: 91.2016\n",
      "Epoch 566/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.7888 - val_loss: 100.8010\n",
      "Epoch 567/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.3776 - val_loss: 102.1124\n",
      "Epoch 568/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7654 - val_loss: 92.7182\n",
      "Epoch 569/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.9194 - val_loss: 92.4095\n",
      "Epoch 570/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.6465 - val_loss: 109.4928\n",
      "Epoch 571/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.3809 - val_loss: 97.7132\n",
      "Epoch 572/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.6449 - val_loss: 96.1044\n",
      "Epoch 573/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7695 - val_loss: 93.0190\n",
      "Epoch 574/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.7585 - val_loss: 94.5488\n",
      "Epoch 575/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8017 - val_loss: 94.2406\n",
      "Epoch 576/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7831 - val_loss: 95.5833\n",
      "Epoch 577/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.3836 - val_loss: 94.2815\n",
      "Epoch 578/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 28.0084 - val_loss: 93.1323\n",
      "Epoch 579/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 27.1889 - val_loss: 94.1441\n",
      "Epoch 580/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 27.6809 - val_loss: 93.1921\n",
      "Epoch 581/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.4030 - val_loss: 94.7930\n",
      "Epoch 582/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.2024 - val_loss: 86.1045\n",
      "Epoch 583/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8373 - val_loss: 92.4847\n",
      "Epoch 584/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.4223 - val_loss: 92.8649\n",
      "Epoch 585/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.4132 - val_loss: 94.1024\n",
      "Epoch 586/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.1579 - val_loss: 97.0309\n",
      "Epoch 587/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.9761 - val_loss: 102.1610\n",
      "Epoch 588/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7146 - val_loss: 96.2556\n",
      "Epoch 589/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8754 - val_loss: 99.4592\n",
      "Epoch 590/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.8138 - val_loss: 94.6194\n",
      "Epoch 591/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.7004 - val_loss: 92.8550\n",
      "Epoch 592/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6928 - val_loss: 93.9685\n",
      "Epoch 593/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.2419 - val_loss: 99.5964\n",
      "Epoch 594/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.1680 - val_loss: 103.3695\n",
      "Epoch 595/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 28.1493 - val_loss: 99.4563\n",
      "Epoch 596/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.7678 - val_loss: 92.2788\n",
      "Epoch 597/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.7352 - val_loss: 94.2212\n",
      "Epoch 598/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8667 - val_loss: 93.0270\n",
      "Epoch 599/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.9880 - val_loss: 97.3643\n",
      "Epoch 600/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.2975 - val_loss: 96.4097\n",
      "Epoch 601/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.4105 - val_loss: 92.5156\n",
      "Epoch 602/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.1137 - val_loss: 94.3059\n",
      "Epoch 603/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.9182 - val_loss: 93.9846\n",
      "Epoch 604/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6992 - val_loss: 99.8072\n",
      "Epoch 605/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.1270 - val_loss: 94.2582\n",
      "Epoch 606/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.5475 - val_loss: 84.8586\n",
      "Epoch 607/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7279 - val_loss: 94.2432\n",
      "Epoch 608/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.9363 - val_loss: 93.8636\n",
      "Epoch 609/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8914 - val_loss: 91.0958\n",
      "Epoch 610/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 26.6283 - val_loss: 91.6111\n",
      "Epoch 611/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.7943 - val_loss: 91.8158\n",
      "Epoch 612/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.3230 - val_loss: 91.3789\n",
      "Epoch 613/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7013 - val_loss: 96.1552\n",
      "Epoch 614/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.1865 - val_loss: 97.5459\n",
      "Epoch 615/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6539 - val_loss: 90.4722\n",
      "Epoch 616/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.5195 - val_loss: 97.6630\n",
      "Epoch 617/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.7721 - val_loss: 90.2648\n",
      "Epoch 618/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0403 - val_loss: 97.4706\n",
      "Epoch 619/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.5170 - val_loss: 93.1078\n",
      "Epoch 620/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7620 - val_loss: 99.1309\n",
      "Epoch 621/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0720 - val_loss: 101.1142\n",
      "Epoch 622/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.3053 - val_loss: 95.9250\n",
      "Epoch 623/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0835 - val_loss: 94.4058\n",
      "Epoch 624/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.3658 - val_loss: 95.9779\n",
      "Epoch 625/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.1390 - val_loss: 91.7502\n",
      "Epoch 626/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0018 - val_loss: 95.7306\n",
      "Epoch 627/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.9574 - val_loss: 97.5601\n",
      "Epoch 628/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.4297 - val_loss: 100.0052\n",
      "Epoch 629/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7026 - val_loss: 94.2927\n",
      "Epoch 630/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8740 - val_loss: 96.6066\n",
      "Epoch 631/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.5145 - val_loss: 97.0920\n",
      "Epoch 632/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0318 - val_loss: 99.0607\n",
      "Epoch 633/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.6929 - val_loss: 96.8011\n",
      "Epoch 634/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.6017 - val_loss: 94.2513\n",
      "Epoch 635/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.2558 - val_loss: 97.3172\n",
      "Epoch 636/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0858 - val_loss: 97.6107\n",
      "Epoch 637/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.7384 - val_loss: 97.3652\n",
      "Epoch 638/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7334 - val_loss: 103.5151\n",
      "Epoch 639/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.3028 - val_loss: 96.4120\n",
      "Epoch 640/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.3064 - val_loss: 104.3104\n",
      "Epoch 641/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.8841 - val_loss: 95.6193\n",
      "Epoch 642/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.0002 - val_loss: 92.8051\n",
      "Epoch 643/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7213 - val_loss: 93.8496\n",
      "Epoch 644/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.1925 - val_loss: 93.6705\n",
      "Epoch 645/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6752 - val_loss: 88.0776\n",
      "Epoch 646/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.2794 - val_loss: 78.9789\n",
      "Epoch 647/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6121 - val_loss: 93.7190\n",
      "Epoch 648/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0282 - val_loss: 101.7267\n",
      "Epoch 649/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7122 - val_loss: 94.0740\n",
      "Epoch 650/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.0953 - val_loss: 90.4721\n",
      "Epoch 651/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.1824 - val_loss: 95.5117\n",
      "Epoch 652/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7387 - val_loss: 91.3892\n",
      "Epoch 653/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0267 - val_loss: 91.3185\n",
      "Epoch 654/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.1248 - val_loss: 94.1171\n",
      "Epoch 655/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.9051 - val_loss: 93.7880\n",
      "Epoch 656/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 27.0633 - val_loss: 98.7781\n",
      "Epoch 657/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.1420 - val_loss: 100.5364\n",
      "Epoch 658/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.2678 - val_loss: 94.9491\n",
      "Epoch 659/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.2338 - val_loss: 92.0022\n",
      "Epoch 660/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0576 - val_loss: 96.0572\n",
      "Epoch 661/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7195 - val_loss: 93.1366\n",
      "Epoch 662/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.4424 - val_loss: 106.4356\n",
      "Epoch 663/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5765 - val_loss: 96.7441\n",
      "Epoch 664/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.4544 - val_loss: 93.9624\n",
      "Epoch 665/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0156 - val_loss: 101.8051\n",
      "Epoch 666/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8449 - val_loss: 105.6140\n",
      "Epoch 667/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.8863 - val_loss: 97.1129\n",
      "Epoch 668/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.9485 - val_loss: 91.9207\n",
      "Epoch 669/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0811 - val_loss: 102.2083\n",
      "Epoch 670/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.9964 - val_loss: 101.2986\n",
      "Epoch 671/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2114 - val_loss: 101.7594\n",
      "Epoch 672/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.8141 - val_loss: 87.0001\n",
      "Epoch 673/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.4676 - val_loss: 97.9545\n",
      "Epoch 674/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5859 - val_loss: 104.3500\n",
      "Epoch 675/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.1893 - val_loss: 96.7732\n",
      "Epoch 676/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.3880 - val_loss: 99.4382\n",
      "Epoch 677/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0673 - val_loss: 99.2612\n",
      "Epoch 678/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8843 - val_loss: 96.9869\n",
      "Epoch 679/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8520 - val_loss: 101.2945\n",
      "Epoch 680/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.5858 - val_loss: 92.1228\n",
      "Epoch 681/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7955 - val_loss: 102.4470\n",
      "Epoch 682/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6507 - val_loss: 94.5154\n",
      "Epoch 683/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6086 - val_loss: 96.8607\n",
      "Epoch 684/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.2870 - val_loss: 97.2831\n",
      "Epoch 685/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.8685 - val_loss: 85.9098\n",
      "Epoch 686/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 27.1791 - val_loss: 92.8238\n",
      "Epoch 687/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0003 - val_loss: 94.8545\n",
      "Epoch 688/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0472 - val_loss: 95.6858\n",
      "Epoch 689/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8576 - val_loss: 91.1965\n",
      "Epoch 690/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.4408 - val_loss: 94.8433\n",
      "Epoch 691/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0369 - val_loss: 91.6786\n",
      "Epoch 692/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.4002 - val_loss: 105.9310\n",
      "Epoch 693/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7268 - val_loss: 96.7270\n",
      "Epoch 694/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.6315 - val_loss: 100.2965\n",
      "Epoch 695/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.2706 - val_loss: 91.7542\n",
      "Epoch 696/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7413 - val_loss: 91.6240\n",
      "Epoch 697/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.9094 - val_loss: 92.3156\n",
      "Epoch 698/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7495 - val_loss: 97.5426\n",
      "Epoch 699/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.9285 - val_loss: 93.5702\n",
      "Epoch 700/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.2912 - val_loss: 94.7545\n",
      "Epoch 701/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0817 - val_loss: 92.9466\n",
      "Epoch 702/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.1538 - val_loss: 99.3288\n",
      "Epoch 703/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0765 - val_loss: 88.4426\n",
      "Epoch 704/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5019 - val_loss: 95.3435\n",
      "Epoch 705/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6883 - val_loss: 90.5748\n",
      "Epoch 706/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8675 - val_loss: 89.5992\n",
      "Epoch 707/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.9929 - val_loss: 80.1332\n",
      "Epoch 708/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.8716 - val_loss: 77.6351\n",
      "Epoch 709/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.4123 - val_loss: 84.4257\n",
      "Epoch 710/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.5966 - val_loss: 85.2661\n",
      "Epoch 711/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 36.0790 - val_loss: 77.1733\n",
      "Epoch 712/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.9305 - val_loss: 94.1481\n",
      "Epoch 713/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.1877 - val_loss: 94.2133\n",
      "Epoch 714/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.3353 - val_loss: 83.6267\n",
      "Epoch 715/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.0021 - val_loss: 82.4551\n",
      "Epoch 716/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.1898 - val_loss: 77.9655\n",
      "Epoch 717/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.3892 - val_loss: 77.7771\n",
      "Epoch 718/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.6368 - val_loss: 95.1671\n",
      "Epoch 719/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2437 - val_loss: 91.8009\n",
      "Epoch 720/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6499 - val_loss: 95.9802\n",
      "Epoch 721/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7674 - val_loss: 92.8004\n",
      "Epoch 722/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2814 - val_loss: 76.6743\n",
      "Epoch 723/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.9334 - val_loss: 79.0497\n",
      "Epoch 724/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.9075 - val_loss: 95.4874\n",
      "Epoch 725/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2610 - val_loss: 93.8453\n",
      "Epoch 726/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.9020 - val_loss: 77.6656\n",
      "Epoch 727/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.5825 - val_loss: 77.4120\n",
      "Epoch 728/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.3502 - val_loss: 92.8578\n",
      "Epoch 729/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.8881 - val_loss: 90.2874\n",
      "Epoch 730/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.4221 - val_loss: 101.0124\n",
      "Epoch 731/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.9198 - val_loss: 98.4283\n",
      "Epoch 732/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6593 - val_loss: 100.9405\n",
      "Epoch 733/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.9702 - val_loss: 96.0075\n",
      "Epoch 734/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.3417 - val_loss: 89.9294\n",
      "Epoch 735/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2864 - val_loss: 94.4875\n",
      "Epoch 736/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.3262 - val_loss: 91.6253\n",
      "Epoch 737/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.4126 - val_loss: 103.7649\n",
      "Epoch 738/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6635 - val_loss: 99.5864\n",
      "Epoch 739/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6346 - val_loss: 96.8282\n",
      "Epoch 740/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.4699 - val_loss: 92.3311\n",
      "Epoch 741/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0775 - val_loss: 93.2456\n",
      "Epoch 742/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6227 - val_loss: 78.1335\n",
      "Epoch 743/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5560 - val_loss: 92.1500\n",
      "Epoch 744/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7343 - val_loss: 94.1574\n",
      "Epoch 745/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0179 - val_loss: 95.8154\n",
      "Epoch 746/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2709 - val_loss: 93.3334\n",
      "Epoch 747/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6569 - val_loss: 89.6207\n",
      "Epoch 748/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.1648 - val_loss: 97.3908\n",
      "Epoch 749/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.1146 - val_loss: 91.5638\n",
      "Epoch 750/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5424 - val_loss: 93.9685\n",
      "Epoch 751/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6512 - val_loss: 94.9066\n",
      "Epoch 752/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5001 - val_loss: 89.8566\n",
      "Epoch 753/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.0993 - val_loss: 106.2071\n",
      "Epoch 754/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8869 - val_loss: 86.4689\n",
      "Epoch 755/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8083 - val_loss: 95.6050\n",
      "Epoch 756/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.1790 - val_loss: 90.2761\n",
      "Epoch 757/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.5929 - val_loss: 77.0639\n",
      "Epoch 758/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.0001 - val_loss: 94.7301\n",
      "Epoch 759/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.9741 - val_loss: 102.7761\n",
      "Epoch 760/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.1016 - val_loss: 91.3738\n",
      "Epoch 761/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6354 - val_loss: 91.7766\n",
      "Epoch 762/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2497 - val_loss: 94.1567\n",
      "Epoch 763/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.9725 - val_loss: 89.7291\n",
      "Epoch 764/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8288 - val_loss: 98.5606\n",
      "Epoch 765/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.6239 - val_loss: 95.8540\n",
      "Epoch 766/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8448 - val_loss: 91.7527\n",
      "Epoch 767/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5848 - val_loss: 82.4448\n",
      "Epoch 768/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.9641 - val_loss: 96.9649\n",
      "Epoch 769/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5123 - val_loss: 97.0366\n",
      "Epoch 770/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.3082 - val_loss: 107.0437\n",
      "Epoch 771/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0849 - val_loss: 97.0441\n",
      "Epoch 772/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.9818 - val_loss: 94.4378\n",
      "Epoch 773/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7436 - val_loss: 95.4902\n",
      "Epoch 774/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.8604 - val_loss: 94.4460\n",
      "Epoch 775/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6831 - val_loss: 80.0611\n",
      "Epoch 776/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.9014 - val_loss: 94.1760\n",
      "Epoch 777/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.3165 - val_loss: 91.6580\n",
      "Epoch 778/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.0543 - val_loss: 95.4493\n",
      "Epoch 779/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6333 - val_loss: 94.5953\n",
      "Epoch 780/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.5470 - val_loss: 78.8100\n",
      "Epoch 781/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.8507 - val_loss: 94.1031\n",
      "Epoch 782/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5077 - val_loss: 93.1593\n",
      "Epoch 783/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6040 - val_loss: 92.5841\n",
      "Epoch 784/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.2260 - val_loss: 81.5856\n",
      "Epoch 785/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.3611 - val_loss: 77.2543\n",
      "Epoch 786/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.9509 - val_loss: 79.5919\n",
      "Epoch 787/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.5529 - val_loss: 96.1194\n",
      "Epoch 788/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.3291 - val_loss: 88.7706\n",
      "Epoch 789/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.6745 - val_loss: 91.8569\n",
      "Epoch 790/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.0664 - val_loss: 91.0155\n",
      "Epoch 791/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 27.0234 - val_loss: 94.7241\n",
      "Epoch 792/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.3787 - val_loss: 90.9987\n",
      "Epoch 793/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.7688 - val_loss: 94.6463\n",
      "Epoch 794/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.5042 - val_loss: 89.3067\n",
      "Epoch 795/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.1765 - val_loss: 94.3016\n",
      "Epoch 796/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.0981 - val_loss: 76.1870\n",
      "Epoch 797/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.3271 - val_loss: 79.7009\n",
      "Epoch 798/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2492 - val_loss: 93.8881\n",
      "Epoch 799/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.8357 - val_loss: 80.7716\n",
      "Epoch 800/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.9571 - val_loss: 78.1738\n",
      "Epoch 801/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.7973 - val_loss: 84.4787\n",
      "Epoch 802/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.7688 - val_loss: 77.0976\n",
      "Epoch 803/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 25.3598 - val_loss: 84.3180\n",
      "Epoch 804/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.5052 - val_loss: 83.5642\n",
      "Epoch 805/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.4242 - val_loss: 76.0471\n",
      "Epoch 806/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7121 - val_loss: 84.1178\n",
      "Epoch 807/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.0652 - val_loss: 92.0631\n",
      "Epoch 808/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 26.2067 - val_loss: 91.8451\n",
      "Epoch 809/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 26.7144 - val_loss: 89.2114\n",
      "Epoch 810/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 26.0252 - val_loss: 97.9297\n",
      "Epoch 811/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.3116 - val_loss: 75.9444\n",
      "Epoch 812/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.4384 - val_loss: 75.5262\n",
      "Epoch 813/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.3789 - val_loss: 74.9997\n",
      "Epoch 814/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8779 - val_loss: 75.7547\n",
      "Epoch 815/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9478 - val_loss: 75.2757\n",
      "Epoch 816/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.6957 - val_loss: 87.5695\n",
      "Epoch 817/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9595 - val_loss: 74.9933\n",
      "Epoch 818/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 24.2782 - val_loss: 87.5839\n",
      "Epoch 819/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 24.2325 - val_loss: 81.6851\n",
      "Epoch 820/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.9485 - val_loss: 82.3022\n",
      "Epoch 821/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7059 - val_loss: 75.6332\n",
      "Epoch 822/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.0757 - val_loss: 80.1213\n",
      "Epoch 823/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.3620 - val_loss: 96.0206\n",
      "Epoch 824/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.2984 - val_loss: 96.4296\n",
      "Epoch 825/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7674 - val_loss: 75.6914\n",
      "Epoch 826/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6563 - val_loss: 91.2681\n",
      "Epoch 827/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6047 - val_loss: 80.7007\n",
      "Epoch 828/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.5203 - val_loss: 77.4768\n",
      "Epoch 829/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9496 - val_loss: 79.3708\n",
      "Epoch 830/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5784 - val_loss: 76.0027\n",
      "Epoch 831/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6137 - val_loss: 74.3184\n",
      "Epoch 832/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8363 - val_loss: 77.5170\n",
      "Epoch 833/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.2874 - val_loss: 73.8349\n",
      "Epoch 834/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.0329 - val_loss: 74.7084\n",
      "Epoch 835/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.2854 - val_loss: 84.6906\n",
      "Epoch 836/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7665 - val_loss: 83.8751\n",
      "Epoch 837/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.2063 - val_loss: 76.9800\n",
      "Epoch 838/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7173 - val_loss: 74.9806\n",
      "Epoch 839/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9974 - val_loss: 73.6872\n",
      "Epoch 840/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5482 - val_loss: 73.8760\n",
      "Epoch 841/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.3802 - val_loss: 75.7490\n",
      "Epoch 842/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2818 - val_loss: 74.7146\n",
      "Epoch 843/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6666 - val_loss: 80.6241\n",
      "Epoch 844/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7499 - val_loss: 79.7549\n",
      "Epoch 845/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.3803 - val_loss: 80.0218\n",
      "Epoch 846/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.3751 - val_loss: 73.6088\n",
      "Epoch 847/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9214 - val_loss: 94.0842\n",
      "Epoch 848/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5193 - val_loss: 73.3588\n",
      "Epoch 849/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0151 - val_loss: 74.4943\n",
      "Epoch 850/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6256 - val_loss: 81.4659\n",
      "Epoch 851/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5952 - val_loss: 73.3936\n",
      "Epoch 852/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6400 - val_loss: 73.4794\n",
      "Epoch 853/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0114 - val_loss: 76.3608\n",
      "Epoch 854/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.4592 - val_loss: 80.4196\n",
      "Epoch 855/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.4694 - val_loss: 74.0547\n",
      "Epoch 856/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7464 - val_loss: 73.1782\n",
      "Epoch 857/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2094 - val_loss: 76.2520\n",
      "Epoch 858/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3266 - val_loss: 75.8083\n",
      "Epoch 859/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4961 - val_loss: 76.8921\n",
      "Epoch 860/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8551 - val_loss: 81.9276\n",
      "Epoch 861/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.0337 - val_loss: 73.5001\n",
      "Epoch 862/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6394 - val_loss: 77.4694\n",
      "Epoch 863/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6558 - val_loss: 88.0940\n",
      "Epoch 864/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.1151 - val_loss: 76.4618\n",
      "Epoch 865/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.1522 - val_loss: 79.4625\n",
      "Epoch 866/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3260 - val_loss: 77.0199\n",
      "Epoch 867/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7042 - val_loss: 76.2007\n",
      "Epoch 868/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2032 - val_loss: 72.7610\n",
      "Epoch 869/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7173 - val_loss: 73.8948\n",
      "Epoch 870/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.7730 - val_loss: 76.0925\n",
      "Epoch 871/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3822 - val_loss: 76.0352\n",
      "Epoch 872/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5146 - val_loss: 72.5396\n",
      "Epoch 873/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9682 - val_loss: 76.1259\n",
      "Epoch 874/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8700 - val_loss: 75.5245\n",
      "Epoch 875/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9388 - val_loss: 89.6597\n",
      "Epoch 876/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6902 - val_loss: 86.2227\n",
      "Epoch 877/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8313 - val_loss: 74.9050\n",
      "Epoch 878/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1878 - val_loss: 74.7333\n",
      "Epoch 879/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8915 - val_loss: 73.0905\n",
      "Epoch 880/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3636 - val_loss: 73.1502\n",
      "Epoch 881/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8437 - val_loss: 77.5350\n",
      "Epoch 882/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4827 - val_loss: 77.4005\n",
      "Epoch 883/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.5188 - val_loss: 83.4373\n",
      "Epoch 884/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6183 - val_loss: 72.9560\n",
      "Epoch 885/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1313 - val_loss: 73.3698\n",
      "Epoch 886/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6723 - val_loss: 76.1411\n",
      "Epoch 887/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3635 - val_loss: 81.1288\n",
      "Epoch 888/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2980 - val_loss: 80.6713\n",
      "Epoch 889/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1986 - val_loss: 72.7342\n",
      "Epoch 890/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2817 - val_loss: 80.6994\n",
      "Epoch 891/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0900 - val_loss: 72.9547\n",
      "Epoch 892/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.0207 - val_loss: 80.6751\n",
      "Epoch 893/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1662 - val_loss: 74.3819\n",
      "Epoch 894/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8860 - val_loss: 79.3017\n",
      "Epoch 895/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1043 - val_loss: 78.6895\n",
      "Epoch 896/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6874 - val_loss: 74.0067\n",
      "Epoch 897/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5073 - val_loss: 78.9543\n",
      "Epoch 898/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9516 - val_loss: 78.0567\n",
      "Epoch 899/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.1406 - val_loss: 71.7654\n",
      "Epoch 900/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9323 - val_loss: 80.5714\n",
      "Epoch 901/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4482 - val_loss: 73.1739\n",
      "Epoch 902/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0878 - val_loss: 72.9249\n",
      "Epoch 903/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.5944 - val_loss: 76.4523\n",
      "Epoch 904/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.6886 - val_loss: 72.2909\n",
      "Epoch 905/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8329 - val_loss: 76.6768\n",
      "Epoch 906/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.3986 - val_loss: 73.4458\n",
      "Epoch 907/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 25.4441 - val_loss: 71.9482\n",
      "Epoch 908/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.5462 - val_loss: 72.9481\n",
      "Epoch 909/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7657 - val_loss: 72.1145\n",
      "Epoch 910/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5273 - val_loss: 77.5309\n",
      "Epoch 911/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.4441 - val_loss: 85.2012\n",
      "Epoch 912/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.0759 - val_loss: 71.6667\n",
      "Epoch 913/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2803 - val_loss: 72.9518\n",
      "Epoch 914/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5824 - val_loss: 73.8987\n",
      "Epoch 915/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9180 - val_loss: 75.7610\n",
      "Epoch 916/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9761 - val_loss: 72.3426\n",
      "Epoch 917/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4841 - val_loss: 77.0526\n",
      "Epoch 918/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9676 - val_loss: 73.9998\n",
      "Epoch 919/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.1808 - val_loss: 84.2798\n",
      "Epoch 920/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9878 - val_loss: 74.4705\n",
      "Epoch 921/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9137 - val_loss: 72.9968\n",
      "Epoch 922/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8260 - val_loss: 74.1292\n",
      "Epoch 923/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.1785 - val_loss: 79.3415\n",
      "Epoch 924/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9863 - val_loss: 74.1628\n",
      "Epoch 925/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.0279 - val_loss: 73.3622\n",
      "Epoch 926/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8224 - val_loss: 73.5224\n",
      "Epoch 927/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9324 - val_loss: 76.0315\n",
      "Epoch 928/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7512 - val_loss: 79.9676\n",
      "Epoch 929/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.2049 - val_loss: 73.0311\n",
      "Epoch 930/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1101 - val_loss: 85.7874\n",
      "Epoch 931/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4083 - val_loss: 78.9605\n",
      "Epoch 932/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7524 - val_loss: 71.4136\n",
      "Epoch 933/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4791 - val_loss: 79.1719\n",
      "Epoch 934/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4863 - val_loss: 80.3241\n",
      "Epoch 935/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5534 - val_loss: 74.6825\n",
      "Epoch 936/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3378 - val_loss: 72.1055\n",
      "Epoch 937/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9315 - val_loss: 73.1801\n",
      "Epoch 938/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0854 - val_loss: 77.0323\n",
      "Epoch 939/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.5201 - val_loss: 92.9482\n",
      "Epoch 940/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7041 - val_loss: 81.1248\n",
      "Epoch 941/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1812 - val_loss: 76.7596\n",
      "Epoch 942/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9025 - val_loss: 85.0463\n",
      "Epoch 943/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7032 - val_loss: 78.8508\n",
      "Epoch 944/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5957 - val_loss: 72.9132\n",
      "Epoch 945/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5012 - val_loss: 72.8924\n",
      "Epoch 946/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9812 - val_loss: 74.0100\n",
      "Epoch 947/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4160 - val_loss: 76.6174\n",
      "Epoch 948/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6480 - val_loss: 74.5069\n",
      "Epoch 949/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9190 - val_loss: 73.7728\n",
      "Epoch 950/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1480 - val_loss: 71.6621\n",
      "Epoch 951/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8437 - val_loss: 82.7918\n",
      "Epoch 952/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4623 - val_loss: 74.9856\n",
      "Epoch 953/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9007 - val_loss: 74.0102\n",
      "Epoch 954/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.4062 - val_loss: 72.5662\n",
      "Epoch 955/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6553 - val_loss: 72.6203\n",
      "Epoch 956/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2420 - val_loss: 71.9870\n",
      "Epoch 957/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2685 - val_loss: 72.9554\n",
      "Epoch 958/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2556 - val_loss: 75.7570\n",
      "Epoch 959/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9865 - val_loss: 83.1311\n",
      "Epoch 960/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1688 - val_loss: 71.1800\n",
      "Epoch 961/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8874 - val_loss: 75.0482\n",
      "Epoch 962/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5110 - val_loss: 90.6057\n",
      "Epoch 963/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6633 - val_loss: 88.6334\n",
      "Epoch 964/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2143 - val_loss: 71.5693\n",
      "Epoch 965/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8454 - val_loss: 77.4483\n",
      "Epoch 966/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7870 - val_loss: 71.2039\n",
      "Epoch 967/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9582 - val_loss: 92.2897\n",
      "Epoch 968/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3000 - val_loss: 71.0627\n",
      "Epoch 969/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7321 - val_loss: 71.3652\n",
      "Epoch 970/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6148 - val_loss: 72.2189\n",
      "Epoch 971/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6541 - val_loss: 73.7594\n",
      "Epoch 972/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8056 - val_loss: 73.1040\n",
      "Epoch 973/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2555 - val_loss: 74.3561\n",
      "Epoch 974/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0433 - val_loss: 82.9435\n",
      "Epoch 975/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4438 - val_loss: 71.2813\n",
      "Epoch 976/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2873 - val_loss: 72.7878\n",
      "Epoch 977/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1018 - val_loss: 87.5442\n",
      "Epoch 978/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1389 - val_loss: 77.1419\n",
      "Epoch 979/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3063 - val_loss: 73.7093\n",
      "Epoch 980/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7149 - val_loss: 73.3724\n",
      "Epoch 981/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7306 - val_loss: 85.8068\n",
      "Epoch 982/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2831 - val_loss: 72.3752\n",
      "Epoch 983/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5183 - val_loss: 71.7659\n",
      "Epoch 984/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6003 - val_loss: 71.2915\n",
      "Epoch 985/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5383 - val_loss: 72.6452\n",
      "Epoch 986/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4033 - val_loss: 75.6264\n",
      "Epoch 987/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2135 - val_loss: 74.5116\n",
      "Epoch 988/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9160 - val_loss: 78.2403\n",
      "Epoch 989/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8566 - val_loss: 83.9169\n",
      "Epoch 990/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6217 - val_loss: 81.6371\n",
      "Epoch 991/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6604 - val_loss: 71.1962\n",
      "Epoch 992/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1597 - val_loss: 74.7298\n",
      "Epoch 993/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9464 - val_loss: 74.8490\n",
      "Epoch 994/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1485 - val_loss: 73.2384\n",
      "Epoch 995/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4080 - val_loss: 70.7288\n",
      "Epoch 996/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0309 - val_loss: 71.2003\n",
      "Epoch 997/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7016 - val_loss: 70.4775\n",
      "Epoch 998/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1998 - val_loss: 71.7605\n",
      "Epoch 999/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6096 - val_loss: 71.3417\n",
      "Epoch 1000/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7226 - val_loss: 70.5244\n",
      "Epoch 1001/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1301 - val_loss: 73.5128\n",
      "Epoch 1002/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5734 - val_loss: 71.4799\n",
      "Epoch 1003/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1101 - val_loss: 74.3171\n",
      "Epoch 1004/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3987 - val_loss: 71.1621\n",
      "Epoch 1005/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7076 - val_loss: 70.4460\n",
      "Epoch 1006/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9947 - val_loss: 70.7782\n",
      "Epoch 1007/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7757 - val_loss: 70.5843\n",
      "Epoch 1008/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1095 - val_loss: 72.6943\n",
      "Epoch 1009/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1469 - val_loss: 74.8000\n",
      "Epoch 1010/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1390 - val_loss: 71.7897\n",
      "Epoch 1011/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2194 - val_loss: 76.6738\n",
      "Epoch 1012/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8323 - val_loss: 72.3449\n",
      "Epoch 1013/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7989 - val_loss: 70.8264\n",
      "Epoch 1014/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7760 - val_loss: 73.7805\n",
      "Epoch 1015/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6200 - val_loss: 92.1325\n",
      "Epoch 1016/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0923 - val_loss: 74.4865\n",
      "Epoch 1017/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2599 - val_loss: 71.6436\n",
      "Epoch 1018/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5000 - val_loss: 85.9059\n",
      "Epoch 1019/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0977 - val_loss: 73.1972\n",
      "Epoch 1020/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2396 - val_loss: 70.9205\n",
      "Epoch 1021/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8799 - val_loss: 70.7991\n",
      "Epoch 1022/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.3485 - val_loss: 101.1761\n",
      "Epoch 1023/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 45.0381 - val_loss: 80.7203\n",
      "Epoch 1024/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 28.0937 - val_loss: 87.2567\n",
      "Epoch 1025/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0221 - val_loss: 75.4992\n",
      "Epoch 1026/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4790 - val_loss: 70.1987\n",
      "Epoch 1027/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 21.9492 - val_loss: 71.6712\n",
      "Epoch 1028/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4153 - val_loss: 71.2294\n",
      "Epoch 1029/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2385 - val_loss: 71.3909\n",
      "Epoch 1030/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 22.1445 - val_loss: 73.6296\n",
      "Epoch 1031/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8647 - val_loss: 69.6897\n",
      "Epoch 1032/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0581 - val_loss: 70.3549\n",
      "Epoch 1033/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7138 - val_loss: 73.0748\n",
      "Epoch 1034/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5918 - val_loss: 79.4693\n",
      "Epoch 1035/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5665 - val_loss: 70.7518\n",
      "Epoch 1036/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0687 - val_loss: 71.3068\n",
      "Epoch 1037/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8049 - val_loss: 71.0620\n",
      "Epoch 1038/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6653 - val_loss: 70.2343\n",
      "Epoch 1039/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6460 - val_loss: 74.6340\n",
      "Epoch 1040/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1841 - val_loss: 70.7791\n",
      "Epoch 1041/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9252 - val_loss: 69.2332\n",
      "Epoch 1042/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7905 - val_loss: 73.7223\n",
      "Epoch 1043/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3216 - val_loss: 72.3397\n",
      "Epoch 1044/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1612 - val_loss: 69.1608\n",
      "Epoch 1045/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7385 - val_loss: 70.5910\n",
      "Epoch 1046/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5073 - val_loss: 69.7543\n",
      "Epoch 1047/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7300 - val_loss: 69.4414\n",
      "Epoch 1048/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9888 - val_loss: 73.2178\n",
      "Epoch 1049/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5142 - val_loss: 69.0905\n",
      "Epoch 1050/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1115 - val_loss: 74.0163\n",
      "Epoch 1051/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1613 - val_loss: 70.9160\n",
      "Epoch 1052/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9503 - val_loss: 71.1416\n",
      "Epoch 1053/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 22.6583 - val_loss: 69.5806\n",
      "Epoch 1054/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2292 - val_loss: 77.1705\n",
      "Epoch 1055/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3599 - val_loss: 71.0374\n",
      "Epoch 1056/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6285 - val_loss: 70.7064\n",
      "Epoch 1057/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9205 - val_loss: 77.1125\n",
      "Epoch 1058/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2229 - val_loss: 74.6542\n",
      "Epoch 1059/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1541 - val_loss: 71.4221\n",
      "Epoch 1060/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8937 - val_loss: 70.5705\n",
      "Epoch 1061/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2102 - val_loss: 70.2318\n",
      "Epoch 1062/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6256 - val_loss: 69.4267\n",
      "Epoch 1063/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9379 - val_loss: 82.5155\n",
      "Epoch 1064/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1075 - val_loss: 70.1025\n",
      "Epoch 1065/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9527 - val_loss: 69.6275\n",
      "Epoch 1066/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3624 - val_loss: 84.2635\n",
      "Epoch 1067/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0719 - val_loss: 75.3384\n",
      "Epoch 1068/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1711 - val_loss: 69.4753\n",
      "Epoch 1069/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5083 - val_loss: 69.0544\n",
      "Epoch 1070/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6535 - val_loss: 78.3406\n",
      "Epoch 1071/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8640 - val_loss: 82.7809\n",
      "Epoch 1072/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0996 - val_loss: 77.9163\n",
      "Epoch 1073/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1601 - val_loss: 69.3459\n",
      "Epoch 1074/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8735 - val_loss: 77.9616\n",
      "Epoch 1075/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7227 - val_loss: 83.7275\n",
      "Epoch 1076/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4634 - val_loss: 72.3110\n",
      "Epoch 1077/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1443 - val_loss: 70.3972\n",
      "Epoch 1078/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5629 - val_loss: 69.3042\n",
      "Epoch 1079/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9725 - val_loss: 74.1096\n",
      "Epoch 1080/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9710 - val_loss: 71.3793\n",
      "Epoch 1081/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4488 - val_loss: 78.0938\n",
      "Epoch 1082/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4840 - val_loss: 69.5081\n",
      "Epoch 1083/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3739 - val_loss: 69.8582\n",
      "Epoch 1084/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9707 - val_loss: 69.9596\n",
      "Epoch 1085/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4007 - val_loss: 69.0295\n",
      "Epoch 1086/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7129 - val_loss: 84.3582\n",
      "Epoch 1087/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5779 - val_loss: 69.5977\n",
      "Epoch 1088/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4252 - val_loss: 70.1103\n",
      "Epoch 1089/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.5519 - val_loss: 69.4923\n",
      "Epoch 1090/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.2458 - val_loss: 69.0035\n",
      "Epoch 1091/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9579 - val_loss: 78.1360\n",
      "Epoch 1092/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2623 - val_loss: 71.1365\n",
      "Epoch 1093/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9173 - val_loss: 75.7682\n",
      "Epoch 1094/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.8426 - val_loss: 72.2791\n",
      "Epoch 1095/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 24.4918 - val_loss: 69.5325\n",
      "Epoch 1096/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0160 - val_loss: 73.8806\n",
      "Epoch 1097/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6214 - val_loss: 70.1363\n",
      "Epoch 1098/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0522 - val_loss: 69.9795\n",
      "Epoch 1099/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2871 - val_loss: 70.1057\n",
      "Epoch 1100/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6235 - val_loss: 70.3142\n",
      "Epoch 1101/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9440 - val_loss: 77.2453\n",
      "Epoch 1102/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3113 - val_loss: 70.7020\n",
      "Epoch 1103/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1504 - val_loss: 72.8651\n",
      "Epoch 1104/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0865 - val_loss: 70.4240\n",
      "Epoch 1105/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8606 - val_loss: 69.9732\n",
      "Epoch 1106/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7557 - val_loss: 77.7732\n",
      "Epoch 1107/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6738 - val_loss: 68.6945\n",
      "Epoch 1108/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3069 - val_loss: 69.4374\n",
      "Epoch 1109/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2269 - val_loss: 69.9701\n",
      "Epoch 1110/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5229 - val_loss: 69.0773\n",
      "Epoch 1111/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2215 - val_loss: 70.3264\n",
      "Epoch 1112/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8648 - val_loss: 72.4048\n",
      "Epoch 1113/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4370 - val_loss: 70.1782\n",
      "Epoch 1114/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9440 - val_loss: 72.8566\n",
      "Epoch 1115/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2490 - val_loss: 73.8523\n",
      "Epoch 1116/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3760 - val_loss: 70.6963\n",
      "Epoch 1117/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6837 - val_loss: 72.5557\n",
      "Epoch 1118/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6446 - val_loss: 69.4743\n",
      "Epoch 1119/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2754 - val_loss: 71.2513\n",
      "Epoch 1120/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5192 - val_loss: 70.8643\n",
      "Epoch 1121/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0565 - val_loss: 69.0434\n",
      "Epoch 1122/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4721 - val_loss: 80.1178\n",
      "Epoch 1123/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7197 - val_loss: 69.8057\n",
      "Epoch 1124/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1480 - val_loss: 77.6280\n",
      "Epoch 1125/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8202 - val_loss: 79.6129\n",
      "Epoch 1126/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5904 - val_loss: 69.0335\n",
      "Epoch 1127/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8643 - val_loss: 73.3661\n",
      "Epoch 1128/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0987 - val_loss: 69.3758\n",
      "Epoch 1129/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9606 - val_loss: 70.4874\n",
      "Epoch 1130/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4965 - val_loss: 75.0930\n",
      "Epoch 1131/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4727 - val_loss: 70.8271\n",
      "Epoch 1132/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3032 - val_loss: 71.1623\n",
      "Epoch 1133/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.4346 - val_loss: 79.4613\n",
      "Epoch 1134/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5824 - val_loss: 69.8150\n",
      "Epoch 1135/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7739 - val_loss: 70.1281\n",
      "Epoch 1136/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8588 - val_loss: 69.2469\n",
      "Epoch 1137/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9857 - val_loss: 68.9998\n",
      "Epoch 1138/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3087 - val_loss: 71.0917\n",
      "Epoch 1139/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8451 - val_loss: 71.8621\n",
      "Epoch 1140/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5862 - val_loss: 71.0357\n",
      "Epoch 1141/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6945 - val_loss: 72.3997\n",
      "Epoch 1142/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4972 - val_loss: 70.7374\n",
      "Epoch 1143/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4048 - val_loss: 79.3618\n",
      "Epoch 1144/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3704 - val_loss: 73.5904\n",
      "Epoch 1145/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 22.3309 - val_loss: 71.6956\n",
      "Epoch 1146/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 8ms/step - loss: 22.5605 - val_loss: 71.0263\n",
      "Epoch 1147/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2785 - val_loss: 70.5328\n",
      "Epoch 1148/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9379 - val_loss: 68.6789\n",
      "Epoch 1149/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4585 - val_loss: 71.9356\n",
      "Epoch 1150/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4823 - val_loss: 73.4467\n",
      "Epoch 1151/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3583 - val_loss: 69.9809\n",
      "Epoch 1152/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9576 - val_loss: 78.0508\n",
      "Epoch 1153/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 22.7796 - val_loss: 76.7137\n",
      "Epoch 1154/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7218 - val_loss: 70.0978\n",
      "Epoch 1155/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6859 - val_loss: 79.1799\n",
      "Epoch 1156/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0227 - val_loss: 72.0145\n",
      "Epoch 1157/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3468 - val_loss: 78.3521\n",
      "Epoch 1158/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1124 - val_loss: 68.7271\n",
      "Epoch 1159/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3236 - val_loss: 70.1678\n",
      "Epoch 1160/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8759 - val_loss: 69.4092\n",
      "Epoch 1161/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1217 - val_loss: 71.5140\n",
      "Epoch 1162/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7910 - val_loss: 70.4268\n",
      "Epoch 1163/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8485 - val_loss: 80.8582\n",
      "Epoch 1164/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3700 - val_loss: 69.7482\n",
      "Epoch 1165/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6433 - val_loss: 70.5720\n",
      "Epoch 1166/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1039 - val_loss: 69.3564\n",
      "Epoch 1167/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6280 - val_loss: 83.7335\n",
      "Epoch 1168/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7911 - val_loss: 73.5967\n",
      "Epoch 1169/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8391 - val_loss: 76.1554\n",
      "Epoch 1170/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.7336 - val_loss: 73.2333\n",
      "Epoch 1171/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5119 - val_loss: 73.2162\n",
      "Epoch 1172/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0680 - val_loss: 73.4417\n",
      "Epoch 1173/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3959 - val_loss: 70.5770\n",
      "Epoch 1174/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5522 - val_loss: 70.6081\n",
      "Epoch 1175/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.6833 - val_loss: 69.8889\n",
      "Epoch 1176/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1672 - val_loss: 78.6838\n",
      "Epoch 1177/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6525 - val_loss: 70.9683\n",
      "Epoch 1178/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5929 - val_loss: 106.8934\n",
      "Epoch 1179/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6620 - val_loss: 81.9561\n",
      "Epoch 1180/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7215 - val_loss: 74.4735\n",
      "Epoch 1181/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5814 - val_loss: 79.9665\n",
      "Epoch 1182/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4780 - val_loss: 70.7009\n",
      "Epoch 1183/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2074 - val_loss: 92.7133\n",
      "Epoch 1184/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3490 - val_loss: 71.7880\n",
      "Epoch 1185/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1947 - val_loss: 70.7384\n",
      "Epoch 1186/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6622 - val_loss: 76.5994\n",
      "Epoch 1187/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9991 - val_loss: 85.8973\n",
      "Epoch 1188/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5114 - val_loss: 75.4270\n",
      "Epoch 1189/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0656 - val_loss: 72.2935\n",
      "Epoch 1190/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2299 - val_loss: 70.9816\n",
      "Epoch 1191/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6672 - val_loss: 74.0630\n",
      "Epoch 1192/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4072 - val_loss: 71.9553\n",
      "Epoch 1193/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6183 - val_loss: 74.3238\n",
      "Epoch 1194/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0941 - val_loss: 73.3237\n",
      "Epoch 1195/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.5745 - val_loss: 70.1981\n",
      "Epoch 1196/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2674 - val_loss: 69.1555\n",
      "Epoch 1197/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8697 - val_loss: 77.4314\n",
      "Epoch 1198/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1280 - val_loss: 69.1596\n",
      "Epoch 1199/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6146 - val_loss: 76.1808\n",
      "Epoch 1200/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5275 - val_loss: 68.9792\n",
      "Epoch 1201/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3754 - val_loss: 69.4316\n",
      "Epoch 1202/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0414 - val_loss: 76.5247\n",
      "Epoch 1203/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7311 - val_loss: 69.1959\n",
      "Epoch 1204/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3325 - val_loss: 76.6677\n",
      "Epoch 1205/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0213 - val_loss: 79.5044\n",
      "Epoch 1206/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4945 - val_loss: 88.0797\n",
      "Epoch 1207/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.3662 - val_loss: 73.0571\n",
      "Epoch 1208/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4181 - val_loss: 69.5868\n",
      "Epoch 1209/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4592 - val_loss: 68.7481\n",
      "Epoch 1210/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2250 - val_loss: 70.1666\n",
      "Epoch 1211/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9152 - val_loss: 69.8966\n",
      "Epoch 1212/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 84.9442 - val_loss: 74.7526\n",
      "Epoch 1213/2000\n",
      "152/152 [==============================] - 1s 10ms/step - loss: 22.6951 - val_loss: 69.0774\n",
      "Epoch 1214/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 22.4986 - val_loss: 71.7200\n",
      "Epoch 1215/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7263 - val_loss: 81.3488\n",
      "Epoch 1216/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2747 - val_loss: 73.7690\n",
      "Epoch 1217/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1057 - val_loss: 70.0199\n",
      "Epoch 1218/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8116 - val_loss: 69.4823\n",
      "Epoch 1219/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4222 - val_loss: 70.1401\n",
      "Epoch 1220/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6549 - val_loss: 78.5914\n",
      "Epoch 1221/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8282 - val_loss: 70.4447\n",
      "Epoch 1222/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2099 - val_loss: 71.5744\n",
      "Epoch 1223/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 22.2333 - val_loss: 75.7580\n",
      "Epoch 1224/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7017 - val_loss: 76.9386\n",
      "Epoch 1225/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4236 - val_loss: 72.7625\n",
      "Epoch 1226/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3859 - val_loss: 69.7445\n",
      "Epoch 1227/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0944 - val_loss: 72.9347\n",
      "Epoch 1228/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5437 - val_loss: 69.2009\n",
      "Epoch 1229/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8111 - val_loss: 72.2698\n",
      "Epoch 1230/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8724 - val_loss: 69.5908\n",
      "Epoch 1231/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3204 - val_loss: 69.9732\n",
      "Epoch 1232/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2092 - val_loss: 69.6846\n",
      "Epoch 1233/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6590 - val_loss: 69.1221\n",
      "Epoch 1234/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2047 - val_loss: 68.9087\n",
      "Epoch 1235/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4653 - val_loss: 70.6935\n",
      "Epoch 1236/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4150 - val_loss: 72.1559\n",
      "Epoch 1237/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4343 - val_loss: 74.2336\n",
      "Epoch 1238/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4949 - val_loss: 77.9021\n",
      "Epoch 1239/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4294 - val_loss: 76.5068\n",
      "Epoch 1240/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5433 - val_loss: 69.0592\n",
      "Epoch 1241/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2188 - val_loss: 69.5148\n",
      "Epoch 1242/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5010 - val_loss: 69.0482\n",
      "Epoch 1243/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4357 - val_loss: 72.7501\n",
      "Epoch 1244/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2169 - val_loss: 70.7793\n",
      "Epoch 1245/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0935 - val_loss: 69.8770\n",
      "Epoch 1246/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1508 - val_loss: 79.2938\n",
      "Epoch 1247/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8735 - val_loss: 73.8001\n",
      "Epoch 1248/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3878 - val_loss: 74.7396\n",
      "Epoch 1249/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4807 - val_loss: 69.2020\n",
      "Epoch 1250/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8327 - val_loss: 74.3066\n",
      "Epoch 1251/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7064 - val_loss: 70.1343\n",
      "Epoch 1252/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5217 - val_loss: 70.5298\n",
      "Epoch 1253/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5845 - val_loss: 69.4811\n",
      "Epoch 1254/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3040 - val_loss: 73.9469\n",
      "Epoch 1255/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9089 - val_loss: 71.1786\n",
      "Epoch 1256/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5125 - val_loss: 74.1508\n",
      "Epoch 1257/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1473 - val_loss: 70.3934\n",
      "Epoch 1258/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8003 - val_loss: 69.8849\n",
      "Epoch 1259/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5738 - val_loss: 70.3291\n",
      "Epoch 1260/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7645 - val_loss: 76.9274\n",
      "Epoch 1261/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5856 - val_loss: 74.9493\n",
      "Epoch 1262/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7210 - val_loss: 72.0088\n",
      "Epoch 1263/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1870 - val_loss: 69.1478\n",
      "Epoch 1264/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8201 - val_loss: 81.5056\n",
      "Epoch 1265/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8393 - val_loss: 72.5677\n",
      "Epoch 1266/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3112 - val_loss: 69.1434\n",
      "Epoch 1267/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5939 - val_loss: 72.6447\n",
      "Epoch 1268/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5536 - val_loss: 71.8869\n",
      "Epoch 1269/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4795 - val_loss: 71.1097\n",
      "Epoch 1270/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6313 - val_loss: 76.4916\n",
      "Epoch 1271/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0245 - val_loss: 70.0093\n",
      "Epoch 1272/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6384 - val_loss: 69.1391\n",
      "Epoch 1273/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1192 - val_loss: 68.9307\n",
      "Epoch 1274/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1893 - val_loss: 83.9084\n",
      "Epoch 1275/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5554 - val_loss: 71.3257\n",
      "Epoch 1276/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9112 - val_loss: 70.9489\n",
      "Epoch 1277/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8529 - val_loss: 69.4073\n",
      "Epoch 1278/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8612 - val_loss: 74.4487\n",
      "Epoch 1279/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2725 - val_loss: 68.9399\n",
      "Epoch 1280/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1420 - val_loss: 75.7402\n",
      "Epoch 1281/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6947 - val_loss: 71.8170\n",
      "Epoch 1282/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1545 - val_loss: 70.4580\n",
      "Epoch 1283/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4191 - val_loss: 76.3616\n",
      "Epoch 1284/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9133 - val_loss: 71.8632\n",
      "Epoch 1285/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2112 - val_loss: 80.9342\n",
      "Epoch 1286/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9489 - val_loss: 69.8589\n",
      "Epoch 1287/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8599 - val_loss: 68.9424\n",
      "Epoch 1288/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6636 - val_loss: 71.9794\n",
      "Epoch 1289/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6249 - val_loss: 72.8341\n",
      "Epoch 1290/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4145 - val_loss: 68.9403\n",
      "Epoch 1291/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7513 - val_loss: 76.5053\n",
      "Epoch 1292/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0207 - val_loss: 70.9862\n",
      "Epoch 1293/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7999 - val_loss: 69.6971\n",
      "Epoch 1294/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5798 - val_loss: 79.2324\n",
      "Epoch 1295/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3928 - val_loss: 73.4427\n",
      "Epoch 1296/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2690 - val_loss: 69.1255\n",
      "Epoch 1297/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7565 - val_loss: 87.6385\n",
      "Epoch 1298/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7392 - val_loss: 68.8046\n",
      "Epoch 1299/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3997 - val_loss: 84.5851\n",
      "Epoch 1300/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3029 - val_loss: 75.0306\n",
      "Epoch 1301/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9131 - val_loss: 70.7655\n",
      "Epoch 1302/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3380 - val_loss: 69.8980\n",
      "Epoch 1303/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3090 - val_loss: 71.1108\n",
      "Epoch 1304/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0576 - val_loss: 83.4089\n",
      "Epoch 1305/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6027 - val_loss: 68.9491\n",
      "Epoch 1306/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0934 - val_loss: 68.7342\n",
      "Epoch 1307/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6248 - val_loss: 71.6759\n",
      "Epoch 1308/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9929 - val_loss: 72.0165\n",
      "Epoch 1309/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1620 - val_loss: 70.2863\n",
      "Epoch 1310/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5134 - val_loss: 69.4418\n",
      "Epoch 1311/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3170 - val_loss: 72.9847\n",
      "Epoch 1312/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0317 - val_loss: 76.2726\n",
      "Epoch 1313/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9447 - val_loss: 76.8576\n",
      "Epoch 1314/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9262 - val_loss: 71.5525\n",
      "Epoch 1315/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2053 - val_loss: 75.2027\n",
      "Epoch 1316/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.8763 - val_loss: 85.5695\n",
      "Epoch 1317/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4289 - val_loss: 89.7828\n",
      "Epoch 1318/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9225 - val_loss: 69.5304\n",
      "Epoch 1319/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2166 - val_loss: 69.5236\n",
      "Epoch 1320/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7298 - val_loss: 78.7273\n",
      "Epoch 1321/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8715 - val_loss: 77.9026\n",
      "Epoch 1322/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3236 - val_loss: 72.3932\n",
      "Epoch 1323/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9474 - val_loss: 68.8182\n",
      "Epoch 1324/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1277 - val_loss: 70.5323\n",
      "Epoch 1325/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9930 - val_loss: 68.6819\n",
      "Epoch 1326/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2956 - val_loss: 76.0447\n",
      "Epoch 1327/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1275 - val_loss: 72.1445\n",
      "Epoch 1328/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7925 - val_loss: 68.5735\n",
      "Epoch 1329/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3881 - val_loss: 72.1024\n",
      "Epoch 1330/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0169 - val_loss: 70.1858\n",
      "Epoch 1331/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 31.4326 - val_loss: 72.0799\n",
      "Epoch 1332/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 33.3711 - val_loss: 74.0358\n",
      "Epoch 1333/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.9036 - val_loss: 73.8989\n",
      "Epoch 1334/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 159.4203 - val_loss: 100.1920\n",
      "Epoch 1335/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 29.7107 - val_loss: 91.7545\n",
      "Epoch 1336/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 58.0269 - val_loss: 84.6404\n",
      "Epoch 1337/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8437 - val_loss: 76.9102\n",
      "Epoch 1338/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3576 - val_loss: 75.5527\n",
      "Epoch 1339/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2632 - val_loss: 70.3973\n",
      "Epoch 1340/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5878 - val_loss: 71.9151\n",
      "Epoch 1341/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0021 - val_loss: 70.2888\n",
      "Epoch 1342/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8340 - val_loss: 76.2737\n",
      "Epoch 1343/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1204 - val_loss: 70.6008\n",
      "Epoch 1344/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1107 - val_loss: 73.6335\n",
      "Epoch 1345/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8824 - val_loss: 68.6701\n",
      "Epoch 1346/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5384 - val_loss: 69.7840\n",
      "Epoch 1347/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9179 - val_loss: 73.8801\n",
      "Epoch 1348/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2436 - val_loss: 69.1955\n",
      "Epoch 1349/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3371 - val_loss: 79.0623\n",
      "Epoch 1350/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3370 - val_loss: 80.1227\n",
      "Epoch 1351/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4261 - val_loss: 69.9209\n",
      "Epoch 1352/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4520 - val_loss: 71.6842\n",
      "Epoch 1353/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9553 - val_loss: 72.4575\n",
      "Epoch 1354/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 47.3464 - val_loss: 72.2551\n",
      "Epoch 1355/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3328 - val_loss: 71.0794\n",
      "Epoch 1356/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3737 - val_loss: 76.8641\n",
      "Epoch 1357/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3362 - val_loss: 72.8441\n",
      "Epoch 1358/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9287 - val_loss: 70.2552\n",
      "Epoch 1359/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7544 - val_loss: 87.0081\n",
      "Epoch 1360/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6803 - val_loss: 69.5296\n",
      "Epoch 1361/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4349 - val_loss: 73.7070\n",
      "Epoch 1362/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9144 - val_loss: 71.4480\n",
      "Epoch 1363/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3047 - val_loss: 69.4297\n",
      "Epoch 1364/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6423 - val_loss: 71.4413\n",
      "Epoch 1365/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7853 - val_loss: 69.9059\n",
      "Epoch 1366/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5475 - val_loss: 69.7074\n",
      "Epoch 1367/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3273 - val_loss: 69.4093\n",
      "Epoch 1368/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3739 - val_loss: 68.5587\n",
      "Epoch 1369/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7548 - val_loss: 68.7931\n",
      "Epoch 1370/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1933 - val_loss: 71.3742\n",
      "Epoch 1371/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9352 - val_loss: 69.7059\n",
      "Epoch 1372/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9819 - val_loss: 68.9921\n",
      "Epoch 1373/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6925 - val_loss: 70.3057\n",
      "Epoch 1374/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1370 - val_loss: 69.0463\n",
      "Epoch 1375/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2365 - val_loss: 69.2010\n",
      "Epoch 1376/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4619 - val_loss: 69.6271\n",
      "Epoch 1377/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5264 - val_loss: 70.9759\n",
      "Epoch 1378/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2115 - val_loss: 72.3135\n",
      "Epoch 1379/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4812 - val_loss: 69.0271\n",
      "Epoch 1380/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2175 - val_loss: 82.4014\n",
      "Epoch 1381/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4115 - val_loss: 69.4301\n",
      "Epoch 1382/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2826 - val_loss: 80.8449\n",
      "Epoch 1383/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7101 - val_loss: 72.8942\n",
      "Epoch 1384/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5963 - val_loss: 81.5454\n",
      "Epoch 1385/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3586 - val_loss: 69.2344\n",
      "Epoch 1386/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3405 - val_loss: 68.7288\n",
      "Epoch 1387/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9292 - val_loss: 71.4869\n",
      "Epoch 1388/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0097 - val_loss: 69.9208\n",
      "Epoch 1389/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7493 - val_loss: 74.2950\n",
      "Epoch 1390/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1095 - val_loss: 74.3292\n",
      "Epoch 1391/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8501 - val_loss: 70.0115\n",
      "Epoch 1392/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6870 - val_loss: 77.8582\n",
      "Epoch 1393/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7087 - val_loss: 83.2360\n",
      "Epoch 1394/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4177 - val_loss: 69.2757\n",
      "Epoch 1395/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0078 - val_loss: 70.4556\n",
      "Epoch 1396/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6998 - val_loss: 68.7316\n",
      "Epoch 1397/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0189 - val_loss: 77.5274\n",
      "Epoch 1398/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3082 - val_loss: 69.9406\n",
      "Epoch 1399/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8792 - val_loss: 72.6605\n",
      "Epoch 1400/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2065 - val_loss: 73.4246\n",
      "Epoch 1401/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5814 - val_loss: 70.8520\n",
      "Epoch 1402/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9949 - val_loss: 75.6211\n",
      "Epoch 1403/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7408 - val_loss: 71.9021\n",
      "Epoch 1404/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9411 - val_loss: 69.4734\n",
      "Epoch 1405/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5839 - val_loss: 69.7243\n",
      "Epoch 1406/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0452 - val_loss: 70.4088\n",
      "Epoch 1407/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2531 - val_loss: 71.9264\n",
      "Epoch 1408/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2436 - val_loss: 68.9183\n",
      "Epoch 1409/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9330 - val_loss: 71.3993\n",
      "Epoch 1410/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4370 - val_loss: 69.7723\n",
      "Epoch 1411/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6886 - val_loss: 73.0982\n",
      "Epoch 1412/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6538 - val_loss: 78.7905\n",
      "Epoch 1413/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1922 - val_loss: 68.4630\n",
      "Epoch 1414/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1700 - val_loss: 69.9133\n",
      "Epoch 1415/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4596 - val_loss: 68.8904\n",
      "Epoch 1416/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8602 - val_loss: 73.1078\n",
      "Epoch 1417/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1396 - val_loss: 70.4473\n",
      "Epoch 1418/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6820 - val_loss: 70.6308\n",
      "Epoch 1419/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1602 - val_loss: 75.8737\n",
      "Epoch 1420/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2115 - val_loss: 80.1964\n",
      "Epoch 1421/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2326 - val_loss: 72.0749\n",
      "Epoch 1422/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9429 - val_loss: 70.7805\n",
      "Epoch 1423/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8825 - val_loss: 68.7287\n",
      "Epoch 1424/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6173 - val_loss: 72.9979\n",
      "Epoch 1425/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9874 - val_loss: 69.1603\n",
      "Epoch 1426/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4973 - val_loss: 73.7715\n",
      "Epoch 1427/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3589 - val_loss: 70.3821\n",
      "Epoch 1428/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4834 - val_loss: 69.2082\n",
      "Epoch 1429/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0662 - val_loss: 69.8862\n",
      "Epoch 1430/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3770 - val_loss: 69.2576\n",
      "Epoch 1431/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6630 - val_loss: 68.5682\n",
      "Epoch 1432/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4434 - val_loss: 74.7011\n",
      "Epoch 1433/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6004 - val_loss: 68.4666\n",
      "Epoch 1434/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1762 - val_loss: 78.3948\n",
      "Epoch 1435/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9116 - val_loss: 69.6471\n",
      "Epoch 1436/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0363 - val_loss: 72.2354\n",
      "Epoch 1437/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4702 - val_loss: 71.8999\n",
      "Epoch 1438/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2379 - val_loss: 68.6218\n",
      "Epoch 1439/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7986 - val_loss: 69.0037\n",
      "Epoch 1440/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8199 - val_loss: 79.2706\n",
      "Epoch 1441/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1599 - val_loss: 70.2093\n",
      "Epoch 1442/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4855 - val_loss: 68.7976\n",
      "Epoch 1443/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9368 - val_loss: 68.7166\n",
      "Epoch 1444/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1889 - val_loss: 69.8866\n",
      "Epoch 1445/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9334 - val_loss: 73.1825\n",
      "Epoch 1446/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3027 - val_loss: 72.8030\n",
      "Epoch 1447/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9160 - val_loss: 70.2491\n",
      "Epoch 1448/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8704 - val_loss: 70.6237\n",
      "Epoch 1449/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0840 - val_loss: 72.7130\n",
      "Epoch 1450/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1129 - val_loss: 73.8056\n",
      "Epoch 1451/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0113 - val_loss: 76.0541\n",
      "Epoch 1452/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8856 - val_loss: 70.2683\n",
      "Epoch 1453/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9789 - val_loss: 77.9213\n",
      "Epoch 1454/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1083 - val_loss: 73.0699\n",
      "Epoch 1455/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8492 - val_loss: 68.7739\n",
      "Epoch 1456/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7543 - val_loss: 72.2906\n",
      "Epoch 1457/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3295 - val_loss: 70.5401\n",
      "Epoch 1458/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1736 - val_loss: 69.4386\n",
      "Epoch 1459/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3063 - val_loss: 76.1760\n",
      "Epoch 1460/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0532 - val_loss: 68.4935\n",
      "Epoch 1461/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7971 - val_loss: 73.1695\n",
      "Epoch 1462/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6837 - val_loss: 70.7603\n",
      "Epoch 1463/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7485 - val_loss: 68.8098\n",
      "Epoch 1464/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6116 - val_loss: 80.7644\n",
      "Epoch 1465/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5079 - val_loss: 77.3135\n",
      "Epoch 1466/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1662 - val_loss: 83.0478\n",
      "Epoch 1467/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2319 - val_loss: 72.1899\n",
      "Epoch 1468/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7910 - val_loss: 77.5763\n",
      "Epoch 1469/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8808 - val_loss: 68.9771\n",
      "Epoch 1470/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9909 - val_loss: 68.4353\n",
      "Epoch 1471/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7007 - val_loss: 72.0893\n",
      "Epoch 1472/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2349 - val_loss: 68.4762\n",
      "Epoch 1473/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4029 - val_loss: 71.0451\n",
      "Epoch 1474/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7584 - val_loss: 82.5923\n",
      "Epoch 1475/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9980 - val_loss: 70.7806\n",
      "Epoch 1476/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8811 - val_loss: 71.2218\n",
      "Epoch 1477/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6098 - val_loss: 76.0795\n",
      "Epoch 1478/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8850 - val_loss: 74.1448\n",
      "Epoch 1479/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0473 - val_loss: 73.2141\n",
      "Epoch 1480/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3458 - val_loss: 68.7635\n",
      "Epoch 1481/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4823 - val_loss: 79.3038\n",
      "Epoch 1482/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4774 - val_loss: 78.7117\n",
      "Epoch 1483/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7633 - val_loss: 70.4263\n",
      "Epoch 1484/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9471 - val_loss: 68.7302\n",
      "Epoch 1485/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4456 - val_loss: 69.7989\n",
      "Epoch 1486/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1539 - val_loss: 69.0782\n",
      "Epoch 1487/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6101 - val_loss: 69.5974\n",
      "Epoch 1488/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5403 - val_loss: 71.9188\n",
      "Epoch 1489/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3321 - val_loss: 78.2677\n",
      "Epoch 1490/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6822 - val_loss: 69.5802\n",
      "Epoch 1491/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2310 - val_loss: 69.4394\n",
      "Epoch 1492/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9041 - val_loss: 68.7908\n",
      "Epoch 1493/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1133 - val_loss: 76.4552\n",
      "Epoch 1494/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6971 - val_loss: 79.5944\n",
      "Epoch 1495/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9990 - val_loss: 73.2709\n",
      "Epoch 1496/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4059 - val_loss: 68.7579\n",
      "Epoch 1497/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0571 - val_loss: 69.9725\n",
      "Epoch 1498/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6040 - val_loss: 74.1276\n",
      "Epoch 1499/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3040 - val_loss: 71.1588\n",
      "Epoch 1500/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1109 - val_loss: 69.7995\n",
      "Epoch 1501/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2232 - val_loss: 71.6723\n",
      "Epoch 1502/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3901 - val_loss: 70.5412\n",
      "Epoch 1503/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8737 - val_loss: 69.0904\n",
      "Epoch 1504/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7529 - val_loss: 79.4128\n",
      "Epoch 1505/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7571 - val_loss: 76.3798\n",
      "Epoch 1506/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2461 - val_loss: 69.2484\n",
      "Epoch 1507/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4900 - val_loss: 72.8933\n",
      "Epoch 1508/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1544 - val_loss: 70.2210\n",
      "Epoch 1509/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5596 - val_loss: 74.2126\n",
      "Epoch 1510/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2830 - val_loss: 69.2231\n",
      "Epoch 1511/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6318 - val_loss: 74.8023\n",
      "Epoch 1512/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9662 - val_loss: 68.8814\n",
      "Epoch 1513/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9231 - val_loss: 68.6846\n",
      "Epoch 1514/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9274 - val_loss: 68.7964\n",
      "Epoch 1515/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1521 - val_loss: 70.5480\n",
      "Epoch 1516/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8066 - val_loss: 72.2240\n",
      "Epoch 1517/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1810 - val_loss: 77.8373\n",
      "Epoch 1518/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3507 - val_loss: 71.4683\n",
      "Epoch 1519/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5631 - val_loss: 70.6648\n",
      "Epoch 1520/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4463 - val_loss: 68.4662\n",
      "Epoch 1521/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9844 - val_loss: 84.5179\n",
      "Epoch 1522/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0744 - val_loss: 70.4691\n",
      "Epoch 1523/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.7086 - val_loss: 87.4188\n",
      "Epoch 1524/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5235 - val_loss: 70.7848\n",
      "Epoch 1525/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8298 - val_loss: 77.3790\n",
      "Epoch 1526/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0209 - val_loss: 71.4267\n",
      "Epoch 1527/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7283 - val_loss: 75.1115\n",
      "Epoch 1528/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0000 - val_loss: 68.6661\n",
      "Epoch 1529/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4826 - val_loss: 69.0110\n",
      "Epoch 1530/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6265 - val_loss: 69.7167\n",
      "Epoch 1531/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7724 - val_loss: 68.6834\n",
      "Epoch 1532/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3305 - val_loss: 75.8730\n",
      "Epoch 1533/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7523 - val_loss: 68.9472\n",
      "Epoch 1534/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9903 - val_loss: 73.4921\n",
      "Epoch 1535/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1168 - val_loss: 79.1347\n",
      "Epoch 1536/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.0090 - val_loss: 70.0937\n",
      "Epoch 1537/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6414 - val_loss: 68.9215\n",
      "Epoch 1538/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8313 - val_loss: 73.3105\n",
      "Epoch 1539/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0985 - val_loss: 70.8070\n",
      "Epoch 1540/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4230 - val_loss: 70.6578\n",
      "Epoch 1541/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0212 - val_loss: 81.8832\n",
      "Epoch 1542/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2438 - val_loss: 72.4932\n",
      "Epoch 1543/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0372 - val_loss: 74.6657\n",
      "Epoch 1544/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5200 - val_loss: 70.0948\n",
      "Epoch 1545/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4417 - val_loss: 73.3049\n",
      "Epoch 1546/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5776 - val_loss: 70.0946\n",
      "Epoch 1547/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1697 - val_loss: 74.9765\n",
      "Epoch 1548/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5498 - val_loss: 68.6360\n",
      "Epoch 1549/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8822 - val_loss: 68.6570\n",
      "Epoch 1550/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0733 - val_loss: 69.1130\n",
      "Epoch 1551/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5499 - val_loss: 74.8361\n",
      "Epoch 1552/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9988 - val_loss: 68.3342\n",
      "Epoch 1553/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8482 - val_loss: 69.0415\n",
      "Epoch 1554/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8399 - val_loss: 72.2688\n",
      "Epoch 1555/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3075 - val_loss: 70.3804\n",
      "Epoch 1556/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9103 - val_loss: 77.2578\n",
      "Epoch 1557/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8835 - val_loss: 75.0868\n",
      "Epoch 1558/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8689 - val_loss: 70.7931\n",
      "Epoch 1559/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2838 - val_loss: 83.2341\n",
      "Epoch 1560/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0775 - val_loss: 68.6562\n",
      "Epoch 1561/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0701 - val_loss: 69.0352\n",
      "Epoch 1562/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5051 - val_loss: 68.7046\n",
      "Epoch 1563/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1093 - val_loss: 69.6563\n",
      "Epoch 1564/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0186 - val_loss: 74.0399\n",
      "Epoch 1565/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6578 - val_loss: 70.1019\n",
      "Epoch 1566/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6045 - val_loss: 71.7613\n",
      "Epoch 1567/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9555 - val_loss: 68.3609\n",
      "Epoch 1568/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8948 - val_loss: 85.7200\n",
      "Epoch 1569/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1130 - val_loss: 70.1992\n",
      "Epoch 1570/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8192 - val_loss: 75.9686\n",
      "Epoch 1571/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1634 - val_loss: 69.2575\n",
      "Epoch 1572/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1160 - val_loss: 70.4459\n",
      "Epoch 1573/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1992 - val_loss: 70.1693\n",
      "Epoch 1574/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1961 - val_loss: 69.0454\n",
      "Epoch 1575/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5209 - val_loss: 68.8947\n",
      "Epoch 1576/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7242 - val_loss: 70.8391\n",
      "Epoch 1577/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6684 - val_loss: 69.9288\n",
      "Epoch 1578/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7795 - val_loss: 69.0993\n",
      "Epoch 1579/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6614 - val_loss: 71.1911\n",
      "Epoch 1580/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9535 - val_loss: 74.7246\n",
      "Epoch 1581/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5183 - val_loss: 68.5518\n",
      "Epoch 1582/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6552 - val_loss: 69.1441\n",
      "Epoch 1583/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8831 - val_loss: 69.9572\n",
      "Epoch 1584/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6294 - val_loss: 69.8972\n",
      "Epoch 1585/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8451 - val_loss: 71.3591\n",
      "Epoch 1586/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.1718 - val_loss: 68.5457\n",
      "Epoch 1587/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2072 - val_loss: 72.4598\n",
      "Epoch 1588/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8828 - val_loss: 68.8116\n",
      "Epoch 1589/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9389 - val_loss: 68.8502\n",
      "Epoch 1590/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7398 - val_loss: 68.7530\n",
      "Epoch 1591/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2350 - val_loss: 68.2765\n",
      "Epoch 1592/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0433 - val_loss: 68.6804\n",
      "Epoch 1593/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3300 - val_loss: 68.9310\n",
      "Epoch 1594/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8030 - val_loss: 74.3084\n",
      "Epoch 1595/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0038 - val_loss: 68.5895\n",
      "Epoch 1596/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8854 - val_loss: 74.6970\n",
      "Epoch 1597/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8824 - val_loss: 79.6153\n",
      "Epoch 1598/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1731 - val_loss: 74.3889\n",
      "Epoch 1599/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9976 - val_loss: 68.5993\n",
      "Epoch 1600/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2442 - val_loss: 77.0211\n",
      "Epoch 1601/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9008 - val_loss: 70.1656\n",
      "Epoch 1602/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0405 - val_loss: 68.2426\n",
      "Epoch 1603/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3707 - val_loss: 71.5895\n",
      "Epoch 1604/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3290 - val_loss: 75.3958\n",
      "Epoch 1605/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5733 - val_loss: 70.4835\n",
      "Epoch 1606/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9971 - val_loss: 68.3069\n",
      "Epoch 1607/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.7309 - val_loss: 68.5303\n",
      "Epoch 1608/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6540 - val_loss: 72.7745\n",
      "Epoch 1609/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6792 - val_loss: 70.0023\n",
      "Epoch 1610/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9067 - val_loss: 68.8477\n",
      "Epoch 1611/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6106 - val_loss: 69.5349\n",
      "Epoch 1612/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6380 - val_loss: 69.1517\n",
      "Epoch 1613/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9886 - val_loss: 86.3188\n",
      "Epoch 1614/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2869 - val_loss: 69.3816\n",
      "Epoch 1615/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8794 - val_loss: 75.1352\n",
      "Epoch 1616/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4922 - val_loss: 69.6031\n",
      "Epoch 1617/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6418 - val_loss: 70.3888\n",
      "Epoch 1618/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3133 - val_loss: 68.9062\n",
      "Epoch 1619/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4523 - val_loss: 69.2808\n",
      "Epoch 1620/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6883 - val_loss: 78.9542\n",
      "Epoch 1621/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0059 - val_loss: 72.8553\n",
      "Epoch 1622/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3381 - val_loss: 68.5968\n",
      "Epoch 1623/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7086 - val_loss: 78.6085\n",
      "Epoch 1624/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0142 - val_loss: 68.4418\n",
      "Epoch 1625/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6458 - val_loss: 70.7718\n",
      "Epoch 1626/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5456 - val_loss: 71.1823\n",
      "Epoch 1627/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6491 - val_loss: 72.6148\n",
      "Epoch 1628/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8034 - val_loss: 75.8717\n",
      "Epoch 1629/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8742 - val_loss: 69.1153\n",
      "Epoch 1630/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8321 - val_loss: 75.0614\n",
      "Epoch 1631/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3233 - val_loss: 68.6877\n",
      "Epoch 1632/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6901 - val_loss: 68.8411\n",
      "Epoch 1633/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7112 - val_loss: 80.3941\n",
      "Epoch 1634/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2708 - val_loss: 71.2032\n",
      "Epoch 1635/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5999 - val_loss: 68.9108\n",
      "Epoch 1636/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5011 - val_loss: 72.0041\n",
      "Epoch 1637/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5496 - val_loss: 68.7933\n",
      "Epoch 1638/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2121 - val_loss: 70.5238\n",
      "Epoch 1639/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9395 - val_loss: 68.9582\n",
      "Epoch 1640/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9326 - val_loss: 68.2297\n",
      "Epoch 1641/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7415 - val_loss: 69.9253\n",
      "Epoch 1642/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5984 - val_loss: 76.9303\n",
      "Epoch 1643/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3284 - val_loss: 68.2006\n",
      "Epoch 1644/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9207 - val_loss: 68.7098\n",
      "Epoch 1645/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0410 - val_loss: 69.0978\n",
      "Epoch 1646/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3737 - val_loss: 69.6590\n",
      "Epoch 1647/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2547 - val_loss: 70.3134\n",
      "Epoch 1648/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3157 - val_loss: 74.2452\n",
      "Epoch 1649/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0543 - val_loss: 68.7117\n",
      "Epoch 1650/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0196 - val_loss: 68.4336\n",
      "Epoch 1651/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1679 - val_loss: 70.7279\n",
      "Epoch 1652/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2241 - val_loss: 68.3949\n",
      "Epoch 1653/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9125 - val_loss: 68.1292\n",
      "Epoch 1654/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4058 - val_loss: 78.2095\n",
      "Epoch 1655/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8395 - val_loss: 71.2010\n",
      "Epoch 1656/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7640 - val_loss: 73.8506\n",
      "Epoch 1657/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7969 - val_loss: 75.1475\n",
      "Epoch 1658/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5219 - val_loss: 83.8303\n",
      "Epoch 1659/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3927 - val_loss: 70.4965\n",
      "Epoch 1660/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0795 - val_loss: 76.3970\n",
      "Epoch 1661/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6945 - val_loss: 88.3721\n",
      "Epoch 1662/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8123 - val_loss: 72.5273\n",
      "Epoch 1663/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1700 - val_loss: 68.7483\n",
      "Epoch 1664/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6200 - val_loss: 68.6961\n",
      "Epoch 1665/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1849 - val_loss: 68.6068\n",
      "Epoch 1666/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8104 - val_loss: 68.1787\n",
      "Epoch 1667/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0954 - val_loss: 70.4968\n",
      "Epoch 1668/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8966 - val_loss: 69.1067\n",
      "Epoch 1669/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.0382 - val_loss: 70.2107\n",
      "Epoch 1670/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2326 - val_loss: 78.2430\n",
      "Epoch 1671/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4250 - val_loss: 74.7625\n",
      "Epoch 1672/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5800 - val_loss: 70.3377\n",
      "Epoch 1673/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0411 - val_loss: 70.6467\n",
      "Epoch 1674/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5337 - val_loss: 93.7384\n",
      "Epoch 1675/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1267 - val_loss: 80.5703\n",
      "Epoch 1676/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4432 - val_loss: 77.2806\n",
      "Epoch 1677/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3763 - val_loss: 73.1157\n",
      "Epoch 1678/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3098 - val_loss: 71.0046\n",
      "Epoch 1679/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6865 - val_loss: 69.3456\n",
      "Epoch 1680/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5455 - val_loss: 81.0213\n",
      "Epoch 1681/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1020 - val_loss: 68.3469\n",
      "Epoch 1682/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7234 - val_loss: 68.1162\n",
      "Epoch 1683/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7961 - val_loss: 69.6291\n",
      "Epoch 1684/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8533 - val_loss: 73.1355\n",
      "Epoch 1685/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9089 - val_loss: 70.1271\n",
      "Epoch 1686/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4453 - val_loss: 72.3078\n",
      "Epoch 1687/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8379 - val_loss: 70.9776\n",
      "Epoch 1688/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6766 - val_loss: 74.9790\n",
      "Epoch 1689/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2450 - val_loss: 76.7722\n",
      "Epoch 1690/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2685 - val_loss: 68.5491\n",
      "Epoch 1691/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6537 - val_loss: 68.9197\n",
      "Epoch 1692/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9490 - val_loss: 73.7430\n",
      "Epoch 1693/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0649 - val_loss: 72.3789\n",
      "Epoch 1694/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0842 - val_loss: 69.5772\n",
      "Epoch 1695/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5899 - val_loss: 81.1886\n",
      "Epoch 1696/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9730 - val_loss: 68.9936\n",
      "Epoch 1697/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5703 - val_loss: 69.7675\n",
      "Epoch 1698/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3876 - val_loss: 69.7637\n",
      "Epoch 1699/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4838 - val_loss: 68.3045\n",
      "Epoch 1700/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6979 - val_loss: 84.6638\n",
      "Epoch 1701/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0277 - val_loss: 69.2726\n",
      "Epoch 1702/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8757 - val_loss: 81.3465\n",
      "Epoch 1703/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4827 - val_loss: 72.4023\n",
      "Epoch 1704/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6438 - val_loss: 80.1215\n",
      "Epoch 1705/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2394 - val_loss: 70.9218\n",
      "Epoch 1706/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.5151 - val_loss: 68.2331\n",
      "Epoch 1707/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5911 - val_loss: 80.1827\n",
      "Epoch 1708/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3869 - val_loss: 74.7996\n",
      "Epoch 1709/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6615 - val_loss: 71.5492\n",
      "Epoch 1710/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7551 - val_loss: 68.5452\n",
      "Epoch 1711/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3501 - val_loss: 73.3995\n",
      "Epoch 1712/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5483 - val_loss: 72.1534\n",
      "Epoch 1713/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1755 - val_loss: 69.4916\n",
      "Epoch 1714/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6383 - val_loss: 68.9762\n",
      "Epoch 1715/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9430 - val_loss: 75.2495\n",
      "Epoch 1716/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4542 - val_loss: 76.6897\n",
      "Epoch 1717/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 21.8588 - val_loss: 70.2261\n",
      "Epoch 1718/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6948 - val_loss: 71.1114\n",
      "Epoch 1719/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8515 - val_loss: 71.5216\n",
      "Epoch 1720/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9985 - val_loss: 71.1941\n",
      "Epoch 1721/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1860 - val_loss: 68.3702\n",
      "Epoch 1722/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8943 - val_loss: 70.9912\n",
      "Epoch 1723/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6213 - val_loss: 77.1626\n",
      "Epoch 1724/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6742 - val_loss: 70.5530\n",
      "Epoch 1725/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2927 - val_loss: 69.6973\n",
      "Epoch 1726/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6342 - val_loss: 68.4803\n",
      "Epoch 1727/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3824 - val_loss: 70.8082\n",
      "Epoch 1728/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1920 - val_loss: 72.3212\n",
      "Epoch 1729/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4472 - val_loss: 70.6564\n",
      "Epoch 1730/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4843 - val_loss: 73.3141\n",
      "Epoch 1731/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4066 - val_loss: 70.1729\n",
      "Epoch 1732/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1894 - val_loss: 68.5384\n",
      "Epoch 1733/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1345 - val_loss: 70.6866\n",
      "Epoch 1734/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9776 - val_loss: 70.1631\n",
      "Epoch 1735/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0735 - val_loss: 68.1213\n",
      "Epoch 1736/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5478 - val_loss: 89.9363\n",
      "Epoch 1737/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6471 - val_loss: 69.6902\n",
      "Epoch 1738/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9629 - val_loss: 69.5061\n",
      "Epoch 1739/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6233 - val_loss: 70.9203\n",
      "Epoch 1740/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8105 - val_loss: 69.1519\n",
      "Epoch 1741/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4237 - val_loss: 80.0950\n",
      "Epoch 1742/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0281 - val_loss: 71.9788\n",
      "Epoch 1743/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5907 - val_loss: 75.4573\n",
      "Epoch 1744/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3217 - val_loss: 68.1372\n",
      "Epoch 1745/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5647 - val_loss: 74.6740\n",
      "Epoch 1746/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9961 - val_loss: 70.2471\n",
      "Epoch 1747/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6288 - val_loss: 83.7837\n",
      "Epoch 1748/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9468 - val_loss: 68.5834\n",
      "Epoch 1749/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4277 - val_loss: 68.3558\n",
      "Epoch 1750/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3116 - val_loss: 72.5939\n",
      "Epoch 1751/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0978 - val_loss: 69.4112\n",
      "Epoch 1752/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8447 - val_loss: 74.4790\n",
      "Epoch 1753/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2202 - val_loss: 72.7474\n",
      "Epoch 1754/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9282 - val_loss: 68.6657\n",
      "Epoch 1755/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5977 - val_loss: 68.2737\n",
      "Epoch 1756/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0829 - val_loss: 76.7271\n",
      "Epoch 1757/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4962 - val_loss: 69.7959\n",
      "Epoch 1758/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7004 - val_loss: 68.7373\n",
      "Epoch 1759/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5426 - val_loss: 70.7774\n",
      "Epoch 1760/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0162 - val_loss: 75.4132\n",
      "Epoch 1761/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4638 - val_loss: 71.0053\n",
      "Epoch 1762/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9593 - val_loss: 68.2969\n",
      "Epoch 1763/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6816 - val_loss: 68.9052\n",
      "Epoch 1764/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9181 - val_loss: 79.8759\n",
      "Epoch 1765/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9361 - val_loss: 74.7801\n",
      "Epoch 1766/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7175 - val_loss: 69.3674\n",
      "Epoch 1767/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7130 - val_loss: 70.7460\n",
      "Epoch 1768/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5221 - val_loss: 77.6798\n",
      "Epoch 1769/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7370 - val_loss: 69.1361\n",
      "Epoch 1770/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8527 - val_loss: 68.8115\n",
      "Epoch 1771/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4212 - val_loss: 73.7336\n",
      "Epoch 1772/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8058 - val_loss: 76.4087\n",
      "Epoch 1773/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1432 - val_loss: 70.4837\n",
      "Epoch 1774/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8811 - val_loss: 68.1785\n",
      "Epoch 1775/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0816 - val_loss: 68.6976\n",
      "Epoch 1776/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8948 - val_loss: 74.5459\n",
      "Epoch 1777/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 21.8651 - val_loss: 71.2334\n",
      "Epoch 1778/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 21.3125 - val_loss: 68.6189\n",
      "Epoch 1779/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2390 - val_loss: 70.6964\n",
      "Epoch 1780/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9324 - val_loss: 68.2937\n",
      "Epoch 1781/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2830 - val_loss: 70.3270\n",
      "Epoch 1782/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6786 - val_loss: 70.1921\n",
      "Epoch 1783/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8356 - val_loss: 76.8733\n",
      "Epoch 1784/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6805 - val_loss: 70.2044\n",
      "Epoch 1785/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5076 - val_loss: 69.6873\n",
      "Epoch 1786/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9132 - val_loss: 68.5458\n",
      "Epoch 1787/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9298 - val_loss: 72.0436\n",
      "Epoch 1788/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6982 - val_loss: 70.8509\n",
      "Epoch 1789/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7600 - val_loss: 68.2911\n",
      "Epoch 1790/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9603 - val_loss: 73.9625\n",
      "Epoch 1791/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7730 - val_loss: 68.1736\n",
      "Epoch 1792/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8519 - val_loss: 69.7410\n",
      "Epoch 1793/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1375 - val_loss: 79.8364\n",
      "Epoch 1794/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7730 - val_loss: 72.8453\n",
      "Epoch 1795/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2905 - val_loss: 74.3491\n",
      "Epoch 1796/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5138 - val_loss: 69.9176\n",
      "Epoch 1797/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9284 - val_loss: 68.2123\n",
      "Epoch 1798/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8707 - val_loss: 83.5142\n",
      "Epoch 1799/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2829 - val_loss: 69.5538\n",
      "Epoch 1800/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6560 - val_loss: 68.9211\n",
      "Epoch 1801/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9501 - val_loss: 73.2532\n",
      "Epoch 1802/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2964 - val_loss: 72.5094\n",
      "Epoch 1803/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6589 - val_loss: 68.5393\n",
      "Epoch 1804/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4344 - val_loss: 76.0281\n",
      "Epoch 1805/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4312 - val_loss: 69.6763\n",
      "Epoch 1806/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8462 - val_loss: 71.3104\n",
      "Epoch 1807/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5887 - val_loss: 68.5411\n",
      "Epoch 1808/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3796 - val_loss: 68.6697\n",
      "Epoch 1809/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5595 - val_loss: 69.6716\n",
      "Epoch 1810/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9782 - val_loss: 68.1978\n",
      "Epoch 1811/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3152 - val_loss: 68.5471\n",
      "Epoch 1812/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9214 - val_loss: 76.5784\n",
      "Epoch 1813/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5831 - val_loss: 69.5336\n",
      "Epoch 1814/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7347 - val_loss: 68.7865\n",
      "Epoch 1815/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8174 - val_loss: 68.4252\n",
      "Epoch 1816/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5206 - val_loss: 70.7005\n",
      "Epoch 1817/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7277 - val_loss: 68.5270\n",
      "Epoch 1818/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6118 - val_loss: 70.7312\n",
      "Epoch 1819/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1699 - val_loss: 69.7861\n",
      "Epoch 1820/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6090 - val_loss: 68.2566\n",
      "Epoch 1821/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6557 - val_loss: 68.3160\n",
      "Epoch 1822/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1444 - val_loss: 71.2790\n",
      "Epoch 1823/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5968 - val_loss: 74.0956\n",
      "Epoch 1824/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6266 - val_loss: 69.3375\n",
      "Epoch 1825/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 22.3606 - val_loss: 69.6881\n",
      "Epoch 1826/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8899 - val_loss: 68.8100\n",
      "Epoch 1827/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7028 - val_loss: 70.1238\n",
      "Epoch 1828/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5494 - val_loss: 68.9726\n",
      "Epoch 1829/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5574 - val_loss: 73.6483\n",
      "Epoch 1830/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2360 - val_loss: 68.1054\n",
      "Epoch 1831/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5238 - val_loss: 69.7378\n",
      "Epoch 1832/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9012 - val_loss: 68.5762\n",
      "Epoch 1833/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5891 - val_loss: 68.5888\n",
      "Epoch 1834/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 21.4736 - val_loss: 68.1229\n",
      "Epoch 1835/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8680 - val_loss: 88.0302\n",
      "Epoch 1836/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 22.1849 - val_loss: 69.2836\n",
      "Epoch 1837/2000\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 22.4181 - val_loss: 73.9375\n",
      "Epoch 1838/2000\n",
      "152/152 [==============================] - 1s 9ms/step - loss: 21.1098 - val_loss: 69.2687\n",
      "Epoch 1839/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 21.6215 - val_loss: 68.8630\n",
      "Epoch 1840/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1696 - val_loss: 68.2977\n",
      "Epoch 1841/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5625 - val_loss: 69.1862\n",
      "Epoch 1842/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 23.2720 - val_loss: 74.7927\n",
      "Epoch 1843/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9658 - val_loss: 79.8806\n",
      "Epoch 1844/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1148 - val_loss: 72.6075\n",
      "Epoch 1845/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8728 - val_loss: 71.6090\n",
      "Epoch 1846/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 21.6211 - val_loss: 71.0486\n",
      "Epoch 1847/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4624 - val_loss: 72.6890\n",
      "Epoch 1848/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4941 - val_loss: 71.5749\n",
      "Epoch 1849/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5560 - val_loss: 68.6992\n",
      "Epoch 1850/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5857 - val_loss: 69.0782\n",
      "Epoch 1851/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7526 - val_loss: 68.2572\n",
      "Epoch 1852/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5966 - val_loss: 68.2382\n",
      "Epoch 1853/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3728 - val_loss: 76.0014\n",
      "Epoch 1854/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8507 - val_loss: 69.2600\n",
      "Epoch 1855/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5905 - val_loss: 72.2353\n",
      "Epoch 1856/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2727 - val_loss: 79.1974\n",
      "Epoch 1857/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0721 - val_loss: 76.6094\n",
      "Epoch 1858/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4703 - val_loss: 68.4680\n",
      "Epoch 1859/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5359 - val_loss: 69.2810\n",
      "Epoch 1860/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1962 - val_loss: 69.0052\n",
      "Epoch 1861/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7542 - val_loss: 78.1414\n",
      "Epoch 1862/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5918 - val_loss: 69.4704\n",
      "Epoch 1863/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7544 - val_loss: 73.1417\n",
      "Epoch 1864/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6909 - val_loss: 68.8449\n",
      "Epoch 1865/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9465 - val_loss: 69.6924\n",
      "Epoch 1866/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9366 - val_loss: 73.9400\n",
      "Epoch 1867/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5947 - val_loss: 69.6845\n",
      "Epoch 1868/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7947 - val_loss: 69.8998\n",
      "Epoch 1869/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5111 - val_loss: 70.7968\n",
      "Epoch 1870/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7158 - val_loss: 69.3050\n",
      "Epoch 1871/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7280 - val_loss: 71.5165\n",
      "Epoch 1872/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3800 - val_loss: 71.9756\n",
      "Epoch 1873/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8600 - val_loss: 68.5784\n",
      "Epoch 1874/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2868 - val_loss: 70.1193\n",
      "Epoch 1875/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1979 - val_loss: 67.9555\n",
      "Epoch 1876/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0073 - val_loss: 73.3357\n",
      "Epoch 1877/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2720 - val_loss: 70.6750\n",
      "Epoch 1878/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7735 - val_loss: 69.0244\n",
      "Epoch 1879/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4050 - val_loss: 77.1429\n",
      "Epoch 1880/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1280 - val_loss: 68.7042\n",
      "Epoch 1881/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7358 - val_loss: 70.0842\n",
      "Epoch 1882/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5869 - val_loss: 69.5347\n",
      "Epoch 1883/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5012 - val_loss: 68.6464\n",
      "Epoch 1884/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8014 - val_loss: 69.7000\n",
      "Epoch 1885/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.6960 - val_loss: 68.3309\n",
      "Epoch 1886/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3149 - val_loss: 74.5319\n",
      "Epoch 1887/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3271 - val_loss: 68.3147\n",
      "Epoch 1888/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3535 - val_loss: 71.3190\n",
      "Epoch 1889/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4884 - val_loss: 68.0777\n",
      "Epoch 1890/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.3722 - val_loss: 68.9628\n",
      "Epoch 1891/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4643 - val_loss: 84.0694\n",
      "Epoch 1892/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3589 - val_loss: 68.5184\n",
      "Epoch 1893/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5195 - val_loss: 69.0449\n",
      "Epoch 1894/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3852 - val_loss: 77.7138\n",
      "Epoch 1895/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.2592 - val_loss: 70.2605\n",
      "Epoch 1896/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5643 - val_loss: 82.2744\n",
      "Epoch 1897/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0763 - val_loss: 68.7296\n",
      "Epoch 1898/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3436 - val_loss: 74.8761\n",
      "Epoch 1899/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3821 - val_loss: 69.1716\n",
      "Epoch 1900/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.9376 - val_loss: 69.1868\n",
      "Epoch 1901/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7600 - val_loss: 71.1164\n",
      "Epoch 1902/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5828 - val_loss: 69.0436\n",
      "Epoch 1903/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6144 - val_loss: 72.4472\n",
      "Epoch 1904/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6482 - val_loss: 69.3965\n",
      "Epoch 1905/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3333 - val_loss: 70.7064\n",
      "Epoch 1906/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6101 - val_loss: 68.4302\n",
      "Epoch 1907/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9438 - val_loss: 82.8269\n",
      "Epoch 1908/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1180 - val_loss: 72.6077\n",
      "Epoch 1909/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1479 - val_loss: 68.7882\n",
      "Epoch 1910/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4873 - val_loss: 71.7861\n",
      "Epoch 1911/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3539 - val_loss: 68.2760\n",
      "Epoch 1912/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6228 - val_loss: 68.9324\n",
      "Epoch 1913/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5410 - val_loss: 75.1315\n",
      "Epoch 1914/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0738 - val_loss: 71.5068\n",
      "Epoch 1915/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5992 - val_loss: 70.8440\n",
      "Epoch 1916/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7761 - val_loss: 77.7849\n",
      "Epoch 1917/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0156 - val_loss: 68.4405\n",
      "Epoch 1918/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1776 - val_loss: 69.2904\n",
      "Epoch 1919/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7009 - val_loss: 71.9194\n",
      "Epoch 1920/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9461 - val_loss: 68.9125\n",
      "Epoch 1921/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8703 - val_loss: 71.2654\n",
      "Epoch 1922/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5850 - val_loss: 70.9619\n",
      "Epoch 1923/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5089 - val_loss: 75.0620\n",
      "Epoch 1924/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4199 - val_loss: 70.2136\n",
      "Epoch 1925/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2246 - val_loss: 68.8890\n",
      "Epoch 1926/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5681 - val_loss: 71.1899\n",
      "Epoch 1927/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3382 - val_loss: 70.1726\n",
      "Epoch 1928/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4919 - val_loss: 74.9747\n",
      "Epoch 1929/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6640 - val_loss: 85.2154\n",
      "Epoch 1930/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4284 - val_loss: 68.0548\n",
      "Epoch 1931/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0805 - val_loss: 73.5864\n",
      "Epoch 1932/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5615 - val_loss: 73.1222\n",
      "Epoch 1933/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6963 - val_loss: 71.4802\n",
      "Epoch 1934/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3228 - val_loss: 93.1729\n",
      "Epoch 1935/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8483 - val_loss: 71.7572\n",
      "Epoch 1936/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7348 - val_loss: 68.7061\n",
      "Epoch 1937/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6758 - val_loss: 74.1640\n",
      "Epoch 1938/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7588 - val_loss: 68.0876\n",
      "Epoch 1939/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2840 - val_loss: 68.1998\n",
      "Epoch 1940/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8129 - val_loss: 68.2465\n",
      "Epoch 1941/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2674 - val_loss: 74.1413\n",
      "Epoch 1942/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8356 - val_loss: 68.5427\n",
      "Epoch 1943/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5171 - val_loss: 69.0958\n",
      "Epoch 1944/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3060 - val_loss: 72.1838\n",
      "Epoch 1945/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8910 - val_loss: 68.2748\n",
      "Epoch 1946/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6627 - val_loss: 70.9186\n",
      "Epoch 1947/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5535 - val_loss: 68.9375\n",
      "Epoch 1948/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9332 - val_loss: 70.1270\n",
      "Epoch 1949/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5901 - val_loss: 68.3478\n",
      "Epoch 1950/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3067 - val_loss: 68.6212\n",
      "Epoch 1951/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9678 - val_loss: 69.5107\n",
      "Epoch 1952/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.4111 - val_loss: 77.3281\n",
      "Epoch 1953/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6925 - val_loss: 70.3225\n",
      "Epoch 1954/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8739 - val_loss: 69.2917\n",
      "Epoch 1955/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2953 - val_loss: 68.6218\n",
      "Epoch 1956/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5121 - val_loss: 68.3177\n",
      "Epoch 1957/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4413 - val_loss: 68.4452\n",
      "Epoch 1958/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7599 - val_loss: 69.9869\n",
      "Epoch 1959/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9033 - val_loss: 68.3503\n",
      "Epoch 1960/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3293 - val_loss: 75.6272\n",
      "Epoch 1961/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6540 - val_loss: 70.8566\n",
      "Epoch 1962/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3752 - val_loss: 68.5874\n",
      "Epoch 1963/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 21.4664 - val_loss: 77.3155\n",
      "Epoch 1964/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6909 - val_loss: 69.5626\n",
      "Epoch 1965/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9155 - val_loss: 75.4534\n",
      "Epoch 1966/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3950 - val_loss: 77.0439\n",
      "Epoch 1967/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.8548 - val_loss: 69.3701\n",
      "Epoch 1968/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1267 - val_loss: 68.2715\n",
      "Epoch 1969/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2828 - val_loss: 71.3043\n",
      "Epoch 1970/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4453 - val_loss: 71.8891\n",
      "Epoch 1971/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9025 - val_loss: 69.4468\n",
      "Epoch 1972/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6485 - val_loss: 72.2962\n",
      "Epoch 1973/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7997 - val_loss: 68.9876\n",
      "Epoch 1974/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6169 - val_loss: 68.6219\n",
      "Epoch 1975/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2485 - val_loss: 68.6859\n",
      "Epoch 1976/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6779 - val_loss: 68.7902\n",
      "Epoch 1977/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5832 - val_loss: 69.9545\n",
      "Epoch 1978/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4181 - val_loss: 68.6879\n",
      "Epoch 1979/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9518 - val_loss: 69.0085\n",
      "Epoch 1980/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5899 - val_loss: 68.2925\n",
      "Epoch 1981/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0126 - val_loss: 72.5488\n",
      "Epoch 1982/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9108 - val_loss: 73.2472\n",
      "Epoch 1983/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9088 - val_loss: 68.4999\n",
      "Epoch 1984/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.2643 - val_loss: 71.7911\n",
      "Epoch 1985/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3987 - val_loss: 72.6493\n",
      "Epoch 1986/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.1992 - val_loss: 72.2001\n",
      "Epoch 1987/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 22.0225 - val_loss: 69.8799\n",
      "Epoch 1988/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.9909 - val_loss: 68.3501\n",
      "Epoch 1989/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5162 - val_loss: 68.2063\n",
      "Epoch 1990/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 20.9943 - val_loss: 70.3421\n",
      "Epoch 1991/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6603 - val_loss: 71.4552\n",
      "Epoch 1992/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6461 - val_loss: 78.5623\n",
      "Epoch 1993/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.1642 - val_loss: 69.5663\n",
      "Epoch 1994/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6696 - val_loss: 71.4864\n",
      "Epoch 1995/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.5871 - val_loss: 68.6967\n",
      "Epoch 1996/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.4173 - val_loss: 72.7791\n",
      "Epoch 1997/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.3066 - val_loss: 70.6883\n",
      "Epoch 1998/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.6528 - val_loss: 74.5586\n",
      "Epoch 1999/2000\n",
      "152/152 [==============================] - 1s 7ms/step - loss: 21.7125 - val_loss: 70.0183\n",
      "Epoch 2000/2000\n",
      "152/152 [==============================] - 1s 8ms/step - loss: 21.9359 - val_loss: 68.7521\n"
     ]
    }
   ],
   "source": [
    "model_3 = None\n",
    "model_history_3 = pd.DataFrame()\n",
    "\n",
    "if os.path.exists(model_name_3):\n",
    "    print(\"Model Found: Loading...\")\n",
    "    model_3 = load_model(model_name_3)\n",
    "    model_history_3 = pd.read_csv(history_name_3)\n",
    "    print(model_3.summary())\n",
    "    print(\"Model Loaded!\")\n",
    "else:\n",
    "    print(\"Model not Found. Fitting model...\")\n",
    "    model_3, model_history_3 = stock_model(num_features, epochs, optimizer_3, model_name_3, history_name_3)\n",
    "    model_history_3 = model_history_3.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "plt.plot(np.arange(0,epochs,1), model_history_3['val_loss'],'--', label='Baseline Val')\n",
    "plt.plot(np.arange(0,epochs,1), model_history_3['loss'], color='blue', label='Baseline Train')\n",
    "plt.ylabel(\"mae\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.xlim([0,max(np.arange(0,epochs,1))])\n",
    "plt.ylim([0,max(max(model_history_3['val_loss']),max(model_history_3['loss']))])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................- 20\n",
      "....................- 40\n",
      "....................- 60\n",
      "....................- 80\n",
      "....................- 100\n",
      "....................- 120\n",
      "....................- 140\n",
      "....................- 160\n",
      "....................- 180\n",
      "....................- 200\n",
      "....................- 220\n",
      "....................- 240\n",
      ".- 242\n",
      "End of data prediction!\n"
     ]
    }
   ],
   "source": [
    "predicted_y_3 = check_all_test_data(test_x, model_3)\n",
    "print(\"End of data prediction!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f25b021eb8>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.arange(1,len(actual_y)+1)\n",
    "plt.plot(x_axis, predicted_y_3[:,0], label='predicted data')\n",
    "plt.plot(x_axis, actual_y[:,0], label='actual data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE =  99.01501352984091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f2519fed68>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print RMSE\n",
    "mse = mean_squared_error(actual_y, predicted_y_3)\n",
    "rmse = math.sqrt(mse)\n",
    "print(\"RMSE = \",rmse)\n",
    "\n",
    "def percent_diff(actual, predicted):\n",
    "    return ((actual-predicted)/actual) * 100\n",
    "\n",
    "#get percent difference between actual and predicted\n",
    "difference = []\n",
    "for i in range(0,len(actual_y)):\n",
    "    difference.append(percent_diff(actual_y[i],predicted_y_3[i]))\n",
    "\n",
    "x_axis = np.arange(1,len(actual_y)+1)\n",
    "plt.plot(x_axis, difference, label='percent difference')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Model (Moving Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3273.81666667, 3274.80444444, 3277.42474074, 3281.11972346,\n",
       "        3283.62770502],\n",
       "       [3277.85      , 3280.67333333, 3284.58488889, 3287.32388148,\n",
       "        3290.79547358],\n",
       "       [3283.46666667, 3287.56444444, 3290.50207407, 3294.18554568,\n",
       "        3296.44791539],\n",
       "       ...,\n",
       "       [3417.56666667, 3415.45444444, 3413.03474074, 3414.33705679,\n",
       "        3416.42619391],\n",
       "       [3423.11666667, 3421.20777778, 3423.05496296, 3425.72529383,\n",
       "        3436.54031342],\n",
       "       [3431.8       , 3434.35333333, 3437.77688889, 3449.39534815,\n",
       "        3459.20503802]])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_values = test_data[:,3]\n",
    "moving_averages_pred = []\n",
    "\n",
    "for i in range(len(test_values)):\n",
    "    end = i + NUMBER_OF_DAYS_DATA_TO_USE\n",
    "    \n",
    "    if end+1 > len(test_values) or end+NUMBER_OF_DAYS_DATA_TO_PREDICT > len(test_values):\n",
    "            break\n",
    "    \n",
    "    moving_prediction_set = list(test_values[i:end])\n",
    "    \n",
    "    for x in range(NUMBER_OF_DAYS_DATA_TO_PREDICT):\n",
    "        \n",
    "        end_x = x + NUMBER_OF_DAYS_DATA_TO_USE\n",
    "        \n",
    "        pred_value = np.mean(moving_prediction_set[x:end_x])         \n",
    "        \n",
    "        moving_prediction_set.append(pred_value)\n",
    "                          \n",
    "    moving_averages_pred.append(moving_prediction_set[NUMBER_OF_DAYS_DATA_TO_USE:NUMBER_OF_DAYS_DATA_TO_USE+NUMBER_OF_DAYS_DATA_TO_PREDICT])\n",
    "    \n",
    "moving_averages_pred = np.array(moving_averages_pred)\n",
    "\n",
    "moving_averages_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for the naive moving average model =  150.12993388495775\n"
     ]
    }
   ],
   "source": [
    "naive_mse = mean_squared_error(actual_y, moving_averages_pred)\n",
    "naive_rmse = math.sqrt(naive_mse)\n",
    "print(\"RMSE for the naive moving average model = \",naive_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f258f35be0>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.arange(1,len(actual_y)+1)\n",
    "plt.plot(x_axis, moving_averages_pred[:,0], label='naive data')\n",
    "plt.plot(x_axis, actual_y[:,0], label='actual data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.array([test_data[15:30]])\n",
    "sample_actual = test_data[30:35,3]\n",
    "\n",
    "def predict_with_model(model, data):\n",
    "    prediction = model.predict(sample)\n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock closing price predictions for the next 5 days\n",
      "3380.1875\n",
      "3373.5261\n",
      "3375.6643\n",
      "3358.571\n",
      "3370.674\n",
      "\n",
      "Actual stock closing prices for the next 5 days\n",
      "3325.5\n",
      "3311.75\n",
      "3353.0\n",
      "3357.5\n",
      "3380.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Stock closing price predictions for the next 5 days\")\n",
    "for each in predict_with_model(model_2, sample):\n",
    "    print(each)\n",
    "\n",
    "print(\"\\nActual stock closing prices for the next 5 days\")   \n",
    "for each in sample_actual:\n",
    "    print(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
